





<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Auto-scheduling a Convolution Layer for GPU &mdash; tvm 0.10.dev0 documentation</title>
  

  
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/css/bootstrap.min.css" integrity="sha384-Gn5384xqQ1aoWXA+058RXPxPg6fy4IWvTNh0E263XmFcJlSAwiGgFAW/dAiS6JXm" crossorigin="anonymous">
  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/sg_gallery.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/sg_gallery-binder.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/sg_gallery-dataframe.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/sg_gallery-rendered-html.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/css/tlcpack_theme.css" type="text/css" />

  
  
    <link rel="shortcut icon" href="../../_static/tvm-logo-square.png"/>
  

  
  
  
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
        <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
        <script src="../../_static/jquery.js"></script>
        <script src="../../_static/underscore.js"></script>
        <script src="../../_static/doctools.js"></script>
    
    <script type="text/javascript" src="../../_static/js/theme.js"></script>

    
    <script type="text/javascript" src="../../_static/js/tlcpack_theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Auto-scheduling a Neural Network for x86 CPU" href="tune_network_x86.html" />
    <link rel="prev" title="Use AutoScheduler for Template-Free Scheduling" href="index.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    
<header class="header">
    <div class="innercontainer">
      <div class="headerInner d-flex justify-content-between align-items-center">
          <div class="headerLogo">
               <a href="https://tvm.apache.org/"><img src=https://tvm.apache.org/assets/images/logo.svg alt="logo"></a>
          </div>

          <div id="headMenu" class="headerNav">
            <button type="button" id="closeHeadMenu" class="navCloseBtn"><img src="../../_static/img/close-icon.svg" alt="Close"></button>
             <ul class="nav">
                <li class="nav-item">
                   <a class="nav-link" href=https://tvm.apache.org/community>Community</a>
                </li>
                <li class="nav-item">
                   <a class="nav-link" href=https://tvm.apache.org/download>Download</a>
                </li>
                <li class="nav-item">
                   <a class="nav-link" href=https://tvm.apache.org/vta>VTA</a>
                </li>
                <li class="nav-item">
                   <a class="nav-link" href=https://tvm.apache.org/blog>Blog</a>
                </li>
                <li class="nav-item">
                   <a class="nav-link" href=https://tvm.apache.org/docs>Docs</a>
                </li>
                <li class="nav-item">
                   <a class="nav-link" href=https://tvmconf.org>Conference</a>
                </li>
                <li class="nav-item">
                   <a class="nav-link" href=https://github.com/apache/tvm/>Github</a>
                </li>
             </ul>
               <div class="responsivetlcdropdown">
                 <button type="button" class="btn-link">
                   ASF
                 </button>
                 <ul>
                     <li>
                       <a href=https://apache.org/>Apache Homepage</a>
                     </li>
                     <li>
                       <a href=https://www.apache.org/licenses/>License</a>
                     </li>
                     <li>
                       <a href=https://www.apache.org/foundation/sponsorship.html>Sponsorship</a>
                     </li>
                     <li>
                       <a href=https://www.apache.org/security/>Security</a>
                     </li>
                     <li>
                       <a href=https://www.apache.org/foundation/thanks.html>Thanks</a>
                     </li>
                     <li>
                       <a href=https://www.apache.org/events/current-event>Events</a>
                     </li>
                 </ul>
               </div>
          </div>
            <div class="responsiveMenuIcon">
              <button type="button" id="menuBtn" class="btn-menu"><img src="../../_static/img/menu-icon.svg" alt="Menu Icon"></button>
            </div>

            <div class="tlcDropdown">
              <div class="dropdown">
                <button type="button" class="btn-link dropdown-toggle" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                  ASF
                </button>
                <div class="dropdown-menu dropdown-menu-right">
                  <ul>
                     <li>
                       <a href=https://apache.org/>Apache Homepage</a>
                     </li>
                     <li>
                       <a href=https://www.apache.org/licenses/>License</a>
                     </li>
                     <li>
                       <a href=https://www.apache.org/foundation/sponsorship.html>Sponsorship</a>
                     </li>
                     <li>
                       <a href=https://www.apache.org/security/>Security</a>
                     </li>
                     <li>
                       <a href=https://www.apache.org/foundation/thanks.html>Thanks</a>
                     </li>
                     <li>
                       <a href=https://www.apache.org/events/current-event>Events</a>
                     </li>
                  </ul>
                </div>
              </div>
          </div>
       </div>
    </div>
 </header>
 
    <nav data-toggle="wy-nav-shift" class="wy-nav-side fixed">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../../index.html">
          

          
            
            <img src="../../_static/tvm-logo-small.png" class="logo" alt="Logo"/>
          
          </a>

          
            
            
              <input type="checkbox" class="version-toggle-box" hidden id="version-toggle">
              <label for="version-toggle" class="version-toggle-label">
                  <div tabindex="0" class="version version-selector version-selector-show">
                    0.10.dev0 <span class="chevron versions-hidden"><svg fill="none" height="24" viewBox="0 0 24 24" width="24" xmlns="http://www.w3.org/2000/svg"><path d="m8 4 8 8-8 8" stroke="#000" stroke-linecap="round" stroke-linejoin="round" stroke-width="2"/></svg></span><span class="chevron versions-shown"><svg fill="none" height="24" viewBox="0 0 24 24" width="24" xmlns="http://www.w3.org/2000/svg"><path d="m4 8 8 8 8-8" stroke="#000" stroke-linecap="round" stroke-linejoin="round" stroke-width="2"/></svg></span>
                  </div>
                </label>
                <div class="version-details wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
                  <p class="caption" role="heading"><span class="caption-text">Versions</span></p>
                  <ol style="text-align: left">
                    
                    
                    
                    
                      <li><div class="version"><a style="font-size: 0.8em; padding: 4px" href="/">0.10.dev0 (main)</a></div></li>
                    
                    
                    
                    
                      <li><div class="version"><a style="font-size: 0.8em; padding: 4px" href="v0.8.0/">v0.8.0</a></div></li>
                    
                    
                    
                    
                      <li><div class="version"><a style="font-size: 0.8em; padding: 4px" href="v0.9.0/">v0.9.0</a></div></li>
                    
                  </ol>
                </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption" role="heading"><span class="caption-text">Getting Started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../install/index.html">Installing TVM</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../contribute/index.html">Contributor Guide</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">User Guide</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../tutorial/index.html">User Tutorial</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../index.html">How To Guides</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../compile_models/index.html">Compile Deep Learning Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="../deploy/index.html">Deploy Models and Integrate TVM</a></li>
<li class="toctree-l2"><a class="reference internal" href="../work_with_relay/index.html">Work With Relay</a></li>
<li class="toctree-l2"><a class="reference internal" href="../work_with_schedules/index.html">Work With Tensor Expression and Schedules</a></li>
<li class="toctree-l2"><a class="reference internal" href="../optimize_operators/index.html">Optimize Tensor Operators</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tune_with_autotvm/index.html">Auto-Tune with Templates and AutoTVM</a></li>
<li class="toctree-l2 current"><a class="reference internal" href="index.html">Use AutoScheduler for Template-Free Scheduling</a><ul class="current">
<li class="toctree-l3 current"><a class="current reference internal" href="#">Auto-scheduling a Convolution Layer for GPU</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#define-the-computation">Define the computation</a></li>
<li class="toctree-l4"><a class="reference internal" href="#create-the-search-task">Create the search task</a></li>
<li class="toctree-l4"><a class="reference internal" href="#run-the-search">Run the search</a></li>
<li class="toctree-l4"><a class="reference internal" href="#check-correctness-and-evaluate-performance">Check correctness and evaluate performance</a></li>
<li class="toctree-l4"><a class="reference internal" href="#using-the-record-file">Using the record file</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="tune_network_x86.html">Auto-scheduling a Neural Network for x86 CPU</a></li>
<li class="toctree-l3"><a class="reference internal" href="tune_network_cuda.html">Auto-scheduling a Neural Network for NVIDIA GPU</a></li>
<li class="toctree-l3"><a class="reference internal" href="tune_network_arm.html">Auto-scheduling a Neural Network for ARM CPU</a></li>
<li class="toctree-l3"><a class="reference internal" href="tune_network_mali.html">Auto-scheduling a Neural Network for mali GPU</a></li>
<li class="toctree-l3"><a class="reference internal" href="tune_sparse_x86.html">Auto-scheduling Sparse Matrix Multiplication on CPU with Custom Sketch Rule</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../work_with_microtvm/index.html">Work With microTVM</a></li>
<li class="toctree-l2"><a class="reference internal" href="../extend_tvm/index.html">Extend TVM</a></li>
<li class="toctree-l2"><a class="reference internal" href="../profile/index.html">Profile Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../errors.html">Handle TVM Errors</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../faq.html">Frequently Asked Questions</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Developer Guide</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../dev/tutorial/index.html">Developer Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../dev/how_to/how_to.html">Developer How-To Guide</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Architecture  Guide</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../arch/index.html">Design and Architecture</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Topic Guides</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../topic/microtvm/index.html">microTVM: TVM on bare-metal</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../topic/vta/index.html">VTA: Versatile Tensor Accelerator</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Reference Guide</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../reference/langref/index.html">Language Reference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../reference/api/python/index.html">Python API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../reference/api/links.html">Other APIs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../reference/publications.html">Publications</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../genindex.html">Index</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">
      
      <nav class="wy-nav-top" aria-label="top navigation" data-toggle="wy-nav-top">
        
            <div class="togglemenu">

            </div>
            <div class="nav-content">
              <!-- tvm -->
              Table of Contents
            </div>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        

          




















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../index.html">Docs</a> <span class="br-arrow">></span></li>
        
          <li><a href="../index.html">How To Guides</a> <span class="br-arrow">></span></li>
        
          <li><a href="index.html">Use AutoScheduler for Template-Free Scheduling</a> <span class="br-arrow">></span></li>
        
      <li>Auto-scheduling a Convolution Layer for GPU</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../../_sources/how_to/tune_with_autoscheduler/tune_conv2d_layer_cuda.rst.txt" rel="nofollow"> <img src="../../_static/img/source.svg" alt="viewsource"/></a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">Note</p>
<p>Click <a class="reference internal" href="#sphx-glr-download-how-to-tune-with-autoscheduler-tune-conv2d-layer-cuda-py"><span class="std std-ref">here</span></a>
to download the full example code</p>
</div>
<div class="sphx-glr-example-title section" id="auto-scheduling-a-convolution-layer-for-gpu">
<span id="auto-scheduler-conv-gpu"></span><span id="sphx-glr-how-to-tune-with-autoscheduler-tune-conv2d-layer-cuda-py"></span><h1>Auto-scheduling a Convolution Layer for GPU<a class="headerlink" href="#auto-scheduling-a-convolution-layer-for-gpu" title="Permalink to this headline">¶</a></h1>
<p><strong>Author</strong>: <a class="reference external" href="https://github.com/merrymercy">Lianmin Zheng</a>,             <a class="reference external" href="https://github.com/jcf94/">Chengfan Jia</a></p>
<p>This is a tutorial on how to use the auto-scheduler for GPUs.</p>
<p>Different from the template-based <a class="reference internal" href="../tune_with_autotvm/index.html#tutorials-autotvm-sec"><span class="std std-ref">autotvm</span></a> which relies on
manual templates to define the search space, the auto-scheduler does not require any templates.
Users only need to write the computation declaration without any schedule commands or templates.
The auto-scheduler can automatically generate a large search space and
find a good schedule in the space.</p>
<p>We use a convolution layer as an example in this tutorial.</p>
<p>Note that this tutorial will not run on Windows or recent versions of macOS. To
get it to run, you will need to wrap the body of this tutorial in a <code class="code docutils literal notranslate"><span class="pre">if</span>
<span class="pre">__name__</span> <span class="pre">==</span> <span class="pre">&quot;__main__&quot;:</span></code> block.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">tvm</span>
<span class="kn">from</span> <span class="nn">tvm</span> <span class="kn">import</span> <span class="n">te</span><span class="p">,</span> <span class="n">auto_scheduler</span><span class="p">,</span> <span class="n">topi</span>
<span class="kn">from</span> <span class="nn">tvm.topi.testing</span> <span class="kn">import</span> <span class="n">conv2d_nchw_python</span>
</pre></div>
</div>
<div class="section" id="define-the-computation">
<h2>Define the computation<a class="headerlink" href="#define-the-computation" title="Permalink to this headline">¶</a></h2>
<p>To begin with, let us define the computation of a convolution layer.
The function should return the list of input/output tensors.
From these tensors, the auto-scheduler can get the whole computational graph.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nd">@auto_scheduler</span><span class="o">.</span><span class="n">register_workload</span>
<span class="k">def</span> <span class="nf">conv2d_layer</span><span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">H</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">W</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">CO</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">CI</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">KH</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">KW</span></a><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">padding</span></a><span class="p">):</span>
    <span class="n">data</span> <span class="o">=</span> <a href="../../reference/api/python/te.html#tvm.te.placeholder" title="tvm.te.placeholder" class="sphx-glr-backref-module-tvm-te sphx-glr-backref-type-py-function"><span class="n">te</span><span class="o">.</span><span class="n">placeholder</span></a><span class="p">((</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">CI</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">H</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">W</span></a><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;data&quot;</span><span class="p">)</span>
    <span class="n">kernel</span> <span class="o">=</span> <a href="../../reference/api/python/te.html#tvm.te.placeholder" title="tvm.te.placeholder" class="sphx-glr-backref-module-tvm-te sphx-glr-backref-type-py-function"><span class="n">te</span><span class="o">.</span><span class="n">placeholder</span></a><span class="p">((</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">CO</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">CI</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">KH</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">KW</span></a><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;kernel&quot;</span><span class="p">)</span>
    <span class="n">bias</span> <span class="o">=</span> <a href="../../reference/api/python/te.html#tvm.te.placeholder" title="tvm.te.placeholder" class="sphx-glr-backref-module-tvm-te sphx-glr-backref-type-py-function"><span class="n">te</span><span class="o">.</span><span class="n">placeholder</span></a><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">CO</span></a><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;bias&quot;</span><span class="p">)</span>
    <span class="n">conv</span> <span class="o">=</span> <a href="../../reference/api/python/topi.html#tvm.topi.nn.conv2d_nchw" title="tvm.topi.nn.conv2d_nchw" class="sphx-glr-backref-module-tvm-topi-nn sphx-glr-backref-type-py-function"><span class="n">topi</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">conv2d_nchw</span></a><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">kernel</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">padding</span></a><span class="p">,</span> <span class="n">dilation</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">out_dtype</span><span class="o">=</span><span class="s2">&quot;float32&quot;</span><span class="p">)</span>
    <span class="n">out</span> <span class="o">=</span> <a href="../../reference/api/python/topi.html#tvm.topi.nn.relu" title="tvm.topi.nn.relu" class="sphx-glr-backref-module-tvm-topi-nn sphx-glr-backref-type-py-function"><span class="n">topi</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">relu</span></a><span class="p">(</span><span class="n">conv</span> <span class="o">+</span> <span class="n">bias</span><span class="p">)</span>
    <span class="k">return</span> <span class="p">[</span><span class="n">data</span><span class="p">,</span> <span class="n">kernel</span><span class="p">,</span> <span class="n">bias</span><span class="p">,</span> <span class="n">out</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="section" id="create-the-search-task">
<h2>Create the search task<a class="headerlink" href="#create-the-search-task" title="Permalink to this headline">¶</a></h2>
<p>We then create a search task for the last convolution layer in the resnet.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="../../reference/api/python/target.html#tvm.target.Target" title="tvm.target.Target" class="sphx-glr-backref-module-tvm-target sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">target</span></a> <span class="o">=</span> <a href="../../reference/api/python/target.html#tvm.target.Target" title="tvm.target.Target" class="sphx-glr-backref-module-tvm-target sphx-glr-backref-type-py-class"><span class="n">tvm</span><span class="o">.</span><span class="n">target</span><span class="o">.</span><span class="n">Target</span></a><span class="p">(</span><span class="s2">&quot;cuda&quot;</span><span class="p">)</span>

<span class="c1"># Use the last layer in ResNet-50</span>
<a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">H</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">W</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">CO</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">CI</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">KH</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">KW</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">strides</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">padding</span></a> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">512</span><span class="p">,</span> <span class="mi">512</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<a href="../../reference/api/python/auto_scheduler.html#tvm.auto_scheduler.SearchTask" title="tvm.auto_scheduler.SearchTask" class="sphx-glr-backref-module-tvm-auto_scheduler sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">task</span></a> <span class="o">=</span> <a href="../../reference/api/python/auto_scheduler.html#tvm.auto_scheduler.SearchTask" title="tvm.auto_scheduler.SearchTask" class="sphx-glr-backref-module-tvm-auto_scheduler sphx-glr-backref-type-py-class"><span class="n">auto_scheduler</span><span class="o">.</span><span class="n">SearchTask</span></a><span class="p">(</span>
    <span class="n">func</span><span class="o">=</span><span class="n">conv2d_layer</span><span class="p">,</span> <a href="../../reference/api/python/ir.html#tvm.ir.Array" title="tvm.ir.Array" class="sphx-glr-backref-module-tvm-ir sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">args</span></a><span class="o">=</span><span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">H</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">W</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">CO</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">CI</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">KH</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">KW</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">strides</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">padding</span></a><span class="p">),</span> <a href="../../reference/api/python/target.html#tvm.target.Target" title="tvm.target.Target" class="sphx-glr-backref-module-tvm-target sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">target</span></a><span class="o">=</span><a href="../../reference/api/python/target.html#tvm.target.Target" title="tvm.target.Target" class="sphx-glr-backref-module-tvm-target sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">target</span></a>
<span class="p">)</span>

<span class="c1"># Inspect the computational graph</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Computational DAG:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><a href="../../reference/api/python/auto_scheduler.html#tvm.auto_scheduler.ComputeDAG" title="tvm.auto_scheduler.ComputeDAG" class="sphx-glr-backref-module-tvm-auto_scheduler sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">task</span><span class="o">.</span><span class="n">compute_dag</span></a><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Computational DAG:
data = PLACEHOLDER [1, 512, 7, 7]
pad_temp(i0, i1, i2, i3) = tir.if_then_else(((((i2 &gt;= 1) &amp;&amp; (i2 &lt; 8)) &amp;&amp; (i3 &gt;= 1)) &amp;&amp; (i3 &lt; 8)), data[i0, i1, (i2 - 1), (i3 - 1)], 0f)
kernel = PLACEHOLDER [512, 512, 3, 3]
conv2d_nchw(nn, ff, yy, xx) += (pad_temp[nn, rc, (yy + ry), (xx + rx)]*kernel[ff, rc, ry, rx])
bias = PLACEHOLDER [1, 512, 1, 1]
T_add(ax0, ax1, ax2, ax3) = (conv2d_nchw[ax0, ax1, ax2, ax3] + bias[ax0, ax1, 0, 0])
compute(i0, i1, i2, i3) = max(T_add[i0, i1, i2, i3], 0f)
</pre></div>
</div>
<p>Next, we set parameters for the auto-scheduler. These parameters
mainly specify how we do the measurement during the search.</p>
<ul class="simple">
<li><p><code class="code docutils literal notranslate"><span class="pre">measure_ctx</span></code> launches a different process for measurement to
provide isolation. It can protect the main process from GPU crashes
during measurement and avoid other runtime conflicts.</p></li>
<li><p><code class="code docutils literal notranslate"><span class="pre">min_repeat_ms</span></code> defines the minimum duration of one “repeat” in every measurement.
This can warmup the GPU, which is necessary to get accurate measurement results.
Typically, we recommend a value &gt;= 300 ms.</p></li>
<li><p><code class="code docutils literal notranslate"><span class="pre">num_measure_trials</span></code> is the number of measurement trials we can use during the search.
We only make 10 trials in this tutorial for a fast demonstration. In practice, 1000 is a
good value for the search to converge. You can do more trials according to your time budget.</p></li>
<li><p>In addition, we use <code class="code docutils literal notranslate"><span class="pre">RecordToFile</span></code> to dump measurement records into a file <cite>conv2d.json</cite>.
The measurement records can be used to query the history best, resume the search,
and do more analyses later.</p></li>
<li><p>see <a class="reference internal" href="../../reference/api/python/auto_scheduler.html#tvm.auto_scheduler.TuningOptions" title="tvm.auto_scheduler.TuningOptions"><code class="xref any py py-class docutils literal notranslate"><span class="pre">auto_scheduler.TuningOptions</span></code></a>,
<a class="reference internal" href="../../reference/api/python/auto_scheduler.html#tvm.auto_scheduler.LocalRPCMeasureContext" title="tvm.auto_scheduler.LocalRPCMeasureContext"><code class="xref any py py-class docutils literal notranslate"><span class="pre">auto_scheduler.LocalRPCMeasureContext</span></code></a> for more parameters.</p></li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">log_file</span></a> <span class="o">=</span> <span class="s2">&quot;conv2d.json&quot;</span>
<span class="n">measure_ctx</span> <span class="o">=</span> <a href="../../reference/api/python/auto_scheduler.html#tvm.auto_scheduler.LocalRPCMeasureContext" title="tvm.auto_scheduler.LocalRPCMeasureContext" class="sphx-glr-backref-module-tvm-auto_scheduler sphx-glr-backref-type-py-class"><span class="n">auto_scheduler</span><span class="o">.</span><span class="n">LocalRPCMeasureContext</span></a><span class="p">(</span><span class="n">min_repeat_ms</span><span class="o">=</span><span class="mi">300</span><span class="p">)</span>
<a href="../../reference/api/python/auto_scheduler.html#tvm.auto_scheduler.TuningOptions" title="tvm.auto_scheduler.TuningOptions" class="sphx-glr-backref-module-tvm-auto_scheduler sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">tune_option</span></a> <span class="o">=</span> <a href="../../reference/api/python/auto_scheduler.html#tvm.auto_scheduler.TuningOptions" title="tvm.auto_scheduler.TuningOptions" class="sphx-glr-backref-module-tvm-auto_scheduler sphx-glr-backref-type-py-class"><span class="n">auto_scheduler</span><span class="o">.</span><span class="n">TuningOptions</span></a><span class="p">(</span>
    <span class="n">num_measure_trials</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>  <span class="c1"># change this to 1000 to achieve the best performance</span>
    <span class="n">runner</span><span class="o">=</span><span class="n">measure_ctx</span><span class="o">.</span><span class="n">runner</span><span class="p">,</span>
    <span class="n">measure_callbacks</span><span class="o">=</span><span class="p">[</span><a href="../../reference/api/python/auto_scheduler.html#tvm.auto_scheduler.RecordToFile" title="tvm.auto_scheduler.RecordToFile" class="sphx-glr-backref-module-tvm-auto_scheduler sphx-glr-backref-type-py-class"><span class="n">auto_scheduler</span><span class="o">.</span><span class="n">RecordToFile</span></a><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">log_file</span></a><span class="p">)],</span>
    <span class="n">verbose</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Get devices for measurement successfully!
</pre></div>
</div>
</div>
<div class="section" id="run-the-search">
<h2>Run the search<a class="headerlink" href="#run-the-search" title="Permalink to this headline">¶</a></h2>
<p>Now we get all inputs ready. Pretty simple, isn’t it?
We can kick off the search and let the auto-scheduler do its magic.
After some measurement trials, we can load the best schedule from the log
file and apply it.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Run auto-tuning (search)</span>
<a href="../../reference/api/python/auto_scheduler.html#tvm.auto_scheduler.SearchTask.tune" title="tvm.auto_scheduler.SearchTask.tune" class="sphx-glr-backref-module-tvm-auto_scheduler sphx-glr-backref-type-py-method"><span class="n">task</span><span class="o">.</span><span class="n">tune</span></a><span class="p">(</span><a href="../../reference/api/python/auto_scheduler.html#tvm.auto_scheduler.TuningOptions" title="tvm.auto_scheduler.TuningOptions" class="sphx-glr-backref-module-tvm-auto_scheduler sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">tune_option</span></a><span class="p">)</span>
<span class="c1"># Apply the best schedule</span>
<a href="../../reference/api/python/te.html#tvm.te.Schedule" title="tvm.te.Schedule" class="sphx-glr-backref-module-tvm-te sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">sch</span></a><span class="p">,</span> <a href="../../reference/api/python/ir.html#tvm.ir.Array" title="tvm.ir.Array" class="sphx-glr-backref-module-tvm-ir sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">args</span></a> <span class="o">=</span> <a href="../../reference/api/python/auto_scheduler.html#tvm.auto_scheduler.SearchTask.apply_best" title="tvm.auto_scheduler.SearchTask.apply_best" class="sphx-glr-backref-module-tvm-auto_scheduler sphx-glr-backref-type-py-method"><span class="n">task</span><span class="o">.</span><span class="n">apply_best</span></a><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">log_file</span></a><span class="p">)</span>

<span class="c1"># Kill the measurement process</span>
<span class="k">del</span> <span class="n">measure_ctx</span>
</pre></div>
</div>
<p>We can lower the schedule to see the IR after auto-scheduling.
The auto-scheduler correctly performs optimizations including multi-level tiling,
cooperative fetching, unrolling and operator fusion.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Lowered TIR:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><a href="../../reference/api/python/driver.html#tvm.lower" title="tvm.lower" class="sphx-glr-backref-module-tvm sphx-glr-backref-type-py-function"><span class="n">tvm</span><span class="o">.</span><span class="n">lower</span></a><span class="p">(</span><a href="../../reference/api/python/te.html#tvm.te.Schedule" title="tvm.te.Schedule" class="sphx-glr-backref-module-tvm-te sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">sch</span></a><span class="p">,</span> <a href="../../reference/api/python/ir.html#tvm.ir.Array" title="tvm.ir.Array" class="sphx-glr-backref-module-tvm-ir sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">args</span></a><span class="p">,</span> <span class="n">simple_mode</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Lowered TIR:
@main = primfn(data_1: handle, kernel_1: handle, bias_1: handle, compute_1: handle) -&gt; ()
  attr = {&quot;from_legacy_te_schedule&quot;: True, &quot;global_symbol&quot;: &quot;main&quot;, &quot;tir.noalias&quot;: True}
  buffers = {data: Buffer(data_2: Pointer(float32), float32, [25088], []),
             kernel: Buffer(kernel_2: Pointer(float32), float32, [2359296], []),
             bias: Buffer(bias_2: Pointer(float32), float32, [512], []),
             compute: Buffer(compute_2: Pointer(float32), float32, [25088], [])}
  buffer_map = {data_1: data, kernel_1: kernel, bias_1: bias, compute_1: compute}
  preflattened_buffer_map = {data_1: data_3: Buffer(data_2, float32, [1, 512, 7, 7], []), kernel_1: kernel_3: Buffer(kernel_2, float32, [512, 512, 3, 3], []), bias_1: bias_3: Buffer(bias_2, float32, [1, 512, 1, 1], []), compute_1: compute_3: Buffer(compute_2, float32, [1, 512, 7, 7], [])} {
  attr [IterVar(blockIdx.x: int32, (nullptr), &quot;ThreadIndex&quot;, &quot;blockIdx.x&quot;)] &quot;thread_extent&quot; = 64;
  allocate(conv2d_nchw: Pointer(local float32), float32, [8]), storage_scope = local;
  allocate(pad_temp.shared: Pointer(shared float32), float32, [5184]), storage_scope = shared;
  allocate(kernel.shared: Pointer(shared float32), float32, [4608]), storage_scope = shared;
  attr [IterVar(threadIdx.x: int32, (nullptr), &quot;ThreadIndex&quot;, &quot;threadIdx.x&quot;)] &quot;thread_extent&quot; = 49 {
    conv2d_nchw_1: Buffer(conv2d_nchw, float32, [16], [], scope=&quot;local&quot;, align=16)[0] = 0f32
    conv2d_nchw_1[4] = 0f32
    conv2d_nchw_1[1] = 0f32
    conv2d_nchw_1[5] = 0f32
    conv2d_nchw_1[2] = 0f32
    conv2d_nchw_1[6] = 0f32
    conv2d_nchw_1[3] = 0f32
    conv2d_nchw_1[7] = 0f32
    for (rc.outer.outer: int32, 0, 8) {
      let cse_var_2: int32 = (rc.outer.outer*3136)
      let cse_var_1: int32 = (rc.outer.outer*576)
       {
        attr [IterVar(threadIdx.x_1: int32, (nullptr), &quot;ThreadIndex&quot;, &quot;threadIdx.x&quot;)] &quot;thread_extent&quot; = 49 {
          pad_temp.shared_1: Buffer(pad_temp.shared, float32, [5184], [], scope=&quot;shared&quot;)[(threadIdx.x_1*12)] = @tir.if_then_else((((3 &lt;= floormod((threadIdx.x_1*4), 27)) &amp;&amp; (floormod((threadIdx.x_1*12), 81) &lt; 72)) &amp;&amp; (1 &lt;= floormod(threadIdx.x_1, 3))), data[((((cse_var_2 + (floordiv((threadIdx.x_1*4), 27)*49)) + (floordiv(floormod((threadIdx.x_1*4), 27), 3)*7)) + (floormod(threadIdx.x_1, 3)*3)) - 8)], 0f32, dtype=float32)
          pad_temp.shared_1[((threadIdx.x_1*12) + 1)] = @tir.if_then_else(((3 &lt;= floormod((threadIdx.x_1*4), 27)) &amp;&amp; (floormod(((threadIdx.x_1*12) + 1), 81) &lt; 72)), data[((((cse_var_2 + (floordiv((threadIdx.x_1*4), 27)*49)) + (floordiv(floormod((threadIdx.x_1*4), 27), 3)*7)) + (floormod(threadIdx.x_1, 3)*3)) - 7)], 0f32, dtype=float32)
          pad_temp.shared_1[((threadIdx.x_1*12) + 2)] = @tir.if_then_else((((3 &lt;= floormod((threadIdx.x_1*4), 27)) &amp;&amp; (floormod(((threadIdx.x_1*12) + 2), 81) &lt; 72)) &amp;&amp; (floormod(threadIdx.x_1, 3) &lt; 2)), data[((((cse_var_2 + (floordiv((threadIdx.x_1*4), 27)*49)) + (floordiv(floormod((threadIdx.x_1*4), 27), 3)*7)) + (floormod(threadIdx.x_1, 3)*3)) - 6)], 0f32, dtype=float32)
          pad_temp.shared_1[((threadIdx.x_1*12) + 3)] = @tir.if_then_else(((((3 &lt;= floormod(((threadIdx.x_1*4) + 1), 27)) &amp;&amp; (floormod(((threadIdx.x_1*12) + 3), 81) &lt; 72)) &amp;&amp; (1 &lt;= floormod(((threadIdx.x_1*3) + 3), 9))) &amp;&amp; (floormod(((threadIdx.x_1*3) + 3), 9) &lt; 8)), data[((((cse_var_2 + (floordiv(((threadIdx.x_1*4) + 1), 27)*49)) + (floordiv(floormod(((threadIdx.x_1*4) + 1), 27), 3)*7)) + floormod(((threadIdx.x_1*3) + 3), 9)) - 8)], 0f32, dtype=float32)
          pad_temp.shared_1[((threadIdx.x_1*12) + 4)] = @tir.if_then_else(((((3 &lt;= floormod(((threadIdx.x_1*4) + 1), 27)) &amp;&amp; (floormod(((threadIdx.x_1*12) + 4), 81) &lt; 72)) &amp;&amp; (1 &lt;= floormod(((threadIdx.x_1*3) + 4), 9))) &amp;&amp; (floormod(((threadIdx.x_1*3) + 4), 9) &lt; 8)), data[((((cse_var_2 + (floordiv(((threadIdx.x_1*4) + 1), 27)*49)) + (floordiv(floormod(((threadIdx.x_1*4) + 1), 27), 3)*7)) + floormod(((threadIdx.x_1*3) + 4), 9)) - 8)], 0f32, dtype=float32)
          pad_temp.shared_1[((threadIdx.x_1*12) + 5)] = @tir.if_then_else(((((3 &lt;= floormod(((threadIdx.x_1*4) + 1), 27)) &amp;&amp; (floormod(((threadIdx.x_1*12) + 5), 81) &lt; 72)) &amp;&amp; (1 &lt;= floormod(((threadIdx.x_1*3) + 5), 9))) &amp;&amp; (floormod(((threadIdx.x_1*3) + 5), 9) &lt; 8)), data[((((cse_var_2 + (floordiv(((threadIdx.x_1*4) + 1), 27)*49)) + (floordiv(floormod(((threadIdx.x_1*4) + 1), 27), 3)*7)) + floormod(((threadIdx.x_1*3) + 5), 9)) - 8)], 0f32, dtype=float32)
          pad_temp.shared_1[((threadIdx.x_1*12) + 6)] = @tir.if_then_else(((((3 &lt;= floormod(((threadIdx.x_1*4) + 2), 27)) &amp;&amp; (floormod(((threadIdx.x_1*12) + 6), 81) &lt; 72)) &amp;&amp; (1 &lt;= floormod(((threadIdx.x_1*3) + 6), 9))) &amp;&amp; (floormod(((threadIdx.x_1*3) + 6), 9) &lt; 8)), data[((((cse_var_2 + (floordiv(((threadIdx.x_1*4) + 2), 27)*49)) + (floordiv(floormod(((threadIdx.x_1*4) + 2), 27), 3)*7)) + floormod(((threadIdx.x_1*3) + 6), 9)) - 8)], 0f32, dtype=float32)
          pad_temp.shared_1[((threadIdx.x_1*12) + 7)] = @tir.if_then_else(((((3 &lt;= floormod(((threadIdx.x_1*4) + 2), 27)) &amp;&amp; (floormod(((threadIdx.x_1*12) + 7), 81) &lt; 72)) &amp;&amp; (1 &lt;= floormod(((threadIdx.x_1*3) + 7), 9))) &amp;&amp; (floormod(((threadIdx.x_1*3) + 7), 9) &lt; 8)), data[((((cse_var_2 + (floordiv(((threadIdx.x_1*4) + 2), 27)*49)) + (floordiv(floormod(((threadIdx.x_1*4) + 2), 27), 3)*7)) + floormod(((threadIdx.x_1*3) + 7), 9)) - 8)], 0f32, dtype=float32)
          pad_temp.shared_1[((threadIdx.x_1*12) + 8)] = @tir.if_then_else(((((3 &lt;= floormod(((threadIdx.x_1*4) + 2), 27)) &amp;&amp; (floormod(((threadIdx.x_1*12) + 8), 81) &lt; 72)) &amp;&amp; (1 &lt;= floormod(((threadIdx.x_1*3) + 8), 9))) &amp;&amp; (floormod(((threadIdx.x_1*3) + 8), 9) &lt; 8)), data[((((cse_var_2 + (floordiv(((threadIdx.x_1*4) + 2), 27)*49)) + (floordiv(floormod(((threadIdx.x_1*4) + 2), 27), 3)*7)) + floormod(((threadIdx.x_1*3) + 8), 9)) - 8)], 0f32, dtype=float32)
          pad_temp.shared_1[((threadIdx.x_1*12) + 9)] = @tir.if_then_else((((1 &lt;= floormod((floordiv((threadIdx.x_1*4), 3) + 1), 9)) &amp;&amp; (floormod(((threadIdx.x_1*12) + 9), 81) &lt; 72)) &amp;&amp; (1 &lt;= floormod(threadIdx.x_1, 3))), data[((((cse_var_2 + (floordiv(((threadIdx.x_1*4) + 3), 27)*49)) + (floormod((floordiv((threadIdx.x_1*4), 3) + 1), 9)*7)) + (floormod(threadIdx.x_1, 3)*3)) - 8)], 0f32, dtype=float32)
          pad_temp.shared_1[((threadIdx.x_1*12) + 10)] = @tir.if_then_else(((1 &lt;= floormod((floordiv((threadIdx.x_1*4), 3) + 1), 9)) &amp;&amp; (floormod(((threadIdx.x_1*12) + 10), 81) &lt; 72)), data[((((cse_var_2 + (floordiv(((threadIdx.x_1*4) + 3), 27)*49)) + (floormod((floordiv((threadIdx.x_1*4), 3) + 1), 9)*7)) + (floormod(threadIdx.x_1, 3)*3)) - 7)], 0f32, dtype=float32)
          pad_temp.shared_1[((threadIdx.x_1*12) + 11)] = @tir.if_then_else((((1 &lt;= floormod((floordiv((threadIdx.x_1*4), 3) + 1), 9)) &amp;&amp; (floormod(((threadIdx.x_1*12) + 11), 81) &lt; 72)) &amp;&amp; (floormod(threadIdx.x_1, 3) &lt; 2)), data[((((cse_var_2 + (floordiv(((threadIdx.x_1*4) + 3), 27)*49)) + (floormod((floordiv((threadIdx.x_1*4), 3) + 1), 9)*7)) + (floormod(threadIdx.x_1, 3)*3)) - 6)], 0f32, dtype=float32)
        }
        attr [IterVar(threadIdx.x_1, (nullptr), &quot;ThreadIndex&quot;, &quot;threadIdx.x&quot;)] &quot;thread_extent&quot; = 49 {
          pad_temp.shared_1[((threadIdx.x_1*12) + 588)] = @tir.if_then_else(((((3 &lt;= floormod(((threadIdx.x_1*4) + 7), 27)) &amp;&amp; (floormod(((threadIdx.x_1*12) + 21), 81) &lt; 72)) &amp;&amp; (1 &lt;= floormod(((threadIdx.x_1*3) + 3), 9))) &amp;&amp; (floormod(((threadIdx.x_1*3) + 3), 9) &lt; 8)), data[((((cse_var_2 + (floordiv(((threadIdx.x_1*4) + 196), 27)*49)) + (floordiv(floormod(((threadIdx.x_1*4) + 7), 27), 3)*7)) + floormod(((threadIdx.x_1*3) + 3), 9)) - 8)], 0f32, dtype=float32)
          pad_temp.shared_1[((threadIdx.x_1*12) + 589)] = @tir.if_then_else(((((3 &lt;= floormod(((threadIdx.x_1*4) + 7), 27)) &amp;&amp; (floormod(((threadIdx.x_1*12) + 22), 81) &lt; 72)) &amp;&amp; (1 &lt;= floormod(((threadIdx.x_1*3) + 4), 9))) &amp;&amp; (floormod(((threadIdx.x_1*3) + 4), 9) &lt; 8)), data[((((cse_var_2 + (floordiv(((threadIdx.x_1*4) + 196), 27)*49)) + (floordiv(floormod(((threadIdx.x_1*4) + 7), 27), 3)*7)) + floormod(((threadIdx.x_1*3) + 4), 9)) - 8)], 0f32, dtype=float32)
          pad_temp.shared_1[((threadIdx.x_1*12) + 590)] = @tir.if_then_else(((((3 &lt;= floormod(((threadIdx.x_1*4) + 7), 27)) &amp;&amp; (floormod(((threadIdx.x_1*12) + 23), 81) &lt; 72)) &amp;&amp; (1 &lt;= floormod(((threadIdx.x_1*3) + 5), 9))) &amp;&amp; (floormod(((threadIdx.x_1*3) + 5), 9) &lt; 8)), data[((((cse_var_2 + (floordiv(((threadIdx.x_1*4) + 196), 27)*49)) + (floordiv(floormod(((threadIdx.x_1*4) + 7), 27), 3)*7)) + floormod(((threadIdx.x_1*3) + 5), 9)) - 8)], 0f32, dtype=float32)
          pad_temp.shared_1[((threadIdx.x_1*12) + 591)] = @tir.if_then_else(((((3 &lt;= floormod(((threadIdx.x_1*4) + 8), 27)) &amp;&amp; (floormod(((threadIdx.x_1*12) + 24), 81) &lt; 72)) &amp;&amp; (1 &lt;= floormod(((threadIdx.x_1*3) + 6), 9))) &amp;&amp; (floormod(((threadIdx.x_1*3) + 6), 9) &lt; 8)), data[((((cse_var_2 + (floordiv(((threadIdx.x_1*4) + 197), 27)*49)) + (floordiv(floormod(((threadIdx.x_1*4) + 8), 27), 3)*7)) + floormod(((threadIdx.x_1*3) + 6), 9)) - 8)], 0f32, dtype=float32)
          pad_temp.shared_1[((threadIdx.x_1*12) + 592)] = @tir.if_then_else(((((3 &lt;= floormod(((threadIdx.x_1*4) + 8), 27)) &amp;&amp; (floormod(((threadIdx.x_1*12) + 25), 81) &lt; 72)) &amp;&amp; (1 &lt;= floormod(((threadIdx.x_1*3) + 7), 9))) &amp;&amp; (floormod(((threadIdx.x_1*3) + 7), 9) &lt; 8)), data[((((cse_var_2 + (floordiv(((threadIdx.x_1*4) + 197), 27)*49)) + (floordiv(floormod(((threadIdx.x_1*4) + 8), 27), 3)*7)) + floormod(((threadIdx.x_1*3) + 7), 9)) - 8)], 0f32, dtype=float32)
          pad_temp.shared_1[((threadIdx.x_1*12) + 593)] = @tir.if_then_else(((((3 &lt;= floormod(((threadIdx.x_1*4) + 8), 27)) &amp;&amp; (floormod(((threadIdx.x_1*12) + 26), 81) &lt; 72)) &amp;&amp; (1 &lt;= floormod(((threadIdx.x_1*3) + 8), 9))) &amp;&amp; (floormod(((threadIdx.x_1*3) + 8), 9) &lt; 8)), data[((((cse_var_2 + (floordiv(((threadIdx.x_1*4) + 197), 27)*49)) + (floordiv(floormod(((threadIdx.x_1*4) + 8), 27), 3)*7)) + floormod(((threadIdx.x_1*3) + 8), 9)) - 8)], 0f32, dtype=float32)
          pad_temp.shared_1[((threadIdx.x_1*12) + 594)] = @tir.if_then_else((((1 &lt;= floormod((floordiv((threadIdx.x_1*4), 3) + 3), 9)) &amp;&amp; (floormod(((threadIdx.x_1*12) + 27), 81) &lt; 72)) &amp;&amp; (1 &lt;= floormod(threadIdx.x_1, 3))), data[((((cse_var_2 + (floordiv(((threadIdx.x_1*4) + 198), 27)*49)) + (floormod((floordiv((threadIdx.x_1*4), 3) + 3), 9)*7)) + (floormod(threadIdx.x_1, 3)*3)) - 8)], 0f32, dtype=float32)
          pad_temp.shared_1[((threadIdx.x_1*12) + 595)] = @tir.if_then_else(((1 &lt;= floormod((floordiv((threadIdx.x_1*4), 3) + 3), 9)) &amp;&amp; (floormod(((threadIdx.x_1*12) + 28), 81) &lt; 72)), data[((((cse_var_2 + (floordiv(((threadIdx.x_1*4) + 198), 27)*49)) + (floormod((floordiv((threadIdx.x_1*4), 3) + 3), 9)*7)) + (floormod(threadIdx.x_1, 3)*3)) - 7)], 0f32, dtype=float32)
          pad_temp.shared_1[((threadIdx.x_1*12) + 596)] = @tir.if_then_else((((1 &lt;= floormod((floordiv((threadIdx.x_1*4), 3) + 3), 9)) &amp;&amp; (floormod(((threadIdx.x_1*12) + 29), 81) &lt; 72)) &amp;&amp; (floormod(threadIdx.x_1, 3) &lt; 2)), data[((((cse_var_2 + (floordiv(((threadIdx.x_1*4) + 198), 27)*49)) + (floormod((floordiv((threadIdx.x_1*4), 3) + 3), 9)*7)) + (floormod(threadIdx.x_1, 3)*3)) - 6)], 0f32, dtype=float32)
          pad_temp.shared_1[((threadIdx.x_1*12) + 597)] = @tir.if_then_else(((((1 &lt;= floormod((floordiv(((threadIdx.x_1*4) + 196), 3) + 1), 9)) &amp;&amp; (floormod(((threadIdx.x_1*12) + 30), 81) &lt; 72)) &amp;&amp; (1 &lt;= floormod(((threadIdx.x_1*3) + 3), 9))) &amp;&amp; (floormod(((threadIdx.x_1*3) + 3), 9) &lt; 8)), data[((((cse_var_2 + (floordiv(((threadIdx.x_1*4) + 199), 27)*49)) + (floormod((floordiv(((threadIdx.x_1*4) + 196), 3) + 1), 9)*7)) + floormod(((threadIdx.x_1*3) + 3), 9)) - 8)], 0f32, dtype=float32)
          pad_temp.shared_1[((threadIdx.x_1*12) + 598)] = @tir.if_then_else(((((1 &lt;= floormod((floordiv(((threadIdx.x_1*4) + 196), 3) + 1), 9)) &amp;&amp; (floormod(((threadIdx.x_1*12) + 31), 81) &lt; 72)) &amp;&amp; (1 &lt;= floormod(((threadIdx.x_1*3) + 4), 9))) &amp;&amp; (floormod(((threadIdx.x_1*3) + 4), 9) &lt; 8)), data[((((cse_var_2 + (floordiv(((threadIdx.x_1*4) + 199), 27)*49)) + (floormod((floordiv(((threadIdx.x_1*4) + 196), 3) + 1), 9)*7)) + floormod(((threadIdx.x_1*3) + 4), 9)) - 8)], 0f32, dtype=float32)
          pad_temp.shared_1[((threadIdx.x_1*12) + 599)] = @tir.if_then_else(((((1 &lt;= floormod((floordiv(((threadIdx.x_1*4) + 196), 3) + 1), 9)) &amp;&amp; (floormod(((threadIdx.x_1*12) + 32), 81) &lt; 72)) &amp;&amp; (1 &lt;= floormod(((threadIdx.x_1*3) + 5), 9))) &amp;&amp; (floormod(((threadIdx.x_1*3) + 5), 9) &lt; 8)), data[((((cse_var_2 + (floordiv(((threadIdx.x_1*4) + 199), 27)*49)) + (floormod((floordiv(((threadIdx.x_1*4) + 196), 3) + 1), 9)*7)) + floormod(((threadIdx.x_1*3) + 5), 9)) - 8)], 0f32, dtype=float32)
        }
        attr [IterVar(threadIdx.x_1, (nullptr), &quot;ThreadIndex&quot;, &quot;threadIdx.x&quot;)] &quot;thread_extent&quot; = 49 {
          pad_temp.shared_1[((threadIdx.x_1*12) + 1176)] = @tir.if_then_else(((((3 &lt;= floormod(((threadIdx.x_1*4) + 14), 27)) &amp;&amp; (floormod(((threadIdx.x_1*12) + 42), 81) &lt; 72)) &amp;&amp; (1 &lt;= floormod(((threadIdx.x_1*3) + 6), 9))) &amp;&amp; (floormod(((threadIdx.x_1*3) + 6), 9) &lt; 8)), data[((((cse_var_2 + (floordiv(((threadIdx.x_1*4) + 392), 27)*49)) + (floordiv(floormod(((threadIdx.x_1*4) + 14), 27), 3)*7)) + floormod(((threadIdx.x_1*3) + 6), 9)) - 8)], 0f32, dtype=float32)
          pad_temp.shared_1[((threadIdx.x_1*12) + 1177)] = @tir.if_then_else(((((3 &lt;= floormod(((threadIdx.x_1*4) + 14), 27)) &amp;&amp; (floormod(((threadIdx.x_1*12) + 43), 81) &lt; 72)) &amp;&amp; (1 &lt;= floormod(((threadIdx.x_1*3) + 7), 9))) &amp;&amp; (floormod(((threadIdx.x_1*3) + 7), 9) &lt; 8)), data[((((cse_var_2 + (floordiv(((threadIdx.x_1*4) + 392), 27)*49)) + (floordiv(floormod(((threadIdx.x_1*4) + 14), 27), 3)*7)) + floormod(((threadIdx.x_1*3) + 7), 9)) - 8)], 0f32, dtype=float32)
          pad_temp.shared_1[((threadIdx.x_1*12) + 1178)] = @tir.if_then_else(((((3 &lt;= floormod(((threadIdx.x_1*4) + 14), 27)) &amp;&amp; (floormod(((threadIdx.x_1*12) + 44), 81) &lt; 72)) &amp;&amp; (1 &lt;= floormod(((threadIdx.x_1*3) + 8), 9))) &amp;&amp; (floormod(((threadIdx.x_1*3) + 8), 9) &lt; 8)), data[((((cse_var_2 + (floordiv(((threadIdx.x_1*4) + 392), 27)*49)) + (floordiv(floormod(((threadIdx.x_1*4) + 14), 27), 3)*7)) + floormod(((threadIdx.x_1*3) + 8), 9)) - 8)], 0f32, dtype=float32)
          pad_temp.shared_1[((threadIdx.x_1*12) + 1179)] = @tir.if_then_else((((1 &lt;= floormod((floordiv((threadIdx.x_1*4), 3) + 5), 9)) &amp;&amp; (floormod(((threadIdx.x_1*12) + 45), 81) &lt; 72)) &amp;&amp; (1 &lt;= floormod(threadIdx.x_1, 3))), data[((((cse_var_2 + (floordiv(((threadIdx.x_1*4) + 393), 27)*49)) + (floormod((floordiv((threadIdx.x_1*4), 3) + 5), 9)*7)) + (floormod(threadIdx.x_1, 3)*3)) - 8)], 0f32, dtype=float32)
          pad_temp.shared_1[((threadIdx.x_1*12) + 1180)] = @tir.if_then_else(((1 &lt;= floormod((floordiv((threadIdx.x_1*4), 3) + 5), 9)) &amp;&amp; (floormod(((threadIdx.x_1*12) + 46), 81) &lt; 72)), data[((((cse_var_2 + (floordiv(((threadIdx.x_1*4) + 393), 27)*49)) + (floormod((floordiv((threadIdx.x_1*4), 3) + 5), 9)*7)) + (floormod(threadIdx.x_1, 3)*3)) - 7)], 0f32, dtype=float32)
          pad_temp.shared_1[((threadIdx.x_1*12) + 1181)] = @tir.if_then_else((((1 &lt;= floormod((floordiv((threadIdx.x_1*4), 3) + 5), 9)) &amp;&amp; (floormod(((threadIdx.x_1*12) + 47), 81) &lt; 72)) &amp;&amp; (floormod(threadIdx.x_1, 3) &lt; 2)), data[((((cse_var_2 + (floordiv(((threadIdx.x_1*4) + 393), 27)*49)) + (floormod((floordiv((threadIdx.x_1*4), 3) + 5), 9)*7)) + (floormod(threadIdx.x_1, 3)*3)) - 6)], 0f32, dtype=float32)
          pad_temp.shared_1[((threadIdx.x_1*12) + 1182)] = @tir.if_then_else(((((3 &lt;= floormod(((threadIdx.x_1*4) + 16), 27)) &amp;&amp; (floormod(((threadIdx.x_1*12) + 48), 81) &lt; 72)) &amp;&amp; (1 &lt;= floormod(((threadIdx.x_1*3) + 3), 9))) &amp;&amp; (floormod(((threadIdx.x_1*3) + 3), 9) &lt; 8)), data[((((cse_var_2 + (floordiv(((threadIdx.x_1*4) + 394), 27)*49)) + (floordiv(floormod(((threadIdx.x_1*4) + 16), 27), 3)*7)) + floormod(((threadIdx.x_1*3) + 3), 9)) - 8)], 0f32, dtype=float32)
          pad_temp.shared_1[((threadIdx.x_1*12) + 1183)] = @tir.if_then_else(((((3 &lt;= floormod(((threadIdx.x_1*4) + 16), 27)) &amp;&amp; (floormod(((threadIdx.x_1*12) + 49), 81) &lt; 72)) &amp;&amp; (1 &lt;= floormod(((threadIdx.x_1*3) + 4), 9))) &amp;&amp; (floormod(((threadIdx.x_1*3) + 4), 9) &lt; 8)), data[((((cse_var_2 + (floordiv(((threadIdx.x_1*4) + 394), 27)*49)) + (floordiv(floormod(((threadIdx.x_1*4) + 16), 27), 3)*7)) + floormod(((threadIdx.x_1*3) + 4), 9)) - 8)], 0f32, dtype=float32)
          pad_temp.shared_1[((threadIdx.x_1*12) + 1184)] = @tir.if_then_else(((((3 &lt;= floormod(((threadIdx.x_1*4) + 16), 27)) &amp;&amp; (floormod(((threadIdx.x_1*12) + 50), 81) &lt; 72)) &amp;&amp; (1 &lt;= floormod(((threadIdx.x_1*3) + 5), 9))) &amp;&amp; (floormod(((threadIdx.x_1*3) + 5), 9) &lt; 8)), data[((((cse_var_2 + (floordiv(((threadIdx.x_1*4) + 394), 27)*49)) + (floordiv(floormod(((threadIdx.x_1*4) + 16), 27), 3)*7)) + floormod(((threadIdx.x_1*3) + 5), 9)) - 8)], 0f32, dtype=float32)
          pad_temp.shared_1[((threadIdx.x_1*12) + 1185)] = @tir.if_then_else(((((1 &lt;= floormod((floordiv(((threadIdx.x_1*4) + 392), 3) + 1), 9)) &amp;&amp; (floormod(((threadIdx.x_1*12) + 51), 81) &lt; 72)) &amp;&amp; (1 &lt;= floormod(((threadIdx.x_1*3) + 6), 9))) &amp;&amp; (floormod(((threadIdx.x_1*3) + 6), 9) &lt; 8)), data[((((cse_var_2 + (floordiv(((threadIdx.x_1*4) + 395), 27)*49)) + (floormod((floordiv(((threadIdx.x_1*4) + 392), 3) + 1), 9)*7)) + floormod(((threadIdx.x_1*3) + 6), 9)) - 8)], 0f32, dtype=float32)
          pad_temp.shared_1[((threadIdx.x_1*12) + 1186)] = @tir.if_then_else(((((1 &lt;= floormod((floordiv(((threadIdx.x_1*4) + 392), 3) + 1), 9)) &amp;&amp; (floormod(((threadIdx.x_1*12) + 52), 81) &lt; 72)) &amp;&amp; (1 &lt;= floormod(((threadIdx.x_1*3) + 7), 9))) &amp;&amp; (floormod(((threadIdx.x_1*3) + 7), 9) &lt; 8)), data[((((cse_var_2 + (floordiv(((threadIdx.x_1*4) + 395), 27)*49)) + (floormod((floordiv(((threadIdx.x_1*4) + 392), 3) + 1), 9)*7)) + floormod(((threadIdx.x_1*3) + 7), 9)) - 8)], 0f32, dtype=float32)
          pad_temp.shared_1[((threadIdx.x_1*12) + 1187)] = @tir.if_then_else(((((1 &lt;= floormod((floordiv(((threadIdx.x_1*4) + 392), 3) + 1), 9)) &amp;&amp; (floormod(((threadIdx.x_1*12) + 53), 81) &lt; 72)) &amp;&amp; (1 &lt;= floormod(((threadIdx.x_1*3) + 8), 9))) &amp;&amp; (floormod(((threadIdx.x_1*3) + 8), 9) &lt; 8)), data[((((cse_var_2 + (floordiv(((threadIdx.x_1*4) + 395), 27)*49)) + (floormod((floordiv(((threadIdx.x_1*4) + 392), 3) + 1), 9)*7)) + floormod(((threadIdx.x_1*3) + 8), 9)) - 8)], 0f32, dtype=float32)
        }
        attr [IterVar(threadIdx.x_1, (nullptr), &quot;ThreadIndex&quot;, &quot;threadIdx.x&quot;)] &quot;thread_extent&quot; = 49 {
          pad_temp.shared_1[((threadIdx.x_1*12) + 1764)] = @tir.if_then_else((((1 &lt;= floormod((floordiv((threadIdx.x_1*4), 3) + 7), 9)) &amp;&amp; (floormod(((threadIdx.x_1*12) + 63), 81) &lt; 72)) &amp;&amp; (1 &lt;= floormod(threadIdx.x_1, 3))), data[((((cse_var_2 + (floordiv(((threadIdx.x_1*4) + 588), 27)*49)) + (floormod((floordiv((threadIdx.x_1*4), 3) + 7), 9)*7)) + (floormod(threadIdx.x_1, 3)*3)) - 8)], 0f32, dtype=float32)
          pad_temp.shared_1[((threadIdx.x_1*12) + 1765)] = @tir.if_then_else(((1 &lt;= floormod((floordiv((threadIdx.x_1*4), 3) + 7), 9)) &amp;&amp; (floormod(((threadIdx.x_1*12) + 64), 81) &lt; 72)), data[((((cse_var_2 + (floordiv(((threadIdx.x_1*4) + 588), 27)*49)) + (floormod((floordiv((threadIdx.x_1*4), 3) + 7), 9)*7)) + (floormod(threadIdx.x_1, 3)*3)) - 7)], 0f32, dtype=float32)
          pad_temp.shared_1[((threadIdx.x_1*12) + 1766)] = @tir.if_then_else((((1 &lt;= floormod((floordiv((threadIdx.x_1*4), 3) + 7), 9)) &amp;&amp; (floormod(((threadIdx.x_1*12) + 65), 81) &lt; 72)) &amp;&amp; (floormod(threadIdx.x_1, 3) &lt; 2)), data[((((cse_var_2 + (floordiv(((threadIdx.x_1*4) + 588), 27)*49)) + (floormod((floordiv((threadIdx.x_1*4), 3) + 7), 9)*7)) + (floormod(threadIdx.x_1, 3)*3)) - 6)], 0f32, dtype=float32)
          pad_temp.shared_1[((threadIdx.x_1*12) + 1767)] = @tir.if_then_else(((((3 &lt;= floormod(((threadIdx.x_1*4) + 22), 27)) &amp;&amp; (floormod(((threadIdx.x_1*12) + 66), 81) &lt; 72)) &amp;&amp; (1 &lt;= floormod(((threadIdx.x_1*3) + 3), 9))) &amp;&amp; (floormod(((threadIdx.x_1*3) + 3), 9) &lt; 8)), data[((((cse_var_2 + (floordiv(((threadIdx.x_1*4) + 589), 27)*49)) + (floordiv(floormod(((threadIdx.x_1*4) + 22), 27), 3)*7)) + floormod(((threadIdx.x_1*3) + 3), 9)) - 8)], 0f32, dtype=float32)
          pad_temp.shared_1[((threadIdx.x_1*12) + 1768)] = @tir.if_then_else(((((3 &lt;= floormod(((threadIdx.x_1*4) + 22), 27)) &amp;&amp; (floormod(((threadIdx.x_1*12) + 67), 81) &lt; 72)) &amp;&amp; (1 &lt;= floormod(((threadIdx.x_1*3) + 4), 9))) &amp;&amp; (floormod(((threadIdx.x_1*3) + 4), 9) &lt; 8)), data[((((cse_var_2 + (floordiv(((threadIdx.x_1*4) + 589), 27)*49)) + (floordiv(floormod(((threadIdx.x_1*4) + 22), 27), 3)*7)) + floormod(((threadIdx.x_1*3) + 4), 9)) - 8)], 0f32, dtype=float32)
          pad_temp.shared_1[((threadIdx.x_1*12) + 1769)] = @tir.if_then_else(((((3 &lt;= floormod(((threadIdx.x_1*4) + 22), 27)) &amp;&amp; (floormod(((threadIdx.x_1*12) + 68), 81) &lt; 72)) &amp;&amp; (1 &lt;= floormod(((threadIdx.x_1*3) + 5), 9))) &amp;&amp; (floormod(((threadIdx.x_1*3) + 5), 9) &lt; 8)), data[((((cse_var_2 + (floordiv(((threadIdx.x_1*4) + 589), 27)*49)) + (floordiv(floormod(((threadIdx.x_1*4) + 22), 27), 3)*7)) + floormod(((threadIdx.x_1*3) + 5), 9)) - 8)], 0f32, dtype=float32)
          pad_temp.shared_1[((threadIdx.x_1*12) + 1770)] = @tir.if_then_else(((((3 &lt;= floormod(((threadIdx.x_1*4) + 23), 27)) &amp;&amp; (floormod(((threadIdx.x_1*12) + 69), 81) &lt; 72)) &amp;&amp; (1 &lt;= floormod(((threadIdx.x_1*3) + 6), 9))) &amp;&amp; (floormod(((threadIdx.x_1*3) + 6), 9) &lt; 8)), data[((((cse_var_2 + (floordiv(((threadIdx.x_1*4) + 590), 27)*49)) + (floordiv(floormod(((threadIdx.x_1*4) + 23), 27), 3)*7)) + floormod(((threadIdx.x_1*3) + 6), 9)) - 8)], 0f32, dtype=float32)
          pad_temp.shared_1[((threadIdx.x_1*12) + 1771)] = @tir.if_then_else(((((3 &lt;= floormod(((threadIdx.x_1*4) + 23), 27)) &amp;&amp; (floormod(((threadIdx.x_1*12) + 70), 81) &lt; 72)) &amp;&amp; (1 &lt;= floormod(((threadIdx.x_1*3) + 7), 9))) &amp;&amp; (floormod(((threadIdx.x_1*3) + 7), 9) &lt; 8)), data[((((cse_var_2 + (floordiv(((threadIdx.x_1*4) + 590), 27)*49)) + (floordiv(floormod(((threadIdx.x_1*4) + 23), 27), 3)*7)) + floormod(((threadIdx.x_1*3) + 7), 9)) - 8)], 0f32, dtype=float32)
          pad_temp.shared_1[((threadIdx.x_1*12) + 1772)] = @tir.if_then_else(((((3 &lt;= floormod(((threadIdx.x_1*4) + 23), 27)) &amp;&amp; (floormod(((threadIdx.x_1*12) + 71), 81) &lt; 72)) &amp;&amp; (1 &lt;= floormod(((threadIdx.x_1*3) + 8), 9))) &amp;&amp; (floormod(((threadIdx.x_1*3) + 8), 9) &lt; 8)), data[((((cse_var_2 + (floordiv(((threadIdx.x_1*4) + 590), 27)*49)) + (floordiv(floormod(((threadIdx.x_1*4) + 23), 27), 3)*7)) + floormod(((threadIdx.x_1*3) + 8), 9)) - 8)], 0f32, dtype=float32)
          pad_temp.shared_1[((threadIdx.x_1*12) + 1773)] = @tir.if_then_else((((1 &lt;= floormod((floordiv((threadIdx.x_1*4), 3) + 8), 9)) &amp;&amp; (floormod(((threadIdx.x_1*12) + 72), 81) &lt; 72)) &amp;&amp; (1 &lt;= floormod(threadIdx.x_1, 3))), data[((((cse_var_2 + (floordiv(((threadIdx.x_1*4) + 591), 27)*49)) + (floormod((floordiv((threadIdx.x_1*4), 3) + 8), 9)*7)) + (floormod(threadIdx.x_1, 3)*3)) - 8)], 0f32, dtype=float32)
          pad_temp.shared_1[((threadIdx.x_1*12) + 1774)] = @tir.if_then_else(((1 &lt;= floormod((floordiv((threadIdx.x_1*4), 3) + 8), 9)) &amp;&amp; (floormod(((threadIdx.x_1*12) + 73), 81) &lt; 72)), data[((((cse_var_2 + (floordiv(((threadIdx.x_1*4) + 591), 27)*49)) + (floormod((floordiv((threadIdx.x_1*4), 3) + 8), 9)*7)) + (floormod(threadIdx.x_1, 3)*3)) - 7)], 0f32, dtype=float32)
          pad_temp.shared_1[((threadIdx.x_1*12) + 1775)] = @tir.if_then_else((((1 &lt;= floormod((floordiv((threadIdx.x_1*4), 3) + 8), 9)) &amp;&amp; (floormod(((threadIdx.x_1*12) + 74), 81) &lt; 72)) &amp;&amp; (floormod(threadIdx.x_1, 3) &lt; 2)), data[((((cse_var_2 + (floordiv(((threadIdx.x_1*4) + 591), 27)*49)) + (floormod((floordiv((threadIdx.x_1*4), 3) + 8), 9)*7)) + (floormod(threadIdx.x_1, 3)*3)) - 6)], 0f32, dtype=float32)
        }
        attr [IterVar(threadIdx.x_1, (nullptr), &quot;ThreadIndex&quot;, &quot;threadIdx.x&quot;)] &quot;thread_extent&quot; = 49 {
          pad_temp.shared_1[((threadIdx.x_1*12) + 2352)] = @tir.if_then_else(((((3 &lt;= floormod(((threadIdx.x_1*4) + 1), 27)) &amp;&amp; (floormod(((threadIdx.x_1*12) + 3), 81) &lt; 72)) &amp;&amp; (1 &lt;= floormod(((threadIdx.x_1*3) + 3), 9))) &amp;&amp; (floormod(((threadIdx.x_1*3) + 3), 9) &lt; 8)), data[((((cse_var_2 + (floordiv(((threadIdx.x_1*4) + 784), 27)*49)) + (floordiv(floormod(((threadIdx.x_1*4) + 1), 27), 3)*7)) + floormod(((threadIdx.x_1*3) + 3), 9)) - 8)], 0f32, dtype=float32)
          pad_temp.shared_1[((threadIdx.x_1*12) + 2353)] = @tir.if_then_else(((((3 &lt;= floormod(((threadIdx.x_1*4) + 1), 27)) &amp;&amp; (floormod(((threadIdx.x_1*12) + 4), 81) &lt; 72)) &amp;&amp; (1 &lt;= floormod(((threadIdx.x_1*3) + 4), 9))) &amp;&amp; (floormod(((threadIdx.x_1*3) + 4), 9) &lt; 8)), data[((((cse_var_2 + (floordiv(((threadIdx.x_1*4) + 784), 27)*49)) + (floordiv(floormod(((threadIdx.x_1*4) + 1), 27), 3)*7)) + floormod(((threadIdx.x_1*3) + 4), 9)) - 8)], 0f32, dtype=float32)
          pad_temp.shared_1[((threadIdx.x_1*12) + 2354)] = @tir.if_then_else(((((3 &lt;= floormod(((threadIdx.x_1*4) + 1), 27)) &amp;&amp; (floormod(((threadIdx.x_1*12) + 5), 81) &lt; 72)) &amp;&amp; (1 &lt;= floormod(((threadIdx.x_1*3) + 5), 9))) &amp;&amp; (floormod(((threadIdx.x_1*3) + 5), 9) &lt; 8)), data[((((cse_var_2 + (floordiv(((threadIdx.x_1*4) + 784), 27)*49)) + (floordiv(floormod(((threadIdx.x_1*4) + 1), 27), 3)*7)) + floormod(((threadIdx.x_1*3) + 5), 9)) - 8)], 0f32, dtype=float32)
          pad_temp.shared_1[((threadIdx.x_1*12) + 2355)] = @tir.if_then_else(((((3 &lt;= floormod(((threadIdx.x_1*4) + 2), 27)) &amp;&amp; (floormod(((threadIdx.x_1*12) + 6), 81) &lt; 72)) &amp;&amp; (1 &lt;= floormod(((threadIdx.x_1*3) + 6), 9))) &amp;&amp; (floormod(((threadIdx.x_1*3) + 6), 9) &lt; 8)), data[((((cse_var_2 + (floordiv(((threadIdx.x_1*4) + 785), 27)*49)) + (floordiv(floormod(((threadIdx.x_1*4) + 2), 27), 3)*7)) + floormod(((threadIdx.x_1*3) + 6), 9)) - 8)], 0f32, dtype=float32)
          pad_temp.shared_1[((threadIdx.x_1*12) + 2356)] = @tir.if_then_else(((((3 &lt;= floormod(((threadIdx.x_1*4) + 2), 27)) &amp;&amp; (floormod(((threadIdx.x_1*12) + 7), 81) &lt; 72)) &amp;&amp; (1 &lt;= floormod(((threadIdx.x_1*3) + 7), 9))) &amp;&amp; (floormod(((threadIdx.x_1*3) + 7), 9) &lt; 8)), data[((((cse_var_2 + (floordiv(((threadIdx.x_1*4) + 785), 27)*49)) + (floordiv(floormod(((threadIdx.x_1*4) + 2), 27), 3)*7)) + floormod(((threadIdx.x_1*3) + 7), 9)) - 8)], 0f32, dtype=float32)
          pad_temp.shared_1[((threadIdx.x_1*12) + 2357)] = @tir.if_then_else(((((3 &lt;= floormod(((threadIdx.x_1*4) + 2), 27)) &amp;&amp; (floormod(((threadIdx.x_1*12) + 8), 81) &lt; 72)) &amp;&amp; (1 &lt;= floormod(((threadIdx.x_1*3) + 8), 9))) &amp;&amp; (floormod(((threadIdx.x_1*3) + 8), 9) &lt; 8)), data[((((cse_var_2 + (floordiv(((threadIdx.x_1*4) + 785), 27)*49)) + (floordiv(floormod(((threadIdx.x_1*4) + 2), 27), 3)*7)) + floormod(((threadIdx.x_1*3) + 8), 9)) - 8)], 0f32, dtype=float32)
          pad_temp.shared_1[((threadIdx.x_1*12) + 2358)] = @tir.if_then_else((((1 &lt;= floormod((floordiv((threadIdx.x_1*4), 3) + 1), 9)) &amp;&amp; (floormod(((threadIdx.x_1*12) + 9), 81) &lt; 72)) &amp;&amp; (1 &lt;= floormod(threadIdx.x_1, 3))), data[((((cse_var_2 + (floordiv(((threadIdx.x_1*4) + 786), 27)*49)) + (floormod((floordiv((threadIdx.x_1*4), 3) + 1), 9)*7)) + (floormod(threadIdx.x_1, 3)*3)) - 8)], 0f32, dtype=float32)
          pad_temp.shared_1[((threadIdx.x_1*12) + 2359)] = @tir.if_then_else(((1 &lt;= floormod((floordiv((threadIdx.x_1*4), 3) + 1), 9)) &amp;&amp; (floormod(((threadIdx.x_1*12) + 10), 81) &lt; 72)), data[((((cse_var_2 + (floordiv(((threadIdx.x_1*4) + 786), 27)*49)) + (floormod((floordiv((threadIdx.x_1*4), 3) + 1), 9)*7)) + (floormod(threadIdx.x_1, 3)*3)) - 7)], 0f32, dtype=float32)
          pad_temp.shared_1[((threadIdx.x_1*12) + 2360)] = @tir.if_then_else((((1 &lt;= floormod((floordiv((threadIdx.x_1*4), 3) + 1), 9)) &amp;&amp; (floormod(((threadIdx.x_1*12) + 11), 81) &lt; 72)) &amp;&amp; (floormod(threadIdx.x_1, 3) &lt; 2)), data[((((cse_var_2 + (floordiv(((threadIdx.x_1*4) + 786), 27)*49)) + (floormod((floordiv((threadIdx.x_1*4), 3) + 1), 9)*7)) + (floormod(threadIdx.x_1, 3)*3)) - 6)], 0f32, dtype=float32)
          pad_temp.shared_1[((threadIdx.x_1*12) + 2361)] = @tir.if_then_else(((((1 &lt;= floormod((floordiv(((threadIdx.x_1*4) + 784), 3) + 1), 9)) &amp;&amp; (floormod(((threadIdx.x_1*12) + 12), 81) &lt; 72)) &amp;&amp; (1 &lt;= floormod(((threadIdx.x_1*3) + 3), 9))) &amp;&amp; (floormod(((threadIdx.x_1*3) + 3), 9) &lt; 8)), data[((((cse_var_2 + (floordiv(((threadIdx.x_1*4) + 787), 27)*49)) + (floormod((floordiv(((threadIdx.x_1*4) + 784), 3) + 1), 9)*7)) + floormod(((threadIdx.x_1*3) + 3), 9)) - 8)], 0f32, dtype=float32)
          pad_temp.shared_1[((threadIdx.x_1*12) + 2362)] = @tir.if_then_else(((((1 &lt;= floormod((floordiv(((threadIdx.x_1*4) + 784), 3) + 1), 9)) &amp;&amp; (floormod(((threadIdx.x_1*12) + 13), 81) &lt; 72)) &amp;&amp; (1 &lt;= floormod(((threadIdx.x_1*3) + 4), 9))) &amp;&amp; (floormod(((threadIdx.x_1*3) + 4), 9) &lt; 8)), data[((((cse_var_2 + (floordiv(((threadIdx.x_1*4) + 787), 27)*49)) + (floormod((floordiv(((threadIdx.x_1*4) + 784), 3) + 1), 9)*7)) + floormod(((threadIdx.x_1*3) + 4), 9)) - 8)], 0f32, dtype=float32)
          pad_temp.shared_1[((threadIdx.x_1*12) + 2363)] = @tir.if_then_else(((((1 &lt;= floormod((floordiv(((threadIdx.x_1*4) + 784), 3) + 1), 9)) &amp;&amp; (floormod(((threadIdx.x_1*12) + 14), 81) &lt; 72)) &amp;&amp; (1 &lt;= floormod(((threadIdx.x_1*3) + 5), 9))) &amp;&amp; (floormod(((threadIdx.x_1*3) + 5), 9) &lt; 8)), data[((((cse_var_2 + (floordiv(((threadIdx.x_1*4) + 787), 27)*49)) + (floormod((floordiv(((threadIdx.x_1*4) + 784), 3) + 1), 9)*7)) + floormod(((threadIdx.x_1*3) + 5), 9)) - 8)], 0f32, dtype=float32)
        }
        attr [IterVar(threadIdx.x_1, (nullptr), &quot;ThreadIndex&quot;, &quot;threadIdx.x&quot;)] &quot;thread_extent&quot; = 49 {
          pad_temp.shared_1[((threadIdx.x_1*12) + 2940)] = @tir.if_then_else(((((3 &lt;= floormod(((threadIdx.x_1*4) + 8), 27)) &amp;&amp; (floormod(((threadIdx.x_1*12) + 24), 81) &lt; 72)) &amp;&amp; (1 &lt;= floormod(((threadIdx.x_1*3) + 6), 9))) &amp;&amp; (floormod(((threadIdx.x_1*3) + 6), 9) &lt; 8)), data[((((cse_var_2 + (floordiv(((threadIdx.x_1*4) + 980), 27)*49)) + (floordiv(floormod(((threadIdx.x_1*4) + 8), 27), 3)*7)) + floormod(((threadIdx.x_1*3) + 6), 9)) - 8)], 0f32, dtype=float32)
          pad_temp.shared_1[((threadIdx.x_1*12) + 2941)] = @tir.if_then_else(((((3 &lt;= floormod(((threadIdx.x_1*4) + 8), 27)) &amp;&amp; (floormod(((threadIdx.x_1*12) + 25), 81) &lt; 72)) &amp;&amp; (1 &lt;= floormod(((threadIdx.x_1*3) + 7), 9))) &amp;&amp; (floormod(((threadIdx.x_1*3) + 7), 9) &lt; 8)), data[((((cse_var_2 + (floordiv(((threadIdx.x_1*4) + 980), 27)*49)) + (floordiv(floormod(((threadIdx.x_1*4) + 8), 27), 3)*7)) + floormod(((threadIdx.x_1*3) + 7), 9)) - 8)], 0f32, dtype=float32)
          pad_temp.shared_1[((threadIdx.x_1*12) + 2942)] = @tir.if_then_else(((((3 &lt;= floormod(((threadIdx.x_1*4) + 8), 27)) &amp;&amp; (floormod(((threadIdx.x_1*12) + 26), 81) &lt; 72)) &amp;&amp; (1 &lt;= floormod(((threadIdx.x_1*3) + 8), 9))) &amp;&amp; (floormod(((threadIdx.x_1*3) + 8), 9) &lt; 8)), data[((((cse_var_2 + (floordiv(((threadIdx.x_1*4) + 980), 27)*49)) + (floordiv(floormod(((threadIdx.x_1*4) + 8), 27), 3)*7)) + floormod(((threadIdx.x_1*3) + 8), 9)) - 8)], 0f32, dtype=float32)
          pad_temp.shared_1[((threadIdx.x_1*12) + 2943)] = @tir.if_then_else((((1 &lt;= floormod((floordiv((threadIdx.x_1*4), 3) + 3), 9)) &amp;&amp; (floormod(((threadIdx.x_1*12) + 27), 81) &lt; 72)) &amp;&amp; (1 &lt;= floormod(threadIdx.x_1, 3))), data[((((cse_var_2 + (floordiv(((threadIdx.x_1*4) + 981), 27)*49)) + (floormod((floordiv((threadIdx.x_1*4), 3) + 3), 9)*7)) + (floormod(threadIdx.x_1, 3)*3)) - 8)], 0f32, dtype=float32)
          pad_temp.shared_1[((threadIdx.x_1*12) + 2944)] = @tir.if_then_else(((1 &lt;= floormod((floordiv((threadIdx.x_1*4), 3) + 3), 9)) &amp;&amp; (floormod(((threadIdx.x_1*12) + 28), 81) &lt; 72)), data[((((cse_var_2 + (floordiv(((threadIdx.x_1*4) + 981), 27)*49)) + (floormod((floordiv((threadIdx.x_1*4), 3) + 3), 9)*7)) + (floormod(threadIdx.x_1, 3)*3)) - 7)], 0f32, dtype=float32)
          pad_temp.shared_1[((threadIdx.x_1*12) + 2945)] = @tir.if_then_else((((1 &lt;= floormod((floordiv((threadIdx.x_1*4), 3) + 3), 9)) &amp;&amp; (floormod(((threadIdx.x_1*12) + 29), 81) &lt; 72)) &amp;&amp; (floormod(threadIdx.x_1, 3) &lt; 2)), data[((((cse_var_2 + (floordiv(((threadIdx.x_1*4) + 981), 27)*49)) + (floormod((floordiv((threadIdx.x_1*4), 3) + 3), 9)*7)) + (floormod(threadIdx.x_1, 3)*3)) - 6)], 0f32, dtype=float32)
          pad_temp.shared_1[((threadIdx.x_1*12) + 2946)] = @tir.if_then_else(((((3 &lt;= floormod(((threadIdx.x_1*4) + 10), 27)) &amp;&amp; (floormod(((threadIdx.x_1*12) + 30), 81) &lt; 72)) &amp;&amp; (1 &lt;= floormod(((threadIdx.x_1*3) + 3), 9))) &amp;&amp; (floormod(((threadIdx.x_1*3) + 3), 9) &lt; 8)), data[((((cse_var_2 + (floordiv(((threadIdx.x_1*4) + 982), 27)*49)) + (floordiv(floormod(((threadIdx.x_1*4) + 10), 27), 3)*7)) + floormod(((threadIdx.x_1*3) + 3), 9)) - 8)], 0f32, dtype=float32)
          pad_temp.shared_1[((threadIdx.x_1*12) + 2947)] = @tir.if_then_else(((((3 &lt;= floormod(((threadIdx.x_1*4) + 10), 27)) &amp;&amp; (floormod(((threadIdx.x_1*12) + 31), 81) &lt; 72)) &amp;&amp; (1 &lt;= floormod(((threadIdx.x_1*3) + 4), 9))) &amp;&amp; (floormod(((threadIdx.x_1*3) + 4), 9) &lt; 8)), data[((((cse_var_2 + (floordiv(((threadIdx.x_1*4) + 982), 27)*49)) + (floordiv(floormod(((threadIdx.x_1*4) + 10), 27), 3)*7)) + floormod(((threadIdx.x_1*3) + 4), 9)) - 8)], 0f32, dtype=float32)
          pad_temp.shared_1[((threadIdx.x_1*12) + 2948)] = @tir.if_then_else(((((3 &lt;= floormod(((threadIdx.x_1*4) + 10), 27)) &amp;&amp; (floormod(((threadIdx.x_1*12) + 32), 81) &lt; 72)) &amp;&amp; (1 &lt;= floormod(((threadIdx.x_1*3) + 5), 9))) &amp;&amp; (floormod(((threadIdx.x_1*3) + 5), 9) &lt; 8)), data[((((cse_var_2 + (floordiv(((threadIdx.x_1*4) + 982), 27)*49)) + (floordiv(floormod(((threadIdx.x_1*4) + 10), 27), 3)*7)) + floormod(((threadIdx.x_1*3) + 5), 9)) - 8)], 0f32, dtype=float32)
          pad_temp.shared_1[((threadIdx.x_1*12) + 2949)] = @tir.if_then_else(((((1 &lt;= floormod((floordiv(((threadIdx.x_1*4) + 980), 3) + 1), 9)) &amp;&amp; (floormod(((threadIdx.x_1*12) + 33), 81) &lt; 72)) &amp;&amp; (1 &lt;= floormod(((threadIdx.x_1*3) + 6), 9))) &amp;&amp; (floormod(((threadIdx.x_1*3) + 6), 9) &lt; 8)), data[((((cse_var_2 + (floordiv(((threadIdx.x_1*4) + 983), 27)*49)) + (floormod((floordiv(((threadIdx.x_1*4) + 980), 3) + 1), 9)*7)) + floormod(((threadIdx.x_1*3) + 6), 9)) - 8)], 0f32, dtype=float32)
          pad_temp.shared_1[((threadIdx.x_1*12) + 2950)] = @tir.if_then_else(((((1 &lt;= floormod((floordiv(((threadIdx.x_1*4) + 980), 3) + 1), 9)) &amp;&amp; (floormod(((threadIdx.x_1*12) + 34), 81) &lt; 72)) &amp;&amp; (1 &lt;= floormod(((threadIdx.x_1*3) + 7), 9))) &amp;&amp; (floormod(((threadIdx.x_1*3) + 7), 9) &lt; 8)), data[((((cse_var_2 + (floordiv(((threadIdx.x_1*4) + 983), 27)*49)) + (floormod((floordiv(((threadIdx.x_1*4) + 980), 3) + 1), 9)*7)) + floormod(((threadIdx.x_1*3) + 7), 9)) - 8)], 0f32, dtype=float32)
          pad_temp.shared_1[((threadIdx.x_1*12) + 2951)] = @tir.if_then_else(((((1 &lt;= floormod((floordiv(((threadIdx.x_1*4) + 980), 3) + 1), 9)) &amp;&amp; (floormod(((threadIdx.x_1*12) + 35), 81) &lt; 72)) &amp;&amp; (1 &lt;= floormod(((threadIdx.x_1*3) + 8), 9))) &amp;&amp; (floormod(((threadIdx.x_1*3) + 8), 9) &lt; 8)), data[((((cse_var_2 + (floordiv(((threadIdx.x_1*4) + 983), 27)*49)) + (floormod((floordiv(((threadIdx.x_1*4) + 980), 3) + 1), 9)*7)) + floormod(((threadIdx.x_1*3) + 8), 9)) - 8)], 0f32, dtype=float32)
        }
        attr [IterVar(threadIdx.x_1, (nullptr), &quot;ThreadIndex&quot;, &quot;threadIdx.x&quot;)] &quot;thread_extent&quot; = 49 {
          pad_temp.shared_1[((threadIdx.x_1*12) + 3528)] = @tir.if_then_else((((1 &lt;= floormod((floordiv((threadIdx.x_1*4), 3) + 5), 9)) &amp;&amp; (floormod(((threadIdx.x_1*12) + 45), 81) &lt; 72)) &amp;&amp; (1 &lt;= floormod(threadIdx.x_1, 3))), data[((((cse_var_2 + (floordiv(((threadIdx.x_1*4) + 1176), 27)*49)) + (floormod((floordiv((threadIdx.x_1*4), 3) + 5), 9)*7)) + (floormod(threadIdx.x_1, 3)*3)) - 8)], 0f32, dtype=float32)
          pad_temp.shared_1[((threadIdx.x_1*12) + 3529)] = @tir.if_then_else(((1 &lt;= floormod((floordiv((threadIdx.x_1*4), 3) + 5), 9)) &amp;&amp; (floormod(((threadIdx.x_1*12) + 46), 81) &lt; 72)), data[((((cse_var_2 + (floordiv(((threadIdx.x_1*4) + 1176), 27)*49)) + (floormod((floordiv((threadIdx.x_1*4), 3) + 5), 9)*7)) + (floormod(threadIdx.x_1, 3)*3)) - 7)], 0f32, dtype=float32)
          pad_temp.shared_1[((threadIdx.x_1*12) + 3530)] = @tir.if_then_else((((1 &lt;= floormod((floordiv((threadIdx.x_1*4), 3) + 5), 9)) &amp;&amp; (floormod(((threadIdx.x_1*12) + 47), 81) &lt; 72)) &amp;&amp; (floormod(threadIdx.x_1, 3) &lt; 2)), data[((((cse_var_2 + (floordiv(((threadIdx.x_1*4) + 1176), 27)*49)) + (floormod((floordiv((threadIdx.x_1*4), 3) + 5), 9)*7)) + (floormod(threadIdx.x_1, 3)*3)) - 6)], 0f32, dtype=float32)
          pad_temp.shared_1[((threadIdx.x_1*12) + 3531)] = @tir.if_then_else(((((3 &lt;= floormod(((threadIdx.x_1*4) + 16), 27)) &amp;&amp; (floormod(((threadIdx.x_1*12) + 48), 81) &lt; 72)) &amp;&amp; (1 &lt;= floormod(((threadIdx.x_1*3) + 3), 9))) &amp;&amp; (floormod(((threadIdx.x_1*3) + 3), 9) &lt; 8)), data[((((cse_var_2 + (floordiv(((threadIdx.x_1*4) + 1177), 27)*49)) + (floordiv(floormod(((threadIdx.x_1*4) + 16), 27), 3)*7)) + floormod(((threadIdx.x_1*3) + 3), 9)) - 8)], 0f32, dtype=float32)
          pad_temp.shared_1[((threadIdx.x_1*12) + 3532)] = @tir.if_then_else(((((3 &lt;= floormod(((threadIdx.x_1*4) + 16), 27)) &amp;&amp; (floormod(((threadIdx.x_1*12) + 49), 81) &lt; 72)) &amp;&amp; (1 &lt;= floormod(((threadIdx.x_1*3) + 4), 9))) &amp;&amp; (floormod(((threadIdx.x_1*3) + 4), 9) &lt; 8)), data[((((cse_var_2 + (floordiv(((threadIdx.x_1*4) + 1177), 27)*49)) + (floordiv(floormod(((threadIdx.x_1*4) + 16), 27), 3)*7)) + floormod(((threadIdx.x_1*3) + 4), 9)) - 8)], 0f32, dtype=float32)
          pad_temp.shared_1[((threadIdx.x_1*12) + 3533)] = @tir.if_then_else(((((3 &lt;= floormod(((threadIdx.x_1*4) + 16), 27)) &amp;&amp; (floormod(((threadIdx.x_1*12) + 50), 81) &lt; 72)) &amp;&amp; (1 &lt;= floormod(((threadIdx.x_1*3) + 5), 9))) &amp;&amp; (floormod(((threadIdx.x_1*3) + 5), 9) &lt; 8)), data[((((cse_var_2 + (floordiv(((threadIdx.x_1*4) + 1177), 27)*49)) + (floordiv(floormod(((threadIdx.x_1*4) + 16), 27), 3)*7)) + floormod(((threadIdx.x_1*3) + 5), 9)) - 8)], 0f32, dtype=float32)
          pad_temp.shared_1[((threadIdx.x_1*12) + 3534)] = @tir.if_then_else(((((3 &lt;= floormod(((threadIdx.x_1*4) + 17), 27)) &amp;&amp; (floormod(((threadIdx.x_1*12) + 51), 81) &lt; 72)) &amp;&amp; (1 &lt;= floormod(((threadIdx.x_1*3) + 6), 9))) &amp;&amp; (floormod(((threadIdx.x_1*3) + 6), 9) &lt; 8)), data[((((cse_var_2 + (floordiv(((threadIdx.x_1*4) + 1178), 27)*49)) + (floordiv(floormod(((threadIdx.x_1*4) + 17), 27), 3)*7)) + floormod(((threadIdx.x_1*3) + 6), 9)) - 8)], 0f32, dtype=float32)
          pad_temp.shared_1[((threadIdx.x_1*12) + 3535)] = @tir.if_then_else(((((3 &lt;= floormod(((threadIdx.x_1*4) + 17), 27)) &amp;&amp; (floormod(((threadIdx.x_1*12) + 52), 81) &lt; 72)) &amp;&amp; (1 &lt;= floormod(((threadIdx.x_1*3) + 7), 9))) &amp;&amp; (floormod(((threadIdx.x_1*3) + 7), 9) &lt; 8)), data[((((cse_var_2 + (floordiv(((threadIdx.x_1*4) + 1178), 27)*49)) + (floordiv(floormod(((threadIdx.x_1*4) + 17), 27), 3)*7)) + floormod(((threadIdx.x_1*3) + 7), 9)) - 8)], 0f32, dtype=float32)
          pad_temp.shared_1[((threadIdx.x_1*12) + 3536)] = @tir.if_then_else(((((3 &lt;= floormod(((threadIdx.x_1*4) + 17), 27)) &amp;&amp; (floormod(((threadIdx.x_1*12) + 53), 81) &lt; 72)) &amp;&amp; (1 &lt;= floormod(((threadIdx.x_1*3) + 8), 9))) &amp;&amp; (floormod(((threadIdx.x_1*3) + 8), 9) &lt; 8)), data[((((cse_var_2 + (floordiv(((threadIdx.x_1*4) + 1178), 27)*49)) + (floordiv(floormod(((threadIdx.x_1*4) + 17), 27), 3)*7)) + floormod(((threadIdx.x_1*3) + 8), 9)) - 8)], 0f32, dtype=float32)
          pad_temp.shared_1[((threadIdx.x_1*12) + 3537)] = @tir.if_then_else((((1 &lt;= floormod((floordiv((threadIdx.x_1*4), 3) + 6), 9)) &amp;&amp; (floormod(((threadIdx.x_1*12) + 54), 81) &lt; 72)) &amp;&amp; (1 &lt;= floormod(threadIdx.x_1, 3))), data[((((cse_var_2 + (floordiv(((threadIdx.x_1*4) + 1179), 27)*49)) + (floormod((floordiv((threadIdx.x_1*4), 3) + 6), 9)*7)) + (floormod(threadIdx.x_1, 3)*3)) - 8)], 0f32, dtype=float32)
          pad_temp.shared_1[((threadIdx.x_1*12) + 3538)] = @tir.if_then_else(((1 &lt;= floormod((floordiv((threadIdx.x_1*4), 3) + 6), 9)) &amp;&amp; (floormod(((threadIdx.x_1*12) + 55), 81) &lt; 72)), data[((((cse_var_2 + (floordiv(((threadIdx.x_1*4) + 1179), 27)*49)) + (floormod((floordiv((threadIdx.x_1*4), 3) + 6), 9)*7)) + (floormod(threadIdx.x_1, 3)*3)) - 7)], 0f32, dtype=float32)
          pad_temp.shared_1[((threadIdx.x_1*12) + 3539)] = @tir.if_then_else((((1 &lt;= floormod((floordiv((threadIdx.x_1*4), 3) + 6), 9)) &amp;&amp; (floormod(((threadIdx.x_1*12) + 56), 81) &lt; 72)) &amp;&amp; (floormod(threadIdx.x_1, 3) &lt; 2)), data[((((cse_var_2 + (floordiv(((threadIdx.x_1*4) + 1179), 27)*49)) + (floormod((floordiv((threadIdx.x_1*4), 3) + 6), 9)*7)) + (floormod(threadIdx.x_1, 3)*3)) - 6)], 0f32, dtype=float32)
        }
        attr [IterVar(threadIdx.x_1, (nullptr), &quot;ThreadIndex&quot;, &quot;threadIdx.x&quot;)] &quot;thread_extent&quot; = 49 {
          pad_temp.shared_1[((threadIdx.x_1*12) + 4116)] = @tir.if_then_else(((((3 &lt;= floormod(((threadIdx.x_1*4) + 22), 27)) &amp;&amp; (floormod(((threadIdx.x_1*12) + 66), 81) &lt; 72)) &amp;&amp; (1 &lt;= floormod(((threadIdx.x_1*3) + 3), 9))) &amp;&amp; (floormod(((threadIdx.x_1*3) + 3), 9) &lt; 8)), data[((((cse_var_2 + (floordiv(((threadIdx.x_1*4) + 1372), 27)*49)) + (floordiv(floormod(((threadIdx.x_1*4) + 22), 27), 3)*7)) + floormod(((threadIdx.x_1*3) + 3), 9)) - 8)], 0f32, dtype=float32)
          pad_temp.shared_1[((threadIdx.x_1*12) + 4117)] = @tir.if_then_else(((((3 &lt;= floormod(((threadIdx.x_1*4) + 22), 27)) &amp;&amp; (floormod(((threadIdx.x_1*12) + 67), 81) &lt; 72)) &amp;&amp; (1 &lt;= floormod(((threadIdx.x_1*3) + 4), 9))) &amp;&amp; (floormod(((threadIdx.x_1*3) + 4), 9) &lt; 8)), data[((((cse_var_2 + (floordiv(((threadIdx.x_1*4) + 1372), 27)*49)) + (floordiv(floormod(((threadIdx.x_1*4) + 22), 27), 3)*7)) + floormod(((threadIdx.x_1*3) + 4), 9)) - 8)], 0f32, dtype=float32)
          pad_temp.shared_1[((threadIdx.x_1*12) + 4118)] = @tir.if_then_else(((((3 &lt;= floormod(((threadIdx.x_1*4) + 22), 27)) &amp;&amp; (floormod(((threadIdx.x_1*12) + 68), 81) &lt; 72)) &amp;&amp; (1 &lt;= floormod(((threadIdx.x_1*3) + 5), 9))) &amp;&amp; (floormod(((threadIdx.x_1*3) + 5), 9) &lt; 8)), data[((((cse_var_2 + (floordiv(((threadIdx.x_1*4) + 1372), 27)*49)) + (floordiv(floormod(((threadIdx.x_1*4) + 22), 27), 3)*7)) + floormod(((threadIdx.x_1*3) + 5), 9)) - 8)], 0f32, dtype=float32)
          pad_temp.shared_1[((threadIdx.x_1*12) + 4119)] = @tir.if_then_else(((((3 &lt;= floormod(((threadIdx.x_1*4) + 23), 27)) &amp;&amp; (floormod(((threadIdx.x_1*12) + 69), 81) &lt; 72)) &amp;&amp; (1 &lt;= floormod(((threadIdx.x_1*3) + 6), 9))) &amp;&amp; (floormod(((threadIdx.x_1*3) + 6), 9) &lt; 8)), data[((((cse_var_2 + (floordiv(((threadIdx.x_1*4) + 1373), 27)*49)) + (floordiv(floormod(((threadIdx.x_1*4) + 23), 27), 3)*7)) + floormod(((threadIdx.x_1*3) + 6), 9)) - 8)], 0f32, dtype=float32)
          pad_temp.shared_1[((threadIdx.x_1*12) + 4120)] = @tir.if_then_else(((((3 &lt;= floormod(((threadIdx.x_1*4) + 23), 27)) &amp;&amp; (floormod(((threadIdx.x_1*12) + 70), 81) &lt; 72)) &amp;&amp; (1 &lt;= floormod(((threadIdx.x_1*3) + 7), 9))) &amp;&amp; (floormod(((threadIdx.x_1*3) + 7), 9) &lt; 8)), data[((((cse_var_2 + (floordiv(((threadIdx.x_1*4) + 1373), 27)*49)) + (floordiv(floormod(((threadIdx.x_1*4) + 23), 27), 3)*7)) + floormod(((threadIdx.x_1*3) + 7), 9)) - 8)], 0f32, dtype=float32)
          pad_temp.shared_1[((threadIdx.x_1*12) + 4121)] = @tir.if_then_else(((((3 &lt;= floormod(((threadIdx.x_1*4) + 23), 27)) &amp;&amp; (floormod(((threadIdx.x_1*12) + 71), 81) &lt; 72)) &amp;&amp; (1 &lt;= floormod(((threadIdx.x_1*3) + 8), 9))) &amp;&amp; (floormod(((threadIdx.x_1*3) + 8), 9) &lt; 8)), data[((((cse_var_2 + (floordiv(((threadIdx.x_1*4) + 1373), 27)*49)) + (floordiv(floormod(((threadIdx.x_1*4) + 23), 27), 3)*7)) + floormod(((threadIdx.x_1*3) + 8), 9)) - 8)], 0f32, dtype=float32)
          pad_temp.shared_1[((threadIdx.x_1*12) + 4122)] = @tir.if_then_else((((1 &lt;= floormod((floordiv((threadIdx.x_1*4), 3) + 8), 9)) &amp;&amp; (floormod(((threadIdx.x_1*12) + 72), 81) &lt; 72)) &amp;&amp; (1 &lt;= floormod(threadIdx.x_1, 3))), data[((((cse_var_2 + (floordiv(((threadIdx.x_1*4) + 1374), 27)*49)) + (floormod((floordiv((threadIdx.x_1*4), 3) + 8), 9)*7)) + (floormod(threadIdx.x_1, 3)*3)) - 8)], 0f32, dtype=float32)
          pad_temp.shared_1[((threadIdx.x_1*12) + 4123)] = @tir.if_then_else(((1 &lt;= floormod((floordiv((threadIdx.x_1*4), 3) + 8), 9)) &amp;&amp; (floormod(((threadIdx.x_1*12) + 73), 81) &lt; 72)), data[((((cse_var_2 + (floordiv(((threadIdx.x_1*4) + 1374), 27)*49)) + (floormod((floordiv((threadIdx.x_1*4), 3) + 8), 9)*7)) + (floormod(threadIdx.x_1, 3)*3)) - 7)], 0f32, dtype=float32)
          pad_temp.shared_1[((threadIdx.x_1*12) + 4124)] = @tir.if_then_else((((1 &lt;= floormod((floordiv((threadIdx.x_1*4), 3) + 8), 9)) &amp;&amp; (floormod(((threadIdx.x_1*12) + 74), 81) &lt; 72)) &amp;&amp; (floormod(threadIdx.x_1, 3) &lt; 2)), data[((((cse_var_2 + (floordiv(((threadIdx.x_1*4) + 1374), 27)*49)) + (floormod((floordiv((threadIdx.x_1*4), 3) + 8), 9)*7)) + (floormod(threadIdx.x_1, 3)*3)) - 6)], 0f32, dtype=float32)
          pad_temp.shared_1[((threadIdx.x_1*12) + 4125)] = @tir.if_then_else(((((1 &lt;= floormod((floordiv(((threadIdx.x_1*4) + 1372), 3) + 1), 9)) &amp;&amp; (floormod(((threadIdx.x_1*12) + 75), 81) &lt; 72)) &amp;&amp; (1 &lt;= floormod(((threadIdx.x_1*3) + 3), 9))) &amp;&amp; (floormod(((threadIdx.x_1*3) + 3), 9) &lt; 8)), data[((((cse_var_2 + (floordiv(((threadIdx.x_1*4) + 1375), 27)*49)) + (floormod((floordiv(((threadIdx.x_1*4) + 1372), 3) + 1), 9)*7)) + floormod(((threadIdx.x_1*3) + 3), 9)) - 8)], 0f32, dtype=float32)
          pad_temp.shared_1[((threadIdx.x_1*12) + 4126)] = @tir.if_then_else(((((1 &lt;= floormod((floordiv(((threadIdx.x_1*4) + 1372), 3) + 1), 9)) &amp;&amp; (floormod(((threadIdx.x_1*12) + 76), 81) &lt; 72)) &amp;&amp; (1 &lt;= floormod(((threadIdx.x_1*3) + 4), 9))) &amp;&amp; (floormod(((threadIdx.x_1*3) + 4), 9) &lt; 8)), data[((((cse_var_2 + (floordiv(((threadIdx.x_1*4) + 1375), 27)*49)) + (floormod((floordiv(((threadIdx.x_1*4) + 1372), 3) + 1), 9)*7)) + floormod(((threadIdx.x_1*3) + 4), 9)) - 8)], 0f32, dtype=float32)
          pad_temp.shared_1[((threadIdx.x_1*12) + 4127)] = @tir.if_then_else(((((1 &lt;= floormod((floordiv(((threadIdx.x_1*4) + 1372), 3) + 1), 9)) &amp;&amp; (floormod(((threadIdx.x_1*12) + 77), 81) &lt; 72)) &amp;&amp; (1 &lt;= floormod(((threadIdx.x_1*3) + 5), 9))) &amp;&amp; (floormod(((threadIdx.x_1*3) + 5), 9) &lt; 8)), data[((((cse_var_2 + (floordiv(((threadIdx.x_1*4) + 1375), 27)*49)) + (floormod((floordiv(((threadIdx.x_1*4) + 1372), 3) + 1), 9)*7)) + floormod(((threadIdx.x_1*3) + 5), 9)) - 8)], 0f32, dtype=float32)
        }
        attr [IterVar(threadIdx.x_1, (nullptr), &quot;ThreadIndex&quot;, &quot;threadIdx.x&quot;)] &quot;thread_extent&quot; = 49 {
          if @tir.likely((threadIdx.x_1 &lt; 40), dtype=bool) {
            pad_temp.shared_1[((threadIdx.x_1*12) + 4704)] = @tir.if_then_else(((((3 &lt;= floormod(((threadIdx.x_1*4) + 2), 27)) &amp;&amp; (floormod(((threadIdx.x_1*12) + 6), 81) &lt; 72)) &amp;&amp; (1 &lt;= floormod(((threadIdx.x_1*3) + 6), 9))) &amp;&amp; (floormod(((threadIdx.x_1*3) + 6), 9) &lt; 8)), data[((((cse_var_2 + (floordiv(((threadIdx.x_1*4) + 1568), 27)*49)) + (floordiv(floormod(((threadIdx.x_1*4) + 2), 27), 3)*7)) + floormod(((threadIdx.x_1*3) + 6), 9)) - 8)], 0f32, dtype=float32)
          }
          if @tir.likely((threadIdx.x_1 &lt; 40), dtype=bool) {
            pad_temp.shared_1[((threadIdx.x_1*12) + 4705)] = @tir.if_then_else(((((3 &lt;= floormod(((threadIdx.x_1*4) + 2), 27)) &amp;&amp; (floormod(((threadIdx.x_1*12) + 7), 81) &lt; 72)) &amp;&amp; (1 &lt;= floormod(((threadIdx.x_1*3) + 7), 9))) &amp;&amp; (floormod(((threadIdx.x_1*3) + 7), 9) &lt; 8)), data[((((cse_var_2 + (floordiv(((threadIdx.x_1*4) + 1568), 27)*49)) + (floordiv(floormod(((threadIdx.x_1*4) + 2), 27), 3)*7)) + floormod(((threadIdx.x_1*3) + 7), 9)) - 8)], 0f32, dtype=float32)
          }
          if @tir.likely((threadIdx.x_1 &lt; 40), dtype=bool) {
            pad_temp.shared_1[((threadIdx.x_1*12) + 4706)] = @tir.if_then_else(((((3 &lt;= floormod(((threadIdx.x_1*4) + 2), 27)) &amp;&amp; (floormod(((threadIdx.x_1*12) + 8), 81) &lt; 72)) &amp;&amp; (1 &lt;= floormod(((threadIdx.x_1*3) + 8), 9))) &amp;&amp; (floormod(((threadIdx.x_1*3) + 8), 9) &lt; 8)), data[((((cse_var_2 + (floordiv(((threadIdx.x_1*4) + 1568), 27)*49)) + (floordiv(floormod(((threadIdx.x_1*4) + 2), 27), 3)*7)) + floormod(((threadIdx.x_1*3) + 8), 9)) - 8)], 0f32, dtype=float32)
          }
          if @tir.likely((threadIdx.x_1 &lt; 40), dtype=bool) {
            pad_temp.shared_1[((threadIdx.x_1*12) + 4707)] = @tir.if_then_else((((1 &lt;= floormod((floordiv((threadIdx.x_1*4), 3) + 1), 9)) &amp;&amp; (floormod(((threadIdx.x_1*12) + 9), 81) &lt; 72)) &amp;&amp; (1 &lt;= floormod(threadIdx.x_1, 3))), data[((((cse_var_2 + (floordiv(((threadIdx.x_1*4) + 1569), 27)*49)) + (floormod((floordiv((threadIdx.x_1*4), 3) + 1), 9)*7)) + (floormod(threadIdx.x_1, 3)*3)) - 8)], 0f32, dtype=float32)
          }
          if @tir.likely((threadIdx.x_1 &lt; 40), dtype=bool) {
            pad_temp.shared_1[((threadIdx.x_1*12) + 4708)] = @tir.if_then_else(((1 &lt;= floormod((floordiv((threadIdx.x_1*4), 3) + 1), 9)) &amp;&amp; (floormod(((threadIdx.x_1*12) + 10), 81) &lt; 72)), data[((((cse_var_2 + (floordiv(((threadIdx.x_1*4) + 1569), 27)*49)) + (floormod((floordiv((threadIdx.x_1*4), 3) + 1), 9)*7)) + (floormod(threadIdx.x_1, 3)*3)) - 7)], 0f32, dtype=float32)
          }
          if @tir.likely((threadIdx.x_1 &lt; 40), dtype=bool) {
            pad_temp.shared_1[((threadIdx.x_1*12) + 4709)] = @tir.if_then_else((((1 &lt;= floormod((floordiv((threadIdx.x_1*4), 3) + 1), 9)) &amp;&amp; (floormod(((threadIdx.x_1*12) + 11), 81) &lt; 72)) &amp;&amp; (floormod(threadIdx.x_1, 3) &lt; 2)), data[((((cse_var_2 + (floordiv(((threadIdx.x_1*4) + 1569), 27)*49)) + (floormod((floordiv((threadIdx.x_1*4), 3) + 1), 9)*7)) + (floormod(threadIdx.x_1, 3)*3)) - 6)], 0f32, dtype=float32)
          }
          if @tir.likely((threadIdx.x_1 &lt; 40), dtype=bool) {
            pad_temp.shared_1[((threadIdx.x_1*12) + 4710)] = @tir.if_then_else(((((3 &lt;= floormod(((threadIdx.x_1*4) + 4), 27)) &amp;&amp; (floormod(((threadIdx.x_1*12) + 12), 81) &lt; 72)) &amp;&amp; (1 &lt;= floormod(((threadIdx.x_1*3) + 3), 9))) &amp;&amp; (floormod(((threadIdx.x_1*3) + 3), 9) &lt; 8)), data[((((cse_var_2 + (floordiv(((threadIdx.x_1*4) + 1570), 27)*49)) + (floordiv(floormod(((threadIdx.x_1*4) + 4), 27), 3)*7)) + floormod(((threadIdx.x_1*3) + 3), 9)) - 8)], 0f32, dtype=float32)
          }
          if @tir.likely((threadIdx.x_1 &lt; 40), dtype=bool) {
            pad_temp.shared_1[((threadIdx.x_1*12) + 4711)] = @tir.if_then_else(((((3 &lt;= floormod(((threadIdx.x_1*4) + 4), 27)) &amp;&amp; (floormod(((threadIdx.x_1*12) + 13), 81) &lt; 72)) &amp;&amp; (1 &lt;= floormod(((threadIdx.x_1*3) + 4), 9))) &amp;&amp; (floormod(((threadIdx.x_1*3) + 4), 9) &lt; 8)), data[((((cse_var_2 + (floordiv(((threadIdx.x_1*4) + 1570), 27)*49)) + (floordiv(floormod(((threadIdx.x_1*4) + 4), 27), 3)*7)) + floormod(((threadIdx.x_1*3) + 4), 9)) - 8)], 0f32, dtype=float32)
          }
          if @tir.likely((threadIdx.x_1 &lt; 40), dtype=bool) {
            pad_temp.shared_1[((threadIdx.x_1*12) + 4712)] = @tir.if_then_else(((((3 &lt;= floormod(((threadIdx.x_1*4) + 4), 27)) &amp;&amp; (floormod(((threadIdx.x_1*12) + 14), 81) &lt; 72)) &amp;&amp; (1 &lt;= floormod(((threadIdx.x_1*3) + 5), 9))) &amp;&amp; (floormod(((threadIdx.x_1*3) + 5), 9) &lt; 8)), data[((((cse_var_2 + (floordiv(((threadIdx.x_1*4) + 1570), 27)*49)) + (floordiv(floormod(((threadIdx.x_1*4) + 4), 27), 3)*7)) + floormod(((threadIdx.x_1*3) + 5), 9)) - 8)], 0f32, dtype=float32)
          }
          if @tir.likely((threadIdx.x_1 &lt; 40), dtype=bool) {
            pad_temp.shared_1[((threadIdx.x_1*12) + 4713)] = @tir.if_then_else(((((1 &lt;= floormod((floordiv(((threadIdx.x_1*4) + 1568), 3) + 1), 9)) &amp;&amp; (floormod(((threadIdx.x_1*12) + 15), 81) &lt; 72)) &amp;&amp; (1 &lt;= floormod(((threadIdx.x_1*3) + 6), 9))) &amp;&amp; (floormod(((threadIdx.x_1*3) + 6), 9) &lt; 8)), data[((((cse_var_2 + (floordiv(((threadIdx.x_1*4) + 1571), 27)*49)) + (floormod((floordiv(((threadIdx.x_1*4) + 1568), 3) + 1), 9)*7)) + floormod(((threadIdx.x_1*3) + 6), 9)) - 8)], 0f32, dtype=float32)
          }
          if @tir.likely((threadIdx.x_1 &lt; 40), dtype=bool) {
            pad_temp.shared_1[((threadIdx.x_1*12) + 4714)] = @tir.if_then_else(((((1 &lt;= floormod((floordiv(((threadIdx.x_1*4) + 1568), 3) + 1), 9)) &amp;&amp; (floormod(((threadIdx.x_1*12) + 16), 81) &lt; 72)) &amp;&amp; (1 &lt;= floormod(((threadIdx.x_1*3) + 7), 9))) &amp;&amp; (floormod(((threadIdx.x_1*3) + 7), 9) &lt; 8)), data[((((cse_var_2 + (floordiv(((threadIdx.x_1*4) + 1571), 27)*49)) + (floormod((floordiv(((threadIdx.x_1*4) + 1568), 3) + 1), 9)*7)) + floormod(((threadIdx.x_1*3) + 7), 9)) - 8)], 0f32, dtype=float32)
          }
          if @tir.likely((threadIdx.x_1 &lt; 40), dtype=bool) {
            pad_temp.shared_1[((threadIdx.x_1*12) + 4715)] = @tir.if_then_else(((((1 &lt;= floormod((floordiv(((threadIdx.x_1*4) + 1568), 3) + 1), 9)) &amp;&amp; (floormod(((threadIdx.x_1*12) + 17), 81) &lt; 72)) &amp;&amp; (1 &lt;= floormod(((threadIdx.x_1*3) + 8), 9))) &amp;&amp; (floormod(((threadIdx.x_1*3) + 8), 9) &lt; 8)), data[((((cse_var_2 + (floordiv(((threadIdx.x_1*4) + 1571), 27)*49)) + (floormod((floordiv(((threadIdx.x_1*4) + 1568), 3) + 1), 9)*7)) + floormod(((threadIdx.x_1*3) + 8), 9)) - 8)], 0f32, dtype=float32)
          }
        }
        attr [IterVar(threadIdx.x_2: int32, (nullptr), &quot;ThreadIndex&quot;, &quot;threadIdx.x&quot;)] &quot;thread_extent&quot; = 49 {
          kernel.shared_1: Buffer(kernel.shared, float32, [4608], [], scope=&quot;shared&quot;)[(threadIdx.x_2*3)] = kernel[(((blockIdx.x*36864) + cse_var_1) + (threadIdx.x_2*3))]
          kernel.shared_1[((threadIdx.x_2*3) + 1)] = kernel[((((blockIdx.x*36864) + cse_var_1) + (threadIdx.x_2*3)) + 1)]
          kernel.shared_1[((threadIdx.x_2*3) + 2)] = kernel[((((blockIdx.x*36864) + cse_var_1) + (threadIdx.x_2*3)) + 2)]
        }
        attr [IterVar(threadIdx.x_2, (nullptr), &quot;ThreadIndex&quot;, &quot;threadIdx.x&quot;)] &quot;thread_extent&quot; = 49 {
          kernel.shared_1[((threadIdx.x_2*3) + 147)] = kernel[((((blockIdx.x*36864) + cse_var_1) + (threadIdx.x_2*3)) + 147)]
          kernel.shared_1[((threadIdx.x_2*3) + 148)] = kernel[((((blockIdx.x*36864) + cse_var_1) + (threadIdx.x_2*3)) + 148)]
          kernel.shared_1[((threadIdx.x_2*3) + 149)] = kernel[((((blockIdx.x*36864) + cse_var_1) + (threadIdx.x_2*3)) + 149)]
        }
        attr [IterVar(threadIdx.x_2, (nullptr), &quot;ThreadIndex&quot;, &quot;threadIdx.x&quot;)] &quot;thread_extent&quot; = 49 {
          kernel.shared_1[((threadIdx.x_2*3) + 294)] = kernel[((((blockIdx.x*36864) + cse_var_1) + (threadIdx.x_2*3)) + 294)]
          kernel.shared_1[((threadIdx.x_2*3) + 295)] = kernel[((((blockIdx.x*36864) + cse_var_1) + (threadIdx.x_2*3)) + 295)]
          kernel.shared_1[((threadIdx.x_2*3) + 296)] = kernel[((((blockIdx.x*36864) + cse_var_1) + (threadIdx.x_2*3)) + 296)]
        }
        attr [IterVar(threadIdx.x_2, (nullptr), &quot;ThreadIndex&quot;, &quot;threadIdx.x&quot;)] &quot;thread_extent&quot; = 49 {
          kernel.shared_1[((threadIdx.x_2*3) + 441)] = kernel[((((blockIdx.x*36864) + (floordiv((threadIdx.x_2 + 147), 192)*4608)) + cse_var_1) + (floormod((threadIdx.x_2 + 147), 192)*3))]
          kernel.shared_1[((threadIdx.x_2*3) + 442)] = kernel[(((((blockIdx.x*36864) + (floordiv((threadIdx.x_2 + 147), 192)*4608)) + cse_var_1) + (floormod((threadIdx.x_2 + 147), 192)*3)) + 1)]
          kernel.shared_1[((threadIdx.x_2*3) + 443)] = kernel[(((((blockIdx.x*36864) + (floordiv((threadIdx.x_2 + 147), 192)*4608)) + cse_var_1) + (floormod((threadIdx.x_2 + 147), 192)*3)) + 2)]
        }
        attr [IterVar(threadIdx.x_2, (nullptr), &quot;ThreadIndex&quot;, &quot;threadIdx.x&quot;)] &quot;thread_extent&quot; = 49 {
          kernel.shared_1[((threadIdx.x_2*3) + 588)] = kernel[((((blockIdx.x*36864) + (floordiv((threadIdx.x_2 + 196), 192)*4608)) + cse_var_1) + ((threadIdx.x_2 + 4)*3))]
          kernel.shared_1[((threadIdx.x_2*3) + 589)] = kernel[(((((blockIdx.x*36864) + (floordiv((threadIdx.x_2 + 196), 192)*4608)) + cse_var_1) + ((threadIdx.x_2 + 4)*3)) + 1)]
          kernel.shared_1[((threadIdx.x_2*3) + 590)] = kernel[(((((blockIdx.x*36864) + (floordiv((threadIdx.x_2 + 196), 192)*4608)) + cse_var_1) + ((threadIdx.x_2 + 4)*3)) + 2)]
        }
        attr [IterVar(threadIdx.x_2, (nullptr), &quot;ThreadIndex&quot;, &quot;threadIdx.x&quot;)] &quot;thread_extent&quot; = 49 {
          kernel.shared_1[((threadIdx.x_2*3) + 735)] = kernel[((((blockIdx.x*36864) + (floordiv((threadIdx.x_2 + 245), 192)*4608)) + cse_var_1) + ((threadIdx.x_2 + 53)*3))]
          kernel.shared_1[((threadIdx.x_2*3) + 736)] = kernel[(((((blockIdx.x*36864) + (floordiv((threadIdx.x_2 + 245), 192)*4608)) + cse_var_1) + ((threadIdx.x_2 + 53)*3)) + 1)]
          kernel.shared_1[((threadIdx.x_2*3) + 737)] = kernel[(((((blockIdx.x*36864) + (floordiv((threadIdx.x_2 + 245), 192)*4608)) + cse_var_1) + ((threadIdx.x_2 + 53)*3)) + 2)]
        }
        attr [IterVar(threadIdx.x_2, (nullptr), &quot;ThreadIndex&quot;, &quot;threadIdx.x&quot;)] &quot;thread_extent&quot; = 49 {
          kernel.shared_1[((threadIdx.x_2*3) + 882)] = kernel[((((blockIdx.x*36864) + (floordiv((threadIdx.x_2 + 294), 192)*4608)) + cse_var_1) + ((threadIdx.x_2 + 102)*3))]
          kernel.shared_1[((threadIdx.x_2*3) + 883)] = kernel[(((((blockIdx.x*36864) + (floordiv((threadIdx.x_2 + 294), 192)*4608)) + cse_var_1) + ((threadIdx.x_2 + 102)*3)) + 1)]
          kernel.shared_1[((threadIdx.x_2*3) + 884)] = kernel[(((((blockIdx.x*36864) + (floordiv((threadIdx.x_2 + 294), 192)*4608)) + cse_var_1) + ((threadIdx.x_2 + 102)*3)) + 2)]
        }
        attr [IterVar(threadIdx.x_2, (nullptr), &quot;ThreadIndex&quot;, &quot;threadIdx.x&quot;)] &quot;thread_extent&quot; = 49 {
          kernel.shared_1[((threadIdx.x_2*3) + 1029)] = kernel[((((blockIdx.x*36864) + (floordiv((threadIdx.x_2 + 343), 192)*4608)) + cse_var_1) + (floormod((threadIdx.x_2 + 151), 192)*3))]
          kernel.shared_1[((threadIdx.x_2*3) + 1030)] = kernel[(((((blockIdx.x*36864) + (floordiv((threadIdx.x_2 + 343), 192)*4608)) + cse_var_1) + (floormod((threadIdx.x_2 + 151), 192)*3)) + 1)]
          kernel.shared_1[((threadIdx.x_2*3) + 1031)] = kernel[(((((blockIdx.x*36864) + (floordiv((threadIdx.x_2 + 343), 192)*4608)) + cse_var_1) + (floormod((threadIdx.x_2 + 151), 192)*3)) + 2)]
        }
        attr [IterVar(threadIdx.x_2, (nullptr), &quot;ThreadIndex&quot;, &quot;threadIdx.x&quot;)] &quot;thread_extent&quot; = 49 {
          kernel.shared_1[((threadIdx.x_2*3) + 1176)] = kernel[((((blockIdx.x*36864) + (floordiv((threadIdx.x_2 + 392), 192)*4608)) + cse_var_1) + ((threadIdx.x_2 + 8)*3))]
          kernel.shared_1[((threadIdx.x_2*3) + 1177)] = kernel[(((((blockIdx.x*36864) + (floordiv((threadIdx.x_2 + 392), 192)*4608)) + cse_var_1) + ((threadIdx.x_2 + 8)*3)) + 1)]
          kernel.shared_1[((threadIdx.x_2*3) + 1178)] = kernel[(((((blockIdx.x*36864) + (floordiv((threadIdx.x_2 + 392), 192)*4608)) + cse_var_1) + ((threadIdx.x_2 + 8)*3)) + 2)]
        }
        attr [IterVar(threadIdx.x_2, (nullptr), &quot;ThreadIndex&quot;, &quot;threadIdx.x&quot;)] &quot;thread_extent&quot; = 49 {
          kernel.shared_1[((threadIdx.x_2*3) + 1323)] = kernel[((((blockIdx.x*36864) + (floordiv((threadIdx.x_2 + 441), 192)*4608)) + cse_var_1) + ((threadIdx.x_2 + 57)*3))]
          kernel.shared_1[((threadIdx.x_2*3) + 1324)] = kernel[(((((blockIdx.x*36864) + (floordiv((threadIdx.x_2 + 441), 192)*4608)) + cse_var_1) + ((threadIdx.x_2 + 57)*3)) + 1)]
          kernel.shared_1[((threadIdx.x_2*3) + 1325)] = kernel[(((((blockIdx.x*36864) + (floordiv((threadIdx.x_2 + 441), 192)*4608)) + cse_var_1) + ((threadIdx.x_2 + 57)*3)) + 2)]
        }
        attr [IterVar(threadIdx.x_2, (nullptr), &quot;ThreadIndex&quot;, &quot;threadIdx.x&quot;)] &quot;thread_extent&quot; = 49 {
          kernel.shared_1[((threadIdx.x_2*3) + 1470)] = kernel[((((blockIdx.x*36864) + (floordiv((threadIdx.x_2 + 490), 192)*4608)) + cse_var_1) + ((threadIdx.x_2 + 106)*3))]
          kernel.shared_1[((threadIdx.x_2*3) + 1471)] = kernel[(((((blockIdx.x*36864) + (floordiv((threadIdx.x_2 + 490), 192)*4608)) + cse_var_1) + ((threadIdx.x_2 + 106)*3)) + 1)]
          kernel.shared_1[((threadIdx.x_2*3) + 1472)] = kernel[(((((blockIdx.x*36864) + (floordiv((threadIdx.x_2 + 490), 192)*4608)) + cse_var_1) + ((threadIdx.x_2 + 106)*3)) + 2)]
        }
        attr [IterVar(threadIdx.x_2, (nullptr), &quot;ThreadIndex&quot;, &quot;threadIdx.x&quot;)] &quot;thread_extent&quot; = 49 {
          kernel.shared_1[((threadIdx.x_2*3) + 1617)] = kernel[((((blockIdx.x*36864) + (floordiv((threadIdx.x_2 + 539), 192)*4608)) + cse_var_1) + (floormod((threadIdx.x_2 + 155), 192)*3))]
          kernel.shared_1[((threadIdx.x_2*3) + 1618)] = kernel[(((((blockIdx.x*36864) + (floordiv((threadIdx.x_2 + 539), 192)*4608)) + cse_var_1) + (floormod((threadIdx.x_2 + 155), 192)*3)) + 1)]
          kernel.shared_1[((threadIdx.x_2*3) + 1619)] = kernel[(((((blockIdx.x*36864) + (floordiv((threadIdx.x_2 + 539), 192)*4608)) + cse_var_1) + (floormod((threadIdx.x_2 + 155), 192)*3)) + 2)]
        }
        attr [IterVar(threadIdx.x_2, (nullptr), &quot;ThreadIndex&quot;, &quot;threadIdx.x&quot;)] &quot;thread_extent&quot; = 49 {
          kernel.shared_1[((threadIdx.x_2*3) + 1764)] = kernel[((((blockIdx.x*36864) + (floordiv((threadIdx.x_2 + 588), 192)*4608)) + cse_var_1) + ((threadIdx.x_2 + 12)*3))]
          kernel.shared_1[((threadIdx.x_2*3) + 1765)] = kernel[(((((blockIdx.x*36864) + (floordiv((threadIdx.x_2 + 588), 192)*4608)) + cse_var_1) + ((threadIdx.x_2 + 12)*3)) + 1)]
          kernel.shared_1[((threadIdx.x_2*3) + 1766)] = kernel[(((((blockIdx.x*36864) + (floordiv((threadIdx.x_2 + 588), 192)*4608)) + cse_var_1) + ((threadIdx.x_2 + 12)*3)) + 2)]
        }
        attr [IterVar(threadIdx.x_2, (nullptr), &quot;ThreadIndex&quot;, &quot;threadIdx.x&quot;)] &quot;thread_extent&quot; = 49 {
          kernel.shared_1[((threadIdx.x_2*3) + 1911)] = kernel[((((blockIdx.x*36864) + (floordiv((threadIdx.x_2 + 637), 192)*4608)) + cse_var_1) + ((threadIdx.x_2 + 61)*3))]
          kernel.shared_1[((threadIdx.x_2*3) + 1912)] = kernel[(((((blockIdx.x*36864) + (floordiv((threadIdx.x_2 + 637), 192)*4608)) + cse_var_1) + ((threadIdx.x_2 + 61)*3)) + 1)]
          kernel.shared_1[((threadIdx.x_2*3) + 1913)] = kernel[(((((blockIdx.x*36864) + (floordiv((threadIdx.x_2 + 637), 192)*4608)) + cse_var_1) + ((threadIdx.x_2 + 61)*3)) + 2)]
        }
        attr [IterVar(threadIdx.x_2, (nullptr), &quot;ThreadIndex&quot;, &quot;threadIdx.x&quot;)] &quot;thread_extent&quot; = 49 {
          kernel.shared_1[((threadIdx.x_2*3) + 2058)] = kernel[((((blockIdx.x*36864) + (floordiv((threadIdx.x_2 + 686), 192)*4608)) + cse_var_1) + ((threadIdx.x_2 + 110)*3))]
          kernel.shared_1[((threadIdx.x_2*3) + 2059)] = kernel[(((((blockIdx.x*36864) + (floordiv((threadIdx.x_2 + 686), 192)*4608)) + cse_var_1) + ((threadIdx.x_2 + 110)*3)) + 1)]
          kernel.shared_1[((threadIdx.x_2*3) + 2060)] = kernel[(((((blockIdx.x*36864) + (floordiv((threadIdx.x_2 + 686), 192)*4608)) + cse_var_1) + ((threadIdx.x_2 + 110)*3)) + 2)]
        }
        attr [IterVar(threadIdx.x_2, (nullptr), &quot;ThreadIndex&quot;, &quot;threadIdx.x&quot;)] &quot;thread_extent&quot; = 49 {
          kernel.shared_1[((threadIdx.x_2*3) + 2205)] = kernel[((((blockIdx.x*36864) + (floordiv((threadIdx.x_2 + 735), 192)*4608)) + cse_var_1) + (floormod((threadIdx.x_2 + 159), 192)*3))]
          kernel.shared_1[((threadIdx.x_2*3) + 2206)] = kernel[(((((blockIdx.x*36864) + (floordiv((threadIdx.x_2 + 735), 192)*4608)) + cse_var_1) + (floormod((threadIdx.x_2 + 159), 192)*3)) + 1)]
          kernel.shared_1[((threadIdx.x_2*3) + 2207)] = kernel[(((((blockIdx.x*36864) + (floordiv((threadIdx.x_2 + 735), 192)*4608)) + cse_var_1) + (floormod((threadIdx.x_2 + 159), 192)*3)) + 2)]
        }
        attr [IterVar(threadIdx.x_2, (nullptr), &quot;ThreadIndex&quot;, &quot;threadIdx.x&quot;)] &quot;thread_extent&quot; = 49 {
          kernel.shared_1[((threadIdx.x_2*3) + 2352)] = kernel[((((blockIdx.x*36864) + (floordiv((threadIdx.x_2 + 784), 192)*4608)) + cse_var_1) + ((threadIdx.x_2 + 16)*3))]
          kernel.shared_1[((threadIdx.x_2*3) + 2353)] = kernel[(((((blockIdx.x*36864) + (floordiv((threadIdx.x_2 + 784), 192)*4608)) + cse_var_1) + ((threadIdx.x_2 + 16)*3)) + 1)]
          kernel.shared_1[((threadIdx.x_2*3) + 2354)] = kernel[(((((blockIdx.x*36864) + (floordiv((threadIdx.x_2 + 784), 192)*4608)) + cse_var_1) + ((threadIdx.x_2 + 16)*3)) + 2)]
        }
        attr [IterVar(threadIdx.x_2, (nullptr), &quot;ThreadIndex&quot;, &quot;threadIdx.x&quot;)] &quot;thread_extent&quot; = 49 {
          kernel.shared_1[((threadIdx.x_2*3) + 2499)] = kernel[((((blockIdx.x*36864) + (floordiv((threadIdx.x_2 + 833), 192)*4608)) + cse_var_1) + ((threadIdx.x_2 + 65)*3))]
          kernel.shared_1[((threadIdx.x_2*3) + 2500)] = kernel[(((((blockIdx.x*36864) + (floordiv((threadIdx.x_2 + 833), 192)*4608)) + cse_var_1) + ((threadIdx.x_2 + 65)*3)) + 1)]
          kernel.shared_1[((threadIdx.x_2*3) + 2501)] = kernel[(((((blockIdx.x*36864) + (floordiv((threadIdx.x_2 + 833), 192)*4608)) + cse_var_1) + ((threadIdx.x_2 + 65)*3)) + 2)]
        }
        attr [IterVar(threadIdx.x_2, (nullptr), &quot;ThreadIndex&quot;, &quot;threadIdx.x&quot;)] &quot;thread_extent&quot; = 49 {
          kernel.shared_1[((threadIdx.x_2*3) + 2646)] = kernel[((((blockIdx.x*36864) + (floordiv((threadIdx.x_2 + 882), 192)*4608)) + cse_var_1) + ((threadIdx.x_2 + 114)*3))]
          kernel.shared_1[((threadIdx.x_2*3) + 2647)] = kernel[(((((blockIdx.x*36864) + (floordiv((threadIdx.x_2 + 882), 192)*4608)) + cse_var_1) + ((threadIdx.x_2 + 114)*3)) + 1)]
          kernel.shared_1[((threadIdx.x_2*3) + 2648)] = kernel[(((((blockIdx.x*36864) + (floordiv((threadIdx.x_2 + 882), 192)*4608)) + cse_var_1) + ((threadIdx.x_2 + 114)*3)) + 2)]
        }
        attr [IterVar(threadIdx.x_2, (nullptr), &quot;ThreadIndex&quot;, &quot;threadIdx.x&quot;)] &quot;thread_extent&quot; = 49 {
          kernel.shared_1[((threadIdx.x_2*3) + 2793)] = kernel[((((blockIdx.x*36864) + (floordiv((threadIdx.x_2 + 931), 192)*4608)) + cse_var_1) + (floormod((threadIdx.x_2 + 163), 192)*3))]
          kernel.shared_1[((threadIdx.x_2*3) + 2794)] = kernel[(((((blockIdx.x*36864) + (floordiv((threadIdx.x_2 + 931), 192)*4608)) + cse_var_1) + (floormod((threadIdx.x_2 + 163), 192)*3)) + 1)]
          kernel.shared_1[((threadIdx.x_2*3) + 2795)] = kernel[(((((blockIdx.x*36864) + (floordiv((threadIdx.x_2 + 931), 192)*4608)) + cse_var_1) + (floormod((threadIdx.x_2 + 163), 192)*3)) + 2)]
        }
        attr [IterVar(threadIdx.x_2, (nullptr), &quot;ThreadIndex&quot;, &quot;threadIdx.x&quot;)] &quot;thread_extent&quot; = 49 {
          kernel.shared_1[((threadIdx.x_2*3) + 2940)] = kernel[((((blockIdx.x*36864) + (floordiv((threadIdx.x_2 + 980), 192)*4608)) + cse_var_1) + ((threadIdx.x_2 + 20)*3))]
          kernel.shared_1[((threadIdx.x_2*3) + 2941)] = kernel[(((((blockIdx.x*36864) + (floordiv((threadIdx.x_2 + 980), 192)*4608)) + cse_var_1) + ((threadIdx.x_2 + 20)*3)) + 1)]
          kernel.shared_1[((threadIdx.x_2*3) + 2942)] = kernel[(((((blockIdx.x*36864) + (floordiv((threadIdx.x_2 + 980), 192)*4608)) + cse_var_1) + ((threadIdx.x_2 + 20)*3)) + 2)]
        }
        attr [IterVar(threadIdx.x_2, (nullptr), &quot;ThreadIndex&quot;, &quot;threadIdx.x&quot;)] &quot;thread_extent&quot; = 49 {
          kernel.shared_1[((threadIdx.x_2*3) + 3087)] = kernel[((((blockIdx.x*36864) + (floordiv((threadIdx.x_2 + 1029), 192)*4608)) + cse_var_1) + ((threadIdx.x_2 + 69)*3))]
          kernel.shared_1[((threadIdx.x_2*3) + 3088)] = kernel[(((((blockIdx.x*36864) + (floordiv((threadIdx.x_2 + 1029), 192)*4608)) + cse_var_1) + ((threadIdx.x_2 + 69)*3)) + 1)]
          kernel.shared_1[((threadIdx.x_2*3) + 3089)] = kernel[(((((blockIdx.x*36864) + (floordiv((threadIdx.x_2 + 1029), 192)*4608)) + cse_var_1) + ((threadIdx.x_2 + 69)*3)) + 2)]
        }
        attr [IterVar(threadIdx.x_2, (nullptr), &quot;ThreadIndex&quot;, &quot;threadIdx.x&quot;)] &quot;thread_extent&quot; = 49 {
          kernel.shared_1[((threadIdx.x_2*3) + 3234)] = kernel[((((blockIdx.x*36864) + (floordiv((threadIdx.x_2 + 1078), 192)*4608)) + cse_var_1) + ((threadIdx.x_2 + 118)*3))]
          kernel.shared_1[((threadIdx.x_2*3) + 3235)] = kernel[(((((blockIdx.x*36864) + (floordiv((threadIdx.x_2 + 1078), 192)*4608)) + cse_var_1) + ((threadIdx.x_2 + 118)*3)) + 1)]
          kernel.shared_1[((threadIdx.x_2*3) + 3236)] = kernel[(((((blockIdx.x*36864) + (floordiv((threadIdx.x_2 + 1078), 192)*4608)) + cse_var_1) + ((threadIdx.x_2 + 118)*3)) + 2)]
        }
        attr [IterVar(threadIdx.x_2, (nullptr), &quot;ThreadIndex&quot;, &quot;threadIdx.x&quot;)] &quot;thread_extent&quot; = 49 {
          kernel.shared_1[((threadIdx.x_2*3) + 3381)] = kernel[((((blockIdx.x*36864) + (floordiv((threadIdx.x_2 + 1127), 192)*4608)) + cse_var_1) + (floormod((threadIdx.x_2 + 167), 192)*3))]
          kernel.shared_1[((threadIdx.x_2*3) + 3382)] = kernel[(((((blockIdx.x*36864) + (floordiv((threadIdx.x_2 + 1127), 192)*4608)) + cse_var_1) + (floormod((threadIdx.x_2 + 167), 192)*3)) + 1)]
          kernel.shared_1[((threadIdx.x_2*3) + 3383)] = kernel[(((((blockIdx.x*36864) + (floordiv((threadIdx.x_2 + 1127), 192)*4608)) + cse_var_1) + (floormod((threadIdx.x_2 + 167), 192)*3)) + 2)]
        }
        attr [IterVar(threadIdx.x_2, (nullptr), &quot;ThreadIndex&quot;, &quot;threadIdx.x&quot;)] &quot;thread_extent&quot; = 49 {
          kernel.shared_1[((threadIdx.x_2*3) + 3528)] = kernel[((((blockIdx.x*36864) + (floordiv((threadIdx.x_2 + 1176), 192)*4608)) + cse_var_1) + ((threadIdx.x_2 + 24)*3))]
          kernel.shared_1[((threadIdx.x_2*3) + 3529)] = kernel[(((((blockIdx.x*36864) + (floordiv((threadIdx.x_2 + 1176), 192)*4608)) + cse_var_1) + ((threadIdx.x_2 + 24)*3)) + 1)]
          kernel.shared_1[((threadIdx.x_2*3) + 3530)] = kernel[(((((blockIdx.x*36864) + (floordiv((threadIdx.x_2 + 1176), 192)*4608)) + cse_var_1) + ((threadIdx.x_2 + 24)*3)) + 2)]
        }
        attr [IterVar(threadIdx.x_2, (nullptr), &quot;ThreadIndex&quot;, &quot;threadIdx.x&quot;)] &quot;thread_extent&quot; = 49 {
          kernel.shared_1[((threadIdx.x_2*3) + 3675)] = kernel[((((blockIdx.x*36864) + (floordiv((threadIdx.x_2 + 1225), 192)*4608)) + cse_var_1) + ((threadIdx.x_2 + 73)*3))]
          kernel.shared_1[((threadIdx.x_2*3) + 3676)] = kernel[(((((blockIdx.x*36864) + (floordiv((threadIdx.x_2 + 1225), 192)*4608)) + cse_var_1) + ((threadIdx.x_2 + 73)*3)) + 1)]
          kernel.shared_1[((threadIdx.x_2*3) + 3677)] = kernel[(((((blockIdx.x*36864) + (floordiv((threadIdx.x_2 + 1225), 192)*4608)) + cse_var_1) + ((threadIdx.x_2 + 73)*3)) + 2)]
        }
        attr [IterVar(threadIdx.x_2, (nullptr), &quot;ThreadIndex&quot;, &quot;threadIdx.x&quot;)] &quot;thread_extent&quot; = 49 {
          kernel.shared_1[((threadIdx.x_2*3) + 3822)] = kernel[((((blockIdx.x*36864) + (floordiv((threadIdx.x_2 + 1274), 192)*4608)) + cse_var_1) + ((threadIdx.x_2 + 122)*3))]
          kernel.shared_1[((threadIdx.x_2*3) + 3823)] = kernel[(((((blockIdx.x*36864) + (floordiv((threadIdx.x_2 + 1274), 192)*4608)) + cse_var_1) + ((threadIdx.x_2 + 122)*3)) + 1)]
          kernel.shared_1[((threadIdx.x_2*3) + 3824)] = kernel[(((((blockIdx.x*36864) + (floordiv((threadIdx.x_2 + 1274), 192)*4608)) + cse_var_1) + ((threadIdx.x_2 + 122)*3)) + 2)]
        }
        attr [IterVar(threadIdx.x_2, (nullptr), &quot;ThreadIndex&quot;, &quot;threadIdx.x&quot;)] &quot;thread_extent&quot; = 49 {
          kernel.shared_1[((threadIdx.x_2*3) + 3969)] = kernel[((((blockIdx.x*36864) + (floordiv((threadIdx.x_2 + 1323), 192)*4608)) + cse_var_1) + (floormod((threadIdx.x_2 + 171), 192)*3))]
          kernel.shared_1[((threadIdx.x_2*3) + 3970)] = kernel[(((((blockIdx.x*36864) + (floordiv((threadIdx.x_2 + 1323), 192)*4608)) + cse_var_1) + (floormod((threadIdx.x_2 + 171), 192)*3)) + 1)]
          kernel.shared_1[((threadIdx.x_2*3) + 3971)] = kernel[(((((blockIdx.x*36864) + (floordiv((threadIdx.x_2 + 1323), 192)*4608)) + cse_var_1) + (floormod((threadIdx.x_2 + 171), 192)*3)) + 2)]
        }
        attr [IterVar(threadIdx.x_2, (nullptr), &quot;ThreadIndex&quot;, &quot;threadIdx.x&quot;)] &quot;thread_extent&quot; = 49 {
          kernel.shared_1[((threadIdx.x_2*3) + 4116)] = kernel[((((blockIdx.x*36864) + (floordiv((threadIdx.x_2 + 1372), 192)*4608)) + cse_var_1) + ((threadIdx.x_2 + 28)*3))]
          kernel.shared_1[((threadIdx.x_2*3) + 4117)] = kernel[(((((blockIdx.x*36864) + (floordiv((threadIdx.x_2 + 1372), 192)*4608)) + cse_var_1) + ((threadIdx.x_2 + 28)*3)) + 1)]
          kernel.shared_1[((threadIdx.x_2*3) + 4118)] = kernel[(((((blockIdx.x*36864) + (floordiv((threadIdx.x_2 + 1372), 192)*4608)) + cse_var_1) + ((threadIdx.x_2 + 28)*3)) + 2)]
        }
        attr [IterVar(threadIdx.x_2, (nullptr), &quot;ThreadIndex&quot;, &quot;threadIdx.x&quot;)] &quot;thread_extent&quot; = 49 {
          kernel.shared_1[((threadIdx.x_2*3) + 4263)] = kernel[((((blockIdx.x*36864) + (floordiv((threadIdx.x_2 + 1421), 192)*4608)) + cse_var_1) + ((threadIdx.x_2 + 77)*3))]
          kernel.shared_1[((threadIdx.x_2*3) + 4264)] = kernel[(((((blockIdx.x*36864) + (floordiv((threadIdx.x_2 + 1421), 192)*4608)) + cse_var_1) + ((threadIdx.x_2 + 77)*3)) + 1)]
          kernel.shared_1[((threadIdx.x_2*3) + 4265)] = kernel[(((((blockIdx.x*36864) + (floordiv((threadIdx.x_2 + 1421), 192)*4608)) + cse_var_1) + ((threadIdx.x_2 + 77)*3)) + 2)]
        }
        attr [IterVar(threadIdx.x_2, (nullptr), &quot;ThreadIndex&quot;, &quot;threadIdx.x&quot;)] &quot;thread_extent&quot; = 49 {
          kernel.shared_1[((threadIdx.x_2*3) + 4410)] = kernel[((((blockIdx.x*36864) + (floordiv((threadIdx.x_2 + 1470), 192)*4608)) + cse_var_1) + ((threadIdx.x_2 + 126)*3))]
          kernel.shared_1[((threadIdx.x_2*3) + 4411)] = kernel[(((((blockIdx.x*36864) + (floordiv((threadIdx.x_2 + 1470), 192)*4608)) + cse_var_1) + ((threadIdx.x_2 + 126)*3)) + 1)]
          kernel.shared_1[((threadIdx.x_2*3) + 4412)] = kernel[(((((blockIdx.x*36864) + (floordiv((threadIdx.x_2 + 1470), 192)*4608)) + cse_var_1) + ((threadIdx.x_2 + 126)*3)) + 2)]
        }
        attr [IterVar(threadIdx.x_2, (nullptr), &quot;ThreadIndex&quot;, &quot;threadIdx.x&quot;)] &quot;thread_extent&quot; = 49;
        if @tir.likely((threadIdx.x_2 &lt; 17), dtype=bool) {
          kernel.shared_1[((threadIdx.x_2*3) + 4557)] = kernel[((((blockIdx.x*36864) + (floordiv((threadIdx.x_2 + 1519), 192)*4608)) + cse_var_1) + ((threadIdx.x_2 + 175)*3))]
          kernel.shared_1[((threadIdx.x_2*3) + 4558)] = kernel[(((((blockIdx.x*36864) + (floordiv((threadIdx.x_2 + 1519), 192)*4608)) + cse_var_1) + ((threadIdx.x_2 + 175)*3)) + 1)]
          kernel.shared_1[((threadIdx.x_2*3) + 4559)] = kernel[(((((blockIdx.x*36864) + (floordiv((threadIdx.x_2 + 1519), 192)*4608)) + cse_var_1) + ((threadIdx.x_2 + 175)*3)) + 2)]
        }
        for (rc.outer.inner: int32, 0, 64) {
          let cse_var_3: int32 = (rc.outer.inner*9)
           {
            conv2d_nchw_1[0] = (conv2d_nchw_1[0] + (pad_temp.shared_1[(((rc.outer.inner*81) + (floordiv(threadIdx.x, 7)*9)) + floormod(threadIdx.x, 7))]*kernel.shared_1[cse_var_3]))
            conv2d_nchw_1[4] = (conv2d_nchw_1[4] + (pad_temp.shared_1[(((rc.outer.inner*81) + (floordiv(threadIdx.x, 7)*9)) + floormod(threadIdx.x, 7))]*kernel.shared_1[(cse_var_3 + 2304)]))
            conv2d_nchw_1[1] = (conv2d_nchw_1[1] + (pad_temp.shared_1[(((rc.outer.inner*81) + (floordiv(threadIdx.x, 7)*9)) + floormod(threadIdx.x, 7))]*kernel.shared_1[(cse_var_3 + 576)]))
            conv2d_nchw_1[5] = (conv2d_nchw_1[5] + (pad_temp.shared_1[(((rc.outer.inner*81) + (floordiv(threadIdx.x, 7)*9)) + floormod(threadIdx.x, 7))]*kernel.shared_1[(cse_var_3 + 2880)]))
            conv2d_nchw_1[0] = (conv2d_nchw_1[0] + (pad_temp.shared_1[((((rc.outer.inner*81) + (floordiv(threadIdx.x, 7)*9)) + floormod(threadIdx.x, 7)) + 1)]*kernel.shared_1[(cse_var_3 + 1)]))
            conv2d_nchw_1[4] = (conv2d_nchw_1[4] + (pad_temp.shared_1[((((rc.outer.inner*81) + (floordiv(threadIdx.x, 7)*9)) + floormod(threadIdx.x, 7)) + 1)]*kernel.shared_1[(cse_var_3 + 2305)]))
            conv2d_nchw_1[1] = (conv2d_nchw_1[1] + (pad_temp.shared_1[((((rc.outer.inner*81) + (floordiv(threadIdx.x, 7)*9)) + floormod(threadIdx.x, 7)) + 1)]*kernel.shared_1[(cse_var_3 + 577)]))
            conv2d_nchw_1[5] = (conv2d_nchw_1[5] + (pad_temp.shared_1[((((rc.outer.inner*81) + (floordiv(threadIdx.x, 7)*9)) + floormod(threadIdx.x, 7)) + 1)]*kernel.shared_1[(cse_var_3 + 2881)]))
            conv2d_nchw_1[0] = (conv2d_nchw_1[0] + (pad_temp.shared_1[((((rc.outer.inner*81) + (floordiv(threadIdx.x, 7)*9)) + floormod(threadIdx.x, 7)) + 2)]*kernel.shared_1[(cse_var_3 + 2)]))
            conv2d_nchw_1[4] = (conv2d_nchw_1[4] + (pad_temp.shared_1[((((rc.outer.inner*81) + (floordiv(threadIdx.x, 7)*9)) + floormod(threadIdx.x, 7)) + 2)]*kernel.shared_1[(cse_var_3 + 2306)]))
            conv2d_nchw_1[1] = (conv2d_nchw_1[1] + (pad_temp.shared_1[((((rc.outer.inner*81) + (floordiv(threadIdx.x, 7)*9)) + floormod(threadIdx.x, 7)) + 2)]*kernel.shared_1[(cse_var_3 + 578)]))
            conv2d_nchw_1[5] = (conv2d_nchw_1[5] + (pad_temp.shared_1[((((rc.outer.inner*81) + (floordiv(threadIdx.x, 7)*9)) + floormod(threadIdx.x, 7)) + 2)]*kernel.shared_1[(cse_var_3 + 2882)]))
            conv2d_nchw_1[2] = (conv2d_nchw_1[2] + (pad_temp.shared_1[(((rc.outer.inner*81) + (floordiv(threadIdx.x, 7)*9)) + floormod(threadIdx.x, 7))]*kernel.shared_1[(cse_var_3 + 1152)]))
            conv2d_nchw_1[6] = (conv2d_nchw_1[6] + (pad_temp.shared_1[(((rc.outer.inner*81) + (floordiv(threadIdx.x, 7)*9)) + floormod(threadIdx.x, 7))]*kernel.shared_1[(cse_var_3 + 3456)]))
            conv2d_nchw_1[3] = (conv2d_nchw_1[3] + (pad_temp.shared_1[(((rc.outer.inner*81) + (floordiv(threadIdx.x, 7)*9)) + floormod(threadIdx.x, 7))]*kernel.shared_1[(cse_var_3 + 1728)]))
            conv2d_nchw_1[7] = (conv2d_nchw_1[7] + (pad_temp.shared_1[(((rc.outer.inner*81) + (floordiv(threadIdx.x, 7)*9)) + floormod(threadIdx.x, 7))]*kernel.shared_1[(cse_var_3 + 4032)]))
            conv2d_nchw_1[2] = (conv2d_nchw_1[2] + (pad_temp.shared_1[((((rc.outer.inner*81) + (floordiv(threadIdx.x, 7)*9)) + floormod(threadIdx.x, 7)) + 1)]*kernel.shared_1[(cse_var_3 + 1153)]))
            conv2d_nchw_1[6] = (conv2d_nchw_1[6] + (pad_temp.shared_1[((((rc.outer.inner*81) + (floordiv(threadIdx.x, 7)*9)) + floormod(threadIdx.x, 7)) + 1)]*kernel.shared_1[(cse_var_3 + 3457)]))
            conv2d_nchw_1[3] = (conv2d_nchw_1[3] + (pad_temp.shared_1[((((rc.outer.inner*81) + (floordiv(threadIdx.x, 7)*9)) + floormod(threadIdx.x, 7)) + 1)]*kernel.shared_1[(cse_var_3 + 1729)]))
            conv2d_nchw_1[7] = (conv2d_nchw_1[7] + (pad_temp.shared_1[((((rc.outer.inner*81) + (floordiv(threadIdx.x, 7)*9)) + floormod(threadIdx.x, 7)) + 1)]*kernel.shared_1[(cse_var_3 + 4033)]))
            conv2d_nchw_1[2] = (conv2d_nchw_1[2] + (pad_temp.shared_1[((((rc.outer.inner*81) + (floordiv(threadIdx.x, 7)*9)) + floormod(threadIdx.x, 7)) + 2)]*kernel.shared_1[(cse_var_3 + 1154)]))
            conv2d_nchw_1[6] = (conv2d_nchw_1[6] + (pad_temp.shared_1[((((rc.outer.inner*81) + (floordiv(threadIdx.x, 7)*9)) + floormod(threadIdx.x, 7)) + 2)]*kernel.shared_1[(cse_var_3 + 3458)]))
            conv2d_nchw_1[3] = (conv2d_nchw_1[3] + (pad_temp.shared_1[((((rc.outer.inner*81) + (floordiv(threadIdx.x, 7)*9)) + floormod(threadIdx.x, 7)) + 2)]*kernel.shared_1[(cse_var_3 + 1730)]))
            conv2d_nchw_1[7] = (conv2d_nchw_1[7] + (pad_temp.shared_1[((((rc.outer.inner*81) + (floordiv(threadIdx.x, 7)*9)) + floormod(threadIdx.x, 7)) + 2)]*kernel.shared_1[(cse_var_3 + 4034)]))
            conv2d_nchw_1[0] = (conv2d_nchw_1[0] + (pad_temp.shared_1[((((rc.outer.inner*81) + (floordiv(threadIdx.x, 7)*9)) + floormod(threadIdx.x, 7)) + 9)]*kernel.shared_1[(cse_var_3 + 3)]))
            conv2d_nchw_1[4] = (conv2d_nchw_1[4] + (pad_temp.shared_1[((((rc.outer.inner*81) + (floordiv(threadIdx.x, 7)*9)) + floormod(threadIdx.x, 7)) + 9)]*kernel.shared_1[(cse_var_3 + 2307)]))
            conv2d_nchw_1[1] = (conv2d_nchw_1[1] + (pad_temp.shared_1[((((rc.outer.inner*81) + (floordiv(threadIdx.x, 7)*9)) + floormod(threadIdx.x, 7)) + 9)]*kernel.shared_1[(cse_var_3 + 579)]))
            conv2d_nchw_1[5] = (conv2d_nchw_1[5] + (pad_temp.shared_1[((((rc.outer.inner*81) + (floordiv(threadIdx.x, 7)*9)) + floormod(threadIdx.x, 7)) + 9)]*kernel.shared_1[(cse_var_3 + 2883)]))
            conv2d_nchw_1[0] = (conv2d_nchw_1[0] + (pad_temp.shared_1[((((rc.outer.inner*81) + (floordiv(threadIdx.x, 7)*9)) + floormod(threadIdx.x, 7)) + 10)]*kernel.shared_1[(cse_var_3 + 4)]))
            conv2d_nchw_1[4] = (conv2d_nchw_1[4] + (pad_temp.shared_1[((((rc.outer.inner*81) + (floordiv(threadIdx.x, 7)*9)) + floormod(threadIdx.x, 7)) + 10)]*kernel.shared_1[(cse_var_3 + 2308)]))
            conv2d_nchw_1[1] = (conv2d_nchw_1[1] + (pad_temp.shared_1[((((rc.outer.inner*81) + (floordiv(threadIdx.x, 7)*9)) + floormod(threadIdx.x, 7)) + 10)]*kernel.shared_1[(cse_var_3 + 580)]))
            conv2d_nchw_1[5] = (conv2d_nchw_1[5] + (pad_temp.shared_1[((((rc.outer.inner*81) + (floordiv(threadIdx.x, 7)*9)) + floormod(threadIdx.x, 7)) + 10)]*kernel.shared_1[(cse_var_3 + 2884)]))
            conv2d_nchw_1[0] = (conv2d_nchw_1[0] + (pad_temp.shared_1[((((rc.outer.inner*81) + (floordiv(threadIdx.x, 7)*9)) + floormod(threadIdx.x, 7)) + 11)]*kernel.shared_1[(cse_var_3 + 5)]))
            conv2d_nchw_1[4] = (conv2d_nchw_1[4] + (pad_temp.shared_1[((((rc.outer.inner*81) + (floordiv(threadIdx.x, 7)*9)) + floormod(threadIdx.x, 7)) + 11)]*kernel.shared_1[(cse_var_3 + 2309)]))
            conv2d_nchw_1[1] = (conv2d_nchw_1[1] + (pad_temp.shared_1[((((rc.outer.inner*81) + (floordiv(threadIdx.x, 7)*9)) + floormod(threadIdx.x, 7)) + 11)]*kernel.shared_1[(cse_var_3 + 581)]))
            conv2d_nchw_1[5] = (conv2d_nchw_1[5] + (pad_temp.shared_1[((((rc.outer.inner*81) + (floordiv(threadIdx.x, 7)*9)) + floormod(threadIdx.x, 7)) + 11)]*kernel.shared_1[(cse_var_3 + 2885)]))
            conv2d_nchw_1[2] = (conv2d_nchw_1[2] + (pad_temp.shared_1[((((rc.outer.inner*81) + (floordiv(threadIdx.x, 7)*9)) + floormod(threadIdx.x, 7)) + 9)]*kernel.shared_1[(cse_var_3 + 1155)]))
            conv2d_nchw_1[6] = (conv2d_nchw_1[6] + (pad_temp.shared_1[((((rc.outer.inner*81) + (floordiv(threadIdx.x, 7)*9)) + floormod(threadIdx.x, 7)) + 9)]*kernel.shared_1[(cse_var_3 + 3459)]))
            conv2d_nchw_1[3] = (conv2d_nchw_1[3] + (pad_temp.shared_1[((((rc.outer.inner*81) + (floordiv(threadIdx.x, 7)*9)) + floormod(threadIdx.x, 7)) + 9)]*kernel.shared_1[(cse_var_3 + 1731)]))
            conv2d_nchw_1[7] = (conv2d_nchw_1[7] + (pad_temp.shared_1[((((rc.outer.inner*81) + (floordiv(threadIdx.x, 7)*9)) + floormod(threadIdx.x, 7)) + 9)]*kernel.shared_1[(cse_var_3 + 4035)]))
            conv2d_nchw_1[2] = (conv2d_nchw_1[2] + (pad_temp.shared_1[((((rc.outer.inner*81) + (floordiv(threadIdx.x, 7)*9)) + floormod(threadIdx.x, 7)) + 10)]*kernel.shared_1[(cse_var_3 + 1156)]))
            conv2d_nchw_1[6] = (conv2d_nchw_1[6] + (pad_temp.shared_1[((((rc.outer.inner*81) + (floordiv(threadIdx.x, 7)*9)) + floormod(threadIdx.x, 7)) + 10)]*kernel.shared_1[(cse_var_3 + 3460)]))
            conv2d_nchw_1[3] = (conv2d_nchw_1[3] + (pad_temp.shared_1[((((rc.outer.inner*81) + (floordiv(threadIdx.x, 7)*9)) + floormod(threadIdx.x, 7)) + 10)]*kernel.shared_1[(cse_var_3 + 1732)]))
            conv2d_nchw_1[7] = (conv2d_nchw_1[7] + (pad_temp.shared_1[((((rc.outer.inner*81) + (floordiv(threadIdx.x, 7)*9)) + floormod(threadIdx.x, 7)) + 10)]*kernel.shared_1[(cse_var_3 + 4036)]))
            conv2d_nchw_1[2] = (conv2d_nchw_1[2] + (pad_temp.shared_1[((((rc.outer.inner*81) + (floordiv(threadIdx.x, 7)*9)) + floormod(threadIdx.x, 7)) + 11)]*kernel.shared_1[(cse_var_3 + 1157)]))
            conv2d_nchw_1[6] = (conv2d_nchw_1[6] + (pad_temp.shared_1[((((rc.outer.inner*81) + (floordiv(threadIdx.x, 7)*9)) + floormod(threadIdx.x, 7)) + 11)]*kernel.shared_1[(cse_var_3 + 3461)]))
            conv2d_nchw_1[3] = (conv2d_nchw_1[3] + (pad_temp.shared_1[((((rc.outer.inner*81) + (floordiv(threadIdx.x, 7)*9)) + floormod(threadIdx.x, 7)) + 11)]*kernel.shared_1[(cse_var_3 + 1733)]))
            conv2d_nchw_1[7] = (conv2d_nchw_1[7] + (pad_temp.shared_1[((((rc.outer.inner*81) + (floordiv(threadIdx.x, 7)*9)) + floormod(threadIdx.x, 7)) + 11)]*kernel.shared_1[(cse_var_3 + 4037)]))
            conv2d_nchw_1[0] = (conv2d_nchw_1[0] + (pad_temp.shared_1[((((rc.outer.inner*81) + (floordiv(threadIdx.x, 7)*9)) + floormod(threadIdx.x, 7)) + 18)]*kernel.shared_1[(cse_var_3 + 6)]))
            conv2d_nchw_1[4] = (conv2d_nchw_1[4] + (pad_temp.shared_1[((((rc.outer.inner*81) + (floordiv(threadIdx.x, 7)*9)) + floormod(threadIdx.x, 7)) + 18)]*kernel.shared_1[(cse_var_3 + 2310)]))
            conv2d_nchw_1[1] = (conv2d_nchw_1[1] + (pad_temp.shared_1[((((rc.outer.inner*81) + (floordiv(threadIdx.x, 7)*9)) + floormod(threadIdx.x, 7)) + 18)]*kernel.shared_1[(cse_var_3 + 582)]))
            conv2d_nchw_1[5] = (conv2d_nchw_1[5] + (pad_temp.shared_1[((((rc.outer.inner*81) + (floordiv(threadIdx.x, 7)*9)) + floormod(threadIdx.x, 7)) + 18)]*kernel.shared_1[(cse_var_3 + 2886)]))
            conv2d_nchw_1[0] = (conv2d_nchw_1[0] + (pad_temp.shared_1[((((rc.outer.inner*81) + (floordiv(threadIdx.x, 7)*9)) + floormod(threadIdx.x, 7)) + 19)]*kernel.shared_1[(cse_var_3 + 7)]))
            conv2d_nchw_1[4] = (conv2d_nchw_1[4] + (pad_temp.shared_1[((((rc.outer.inner*81) + (floordiv(threadIdx.x, 7)*9)) + floormod(threadIdx.x, 7)) + 19)]*kernel.shared_1[(cse_var_3 + 2311)]))
            conv2d_nchw_1[1] = (conv2d_nchw_1[1] + (pad_temp.shared_1[((((rc.outer.inner*81) + (floordiv(threadIdx.x, 7)*9)) + floormod(threadIdx.x, 7)) + 19)]*kernel.shared_1[(cse_var_3 + 583)]))
            conv2d_nchw_1[5] = (conv2d_nchw_1[5] + (pad_temp.shared_1[((((rc.outer.inner*81) + (floordiv(threadIdx.x, 7)*9)) + floormod(threadIdx.x, 7)) + 19)]*kernel.shared_1[(cse_var_3 + 2887)]))
            conv2d_nchw_1[0] = (conv2d_nchw_1[0] + (pad_temp.shared_1[((((rc.outer.inner*81) + (floordiv(threadIdx.x, 7)*9)) + floormod(threadIdx.x, 7)) + 20)]*kernel.shared_1[(cse_var_3 + 8)]))
            conv2d_nchw_1[4] = (conv2d_nchw_1[4] + (pad_temp.shared_1[((((rc.outer.inner*81) + (floordiv(threadIdx.x, 7)*9)) + floormod(threadIdx.x, 7)) + 20)]*kernel.shared_1[(cse_var_3 + 2312)]))
            conv2d_nchw_1[1] = (conv2d_nchw_1[1] + (pad_temp.shared_1[((((rc.outer.inner*81) + (floordiv(threadIdx.x, 7)*9)) + floormod(threadIdx.x, 7)) + 20)]*kernel.shared_1[(cse_var_3 + 584)]))
            conv2d_nchw_1[5] = (conv2d_nchw_1[5] + (pad_temp.shared_1[((((rc.outer.inner*81) + (floordiv(threadIdx.x, 7)*9)) + floormod(threadIdx.x, 7)) + 20)]*kernel.shared_1[(cse_var_3 + 2888)]))
            conv2d_nchw_1[2] = (conv2d_nchw_1[2] + (pad_temp.shared_1[((((rc.outer.inner*81) + (floordiv(threadIdx.x, 7)*9)) + floormod(threadIdx.x, 7)) + 18)]*kernel.shared_1[(cse_var_3 + 1158)]))
            conv2d_nchw_1[6] = (conv2d_nchw_1[6] + (pad_temp.shared_1[((((rc.outer.inner*81) + (floordiv(threadIdx.x, 7)*9)) + floormod(threadIdx.x, 7)) + 18)]*kernel.shared_1[(cse_var_3 + 3462)]))
            conv2d_nchw_1[3] = (conv2d_nchw_1[3] + (pad_temp.shared_1[((((rc.outer.inner*81) + (floordiv(threadIdx.x, 7)*9)) + floormod(threadIdx.x, 7)) + 18)]*kernel.shared_1[(cse_var_3 + 1734)]))
            conv2d_nchw_1[7] = (conv2d_nchw_1[7] + (pad_temp.shared_1[((((rc.outer.inner*81) + (floordiv(threadIdx.x, 7)*9)) + floormod(threadIdx.x, 7)) + 18)]*kernel.shared_1[(cse_var_3 + 4038)]))
            conv2d_nchw_1[2] = (conv2d_nchw_1[2] + (pad_temp.shared_1[((((rc.outer.inner*81) + (floordiv(threadIdx.x, 7)*9)) + floormod(threadIdx.x, 7)) + 19)]*kernel.shared_1[(cse_var_3 + 1159)]))
            conv2d_nchw_1[6] = (conv2d_nchw_1[6] + (pad_temp.shared_1[((((rc.outer.inner*81) + (floordiv(threadIdx.x, 7)*9)) + floormod(threadIdx.x, 7)) + 19)]*kernel.shared_1[(cse_var_3 + 3463)]))
            conv2d_nchw_1[3] = (conv2d_nchw_1[3] + (pad_temp.shared_1[((((rc.outer.inner*81) + (floordiv(threadIdx.x, 7)*9)) + floormod(threadIdx.x, 7)) + 19)]*kernel.shared_1[(cse_var_3 + 1735)]))
            conv2d_nchw_1[7] = (conv2d_nchw_1[7] + (pad_temp.shared_1[((((rc.outer.inner*81) + (floordiv(threadIdx.x, 7)*9)) + floormod(threadIdx.x, 7)) + 19)]*kernel.shared_1[(cse_var_3 + 4039)]))
            conv2d_nchw_1[2] = (conv2d_nchw_1[2] + (pad_temp.shared_1[((((rc.outer.inner*81) + (floordiv(threadIdx.x, 7)*9)) + floormod(threadIdx.x, 7)) + 20)]*kernel.shared_1[(cse_var_3 + 1160)]))
            conv2d_nchw_1[6] = (conv2d_nchw_1[6] + (pad_temp.shared_1[((((rc.outer.inner*81) + (floordiv(threadIdx.x, 7)*9)) + floormod(threadIdx.x, 7)) + 20)]*kernel.shared_1[(cse_var_3 + 3464)]))
            conv2d_nchw_1[3] = (conv2d_nchw_1[3] + (pad_temp.shared_1[((((rc.outer.inner*81) + (floordiv(threadIdx.x, 7)*9)) + floormod(threadIdx.x, 7)) + 20)]*kernel.shared_1[(cse_var_3 + 1736)]))
            conv2d_nchw_1[7] = (conv2d_nchw_1[7] + (pad_temp.shared_1[((((rc.outer.inner*81) + (floordiv(threadIdx.x, 7)*9)) + floormod(threadIdx.x, 7)) + 20)]*kernel.shared_1[(cse_var_3 + 4040)]))
          }
        }
      }
    }
    for (i1.inner: int32, 0, 4) {
      compute[(((blockIdx.x*392) + (i1.inner*49)) + threadIdx.x)] = max((conv2d_nchw_1[i1.inner] + bias[((blockIdx.x*8) + i1.inner)]), 0f32)
      compute[((((blockIdx.x*392) + (i1.inner*49)) + threadIdx.x) + 196)] = max((conv2d_nchw_1[(i1.inner + 4)] + bias[(((blockIdx.x*8) + i1.inner) + 4)]), 0f32)
    }
  }
}
</pre></div>
</div>
</div>
<div class="section" id="check-correctness-and-evaluate-performance">
<h2>Check correctness and evaluate performance<a class="headerlink" href="#check-correctness-and-evaluate-performance" title="Permalink to this headline">¶</a></h2>
<p>We build the binary and check its correctness and performance.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">func</span> <span class="o">=</span> <a href="../../reference/api/python/driver.html#tvm.build" title="tvm.build" class="sphx-glr-backref-module-tvm sphx-glr-backref-type-py-function"><span class="n">tvm</span><span class="o">.</span><span class="n">build</span></a><span class="p">(</span><a href="../../reference/api/python/te.html#tvm.te.Schedule" title="tvm.te.Schedule" class="sphx-glr-backref-module-tvm-te sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">sch</span></a><span class="p">,</span> <a href="../../reference/api/python/ir.html#tvm.ir.Array" title="tvm.ir.Array" class="sphx-glr-backref-module-tvm-ir sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">args</span></a><span class="p">,</span> <a href="../../reference/api/python/target.html#tvm.target.Target" title="tvm.target.Target" class="sphx-glr-backref-module-tvm-target sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">target</span></a><span class="p">)</span>

<span class="c1"># Check correctness</span>
<span class="n">data_np</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">N</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">CI</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">H</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">W</span></a><span class="p">))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">weight_np</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">CO</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">CI</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">KH</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">KW</span></a><span class="p">))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">bias_np</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <a href="https://docs.python.org/3/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">CO</span></a><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">conv_np</span> <span class="o">=</span> <span class="n">conv2d_nchw_python</span><span class="p">(</span><span class="n">data_np</span><span class="p">,</span> <span class="n">weight_np</span><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">strides</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">padding</span></a><span class="p">)</span>
<span class="n">out_np</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">maximum</span><span class="p">(</span><span class="n">conv_np</span> <span class="o">+</span> <span class="n">bias_np</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">)</span>

<span class="n">dev</span> <span class="o">=</span> <span class="n">tvm</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>
<span class="n">data_tvm</span> <span class="o">=</span> <a href="../../reference/api/python/ndarray.html#tvm.nd.array" title="tvm.nd.array" class="sphx-glr-backref-module-tvm-nd sphx-glr-backref-type-py-function"><span class="n">tvm</span><span class="o">.</span><span class="n">nd</span><span class="o">.</span><span class="n">array</span></a><span class="p">(</span><span class="n">data_np</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">dev</span><span class="p">)</span>
<span class="n">weight_tvm</span> <span class="o">=</span> <a href="../../reference/api/python/ndarray.html#tvm.nd.array" title="tvm.nd.array" class="sphx-glr-backref-module-tvm-nd sphx-glr-backref-type-py-function"><span class="n">tvm</span><span class="o">.</span><span class="n">nd</span><span class="o">.</span><span class="n">array</span></a><span class="p">(</span><span class="n">weight_np</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">dev</span><span class="p">)</span>
<span class="n">bias_tvm</span> <span class="o">=</span> <a href="../../reference/api/python/ndarray.html#tvm.nd.array" title="tvm.nd.array" class="sphx-glr-backref-module-tvm-nd sphx-glr-backref-type-py-function"><span class="n">tvm</span><span class="o">.</span><span class="n">nd</span><span class="o">.</span><span class="n">array</span></a><span class="p">(</span><span class="n">bias_np</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">dev</span><span class="p">)</span>
<span class="n">out_tvm</span> <span class="o">=</span> <a href="../../reference/api/python/ndarray.html#tvm.nd.empty" title="tvm.nd.empty" class="sphx-glr-backref-module-tvm-nd sphx-glr-backref-type-py-function"><span class="n">tvm</span><span class="o">.</span><span class="n">nd</span><span class="o">.</span><span class="n">empty</span></a><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">out_np</span><span class="o">.</span><span class="n">shape</span></a><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">dev</span><span class="p">)</span>
<span class="n">func</span><span class="p">(</span><span class="n">data_tvm</span><span class="p">,</span> <span class="n">weight_tvm</span><span class="p">,</span> <span class="n">bias_tvm</span><span class="p">,</span> <span class="n">out_tvm</span><span class="p">)</span>

<span class="c1"># Check results</span>
<span class="n">np</span><span class="o">.</span><span class="n">testing</span><span class="o">.</span><span class="n">assert_allclose</span><span class="p">(</span><span class="n">out_np</span><span class="p">,</span> <span class="n">out_tvm</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">rtol</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">)</span>

<span class="c1"># Evaluate execution time</span>
<span class="n">evaluator</span> <span class="o">=</span> <a href="../../reference/api/python/runtime.html#tvm.runtime.Module.time_evaluator" title="tvm.runtime.Module.time_evaluator" class="sphx-glr-backref-module-tvm-runtime sphx-glr-backref-type-py-method"><span class="n">func</span><span class="o">.</span><span class="n">time_evaluator</span></a><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">func</span><span class="o">.</span><span class="n">entry_name</span></a><span class="p">,</span> <span class="n">dev</span><span class="p">,</span> <span class="n">min_repeat_ms</span><span class="o">=</span><span class="mi">500</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span>
    <span class="s2">&quot;Execution time of this operator: </span><span class="si">%.3f</span><span class="s2"> ms&quot;</span>
    <span class="o">%</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">median</span><span class="p">(</span><span class="n">evaluator</span><span class="p">(</span><span class="n">data_tvm</span><span class="p">,</span> <span class="n">weight_tvm</span><span class="p">,</span> <span class="n">bias_tvm</span><span class="p">,</span> <span class="n">out_tvm</span><span class="p">)</span><span class="o">.</span><span class="n">results</span><span class="p">)</span> <span class="o">*</span> <span class="mi">1000</span><span class="p">)</span>
<span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Execution time of this operator: 0.326 ms
</pre></div>
</div>
</div>
<div class="section" id="using-the-record-file">
<h2>Using the record file<a class="headerlink" href="#using-the-record-file" title="Permalink to this headline">¶</a></h2>
<p>During the search, all measurement records are dumped into the record
file “conv2d.json”. The measurement records can be used to re-apply search results,
resume the search, and perform other analyses.</p>
<p>Here is an example where we load the best schedule from a file,
print the equivalent python schedule API and CUDA source code.
They can be used for debugging and learning the behavior of the auto-scheduler.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Equivalent python schedule:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><a href="../../reference/api/python/auto_scheduler.html#tvm.auto_scheduler.SearchTask.print_best" title="tvm.auto_scheduler.SearchTask.print_best" class="sphx-glr-backref-module-tvm-auto_scheduler sphx-glr-backref-type-py-method"><span class="n">task</span><span class="o">.</span><span class="n">print_best</span></a><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">log_file</span></a><span class="p">,</span> <span class="n">print_mode</span><span class="o">=</span><span class="s2">&quot;schedule&quot;</span><span class="p">))</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;CUDA source code:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><a href="../../reference/api/python/auto_scheduler.html#tvm.auto_scheduler.SearchTask.print_best" title="tvm.auto_scheduler.SearchTask.print_best" class="sphx-glr-backref-module-tvm-auto_scheduler sphx-glr-backref-type-py-method"><span class="n">task</span><span class="o">.</span><span class="n">print_best</span></a><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">log_file</span></a><span class="p">,</span> <span class="n">print_mode</span><span class="o">=</span><span class="s2">&quot;cuda&quot;</span><span class="p">))</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Equivalent python schedule:
pad_temp_i0, pad_temp_i1, pad_temp_i2, pad_temp_i3 = tuple(pad_temp.op.axis) + tuple(pad_temp.op.reduce_axis)
conv2d_nchw_nn, conv2d_nchw_ff, conv2d_nchw_yy, conv2d_nchw_xx, conv2d_nchw_rc, conv2d_nchw_ry, conv2d_nchw_rx = tuple(conv2d_nchw.op.axis) + tuple(conv2d_nchw.op.reduce_axis)
T_add_ax0, T_add_ax1, T_add_ax2, T_add_ax3 = tuple(T_add.op.axis) + tuple(T_add.op.reduce_axis)
compute_i0, compute_i1, compute_i2, compute_i3 = tuple(compute.op.axis) + tuple(compute.op.reduce_axis)
s[T_add].compute_inline()
conv2d_nchw_nn_o_i, conv2d_nchw_nn_i = s[conv2d_nchw].split(conv2d_nchw_nn, factor=1)
conv2d_nchw_nn_o_o_i, conv2d_nchw_nn_o_i = s[conv2d_nchw].split(conv2d_nchw_nn_o_i, factor=1)
conv2d_nchw_nn_o_o_o_i, conv2d_nchw_nn_o_o_i = s[conv2d_nchw].split(conv2d_nchw_nn_o_o_i, factor=1)
conv2d_nchw_nn_o_o_o_o, conv2d_nchw_nn_o_o_o_i = s[conv2d_nchw].split(conv2d_nchw_nn_o_o_o_i, factor=1)
conv2d_nchw_ff_o_i, conv2d_nchw_ff_i = s[conv2d_nchw].split(conv2d_nchw_ff, factor=2)
conv2d_nchw_ff_o_o_i, conv2d_nchw_ff_o_i = s[conv2d_nchw].split(conv2d_nchw_ff_o_i, factor=2)
conv2d_nchw_ff_o_o_o_i, conv2d_nchw_ff_o_o_i = s[conv2d_nchw].split(conv2d_nchw_ff_o_o_i, factor=1)
conv2d_nchw_ff_o_o_o_o, conv2d_nchw_ff_o_o_o_i = s[conv2d_nchw].split(conv2d_nchw_ff_o_o_o_i, factor=2)
conv2d_nchw_yy_o_i, conv2d_nchw_yy_i = s[conv2d_nchw].split(conv2d_nchw_yy, factor=1)
conv2d_nchw_yy_o_o_i, conv2d_nchw_yy_o_i = s[conv2d_nchw].split(conv2d_nchw_yy_o_i, factor=1)
conv2d_nchw_yy_o_o_o_i, conv2d_nchw_yy_o_o_i = s[conv2d_nchw].split(conv2d_nchw_yy_o_o_i, factor=7)
conv2d_nchw_yy_o_o_o_o, conv2d_nchw_yy_o_o_o_i = s[conv2d_nchw].split(conv2d_nchw_yy_o_o_o_i, factor=1)
conv2d_nchw_xx_o_i, conv2d_nchw_xx_i = s[conv2d_nchw].split(conv2d_nchw_xx, factor=1)
conv2d_nchw_xx_o_o_i, conv2d_nchw_xx_o_i = s[conv2d_nchw].split(conv2d_nchw_xx_o_i, factor=1)
conv2d_nchw_xx_o_o_o_i, conv2d_nchw_xx_o_o_i = s[conv2d_nchw].split(conv2d_nchw_xx_o_o_i, factor=7)
conv2d_nchw_xx_o_o_o_o, conv2d_nchw_xx_o_o_o_i = s[conv2d_nchw].split(conv2d_nchw_xx_o_o_o_i, factor=1)
conv2d_nchw_rc_o_i, conv2d_nchw_rc_i = s[conv2d_nchw].split(conv2d_nchw_rc, factor=1)
conv2d_nchw_rc_o_o, conv2d_nchw_rc_o_i = s[conv2d_nchw].split(conv2d_nchw_rc_o_i, factor=64)
conv2d_nchw_ry_o_i, conv2d_nchw_ry_i = s[conv2d_nchw].split(conv2d_nchw_ry, factor=1)
conv2d_nchw_ry_o_o, conv2d_nchw_ry_o_i = s[conv2d_nchw].split(conv2d_nchw_ry_o_i, factor=3)
conv2d_nchw_rx_o_i, conv2d_nchw_rx_i = s[conv2d_nchw].split(conv2d_nchw_rx, factor=3)
conv2d_nchw_rx_o_o, conv2d_nchw_rx_o_i = s[conv2d_nchw].split(conv2d_nchw_rx_o_i, factor=1)
s[conv2d_nchw].reorder(conv2d_nchw_nn_o_o_o_o, conv2d_nchw_ff_o_o_o_o, conv2d_nchw_yy_o_o_o_o, conv2d_nchw_xx_o_o_o_o, conv2d_nchw_nn_o_o_o_i, conv2d_nchw_ff_o_o_o_i, conv2d_nchw_yy_o_o_o_i, conv2d_nchw_xx_o_o_o_i, conv2d_nchw_nn_o_o_i, conv2d_nchw_ff_o_o_i, conv2d_nchw_yy_o_o_i, conv2d_nchw_xx_o_o_i, conv2d_nchw_rc_o_o, conv2d_nchw_ry_o_o, conv2d_nchw_rx_o_o, conv2d_nchw_rc_o_i, conv2d_nchw_ry_o_i, conv2d_nchw_rx_o_i, conv2d_nchw_nn_o_i, conv2d_nchw_ff_o_i, conv2d_nchw_yy_o_i, conv2d_nchw_xx_o_i, conv2d_nchw_rc_i, conv2d_nchw_ry_i, conv2d_nchw_rx_i, conv2d_nchw_nn_i, conv2d_nchw_ff_i, conv2d_nchw_yy_i, conv2d_nchw_xx_i)
compute_i0_o_i, compute_i0_i = s[compute].split(compute_i0, factor=1)
compute_i0_o_o_i, compute_i0_o_i = s[compute].split(compute_i0_o_i, factor=1)
compute_i0_o_o_o, compute_i0_o_o_i = s[compute].split(compute_i0_o_o_i, factor=1)
compute_i1_o_i, compute_i1_i = s[compute].split(compute_i1, factor=4)
compute_i1_o_o_i, compute_i1_o_i = s[compute].split(compute_i1_o_i, factor=1)
compute_i1_o_o_o, compute_i1_o_o_i = s[compute].split(compute_i1_o_o_i, factor=2)
compute_i2_o_i, compute_i2_i = s[compute].split(compute_i2, factor=1)
compute_i2_o_o_i, compute_i2_o_i = s[compute].split(compute_i2_o_i, factor=7)
compute_i2_o_o_o, compute_i2_o_o_i = s[compute].split(compute_i2_o_o_i, factor=1)
compute_i3_o_i, compute_i3_i = s[compute].split(compute_i3, factor=1)
compute_i3_o_o_i, compute_i3_o_i = s[compute].split(compute_i3_o_i, factor=7)
compute_i3_o_o_o, compute_i3_o_o_i = s[compute].split(compute_i3_o_o_i, factor=1)
s[compute].reorder(compute_i0_o_o_o, compute_i1_o_o_o, compute_i2_o_o_o, compute_i3_o_o_o, compute_i0_o_o_i, compute_i1_o_o_i, compute_i2_o_o_i, compute_i3_o_o_i, compute_i0_o_i, compute_i1_o_i, compute_i2_o_i, compute_i3_o_i, compute_i0_i, compute_i1_i, compute_i2_i, compute_i3_i)
s[conv2d_nchw].compute_at(s[compute], compute_i3_o_i)
kernel_shared = s.cache_read(kernel, &quot;shared&quot;, [conv2d_nchw])
kernel_shared_ax0, kernel_shared_ax1, kernel_shared_ax2, kernel_shared_ax3 = tuple(kernel_shared.op.axis)
s[kernel_shared].compute_at(s[conv2d_nchw], conv2d_nchw_rx_o_o)
pad_temp_shared = s.cache_read(pad_temp, &quot;shared&quot;, [conv2d_nchw])
pad_temp_shared_ax0, pad_temp_shared_ax1, pad_temp_shared_ax2, pad_temp_shared_ax3 = tuple(pad_temp_shared.op.axis)
s[pad_temp_shared].compute_at(s[conv2d_nchw], conv2d_nchw_rx_o_o)
s[pad_temp].compute_inline()
compute_i0_o_o_o_i1_o_o_o_fused_i2_o_o_o_fused_i3_o_o_o_fused = s[compute].fuse(compute_i0_o_o_o, compute_i1_o_o_o, compute_i2_o_o_o, compute_i3_o_o_o)
s[compute].bind(compute_i0_o_o_o_i1_o_o_o_fused_i2_o_o_o_fused_i3_o_o_o_fused, te.thread_axis(&quot;blockIdx.x&quot;))
compute_i0_o_o_i_i1_o_o_i_fused_i2_o_o_i_fused_i3_o_o_i_fused = s[compute].fuse(compute_i0_o_o_i, compute_i1_o_o_i, compute_i2_o_o_i, compute_i3_o_o_i)
s[compute].bind(compute_i0_o_o_i_i1_o_o_i_fused_i2_o_o_i_fused_i3_o_o_i_fused, te.thread_axis(&quot;vthread&quot;))
compute_i0_o_i_i1_o_i_fused_i2_o_i_fused_i3_o_i_fused = s[compute].fuse(compute_i0_o_i, compute_i1_o_i, compute_i2_o_i, compute_i3_o_i)
s[compute].bind(compute_i0_o_i_i1_o_i_fused_i2_o_i_fused_i3_o_i_fused, te.thread_axis(&quot;threadIdx.x&quot;))
kernel_shared_ax0_ax1_fused_ax2_fused_ax3_fused = s[kernel_shared].fuse(kernel_shared_ax0, kernel_shared_ax1, kernel_shared_ax2, kernel_shared_ax3)
kernel_shared_ax0_ax1_fused_ax2_fused_ax3_fused_o, kernel_shared_ax0_ax1_fused_ax2_fused_ax3_fused_i = s[kernel_shared].split(kernel_shared_ax0_ax1_fused_ax2_fused_ax3_fused, factor=3)
s[kernel_shared].vectorize(kernel_shared_ax0_ax1_fused_ax2_fused_ax3_fused_i)
kernel_shared_ax0_ax1_fused_ax2_fused_ax3_fused_o_o, kernel_shared_ax0_ax1_fused_ax2_fused_ax3_fused_o_i = s[kernel_shared].split(kernel_shared_ax0_ax1_fused_ax2_fused_ax3_fused_o, factor=49)
s[kernel_shared].bind(kernel_shared_ax0_ax1_fused_ax2_fused_ax3_fused_o_i, te.thread_axis(&quot;threadIdx.x&quot;))
pad_temp_shared_ax0_ax1_fused_ax2_fused_ax3_fused = s[pad_temp_shared].fuse(pad_temp_shared_ax0, pad_temp_shared_ax1, pad_temp_shared_ax2, pad_temp_shared_ax3)
pad_temp_shared_ax0_ax1_fused_ax2_fused_ax3_fused_o, pad_temp_shared_ax0_ax1_fused_ax2_fused_ax3_fused_i = s[pad_temp_shared].split(pad_temp_shared_ax0_ax1_fused_ax2_fused_ax3_fused, factor=12)
s[pad_temp_shared].vectorize(pad_temp_shared_ax0_ax1_fused_ax2_fused_ax3_fused_i)
pad_temp_shared_ax0_ax1_fused_ax2_fused_ax3_fused_o_o, pad_temp_shared_ax0_ax1_fused_ax2_fused_ax3_fused_o_i = s[pad_temp_shared].split(pad_temp_shared_ax0_ax1_fused_ax2_fused_ax3_fused_o, factor=49)
s[pad_temp_shared].bind(pad_temp_shared_ax0_ax1_fused_ax2_fused_ax3_fused_o_i, te.thread_axis(&quot;threadIdx.x&quot;))
s[conv2d_nchw].pragma(conv2d_nchw_nn_o_o_o_o, &quot;auto_unroll_max_step&quot;, 1024)
s[conv2d_nchw].pragma(conv2d_nchw_nn_o_o_o_o, &quot;unroll_explicit&quot;, True)

CUDA source code:

#ifdef _WIN32
  using uint = unsigned int;
  using uchar = unsigned char;
  using ushort = unsigned short;
  using int64_t = long long;
  using uint64_t = unsigned long long;
#else
  #define uint unsigned int
  #define uchar unsigned char
  #define ushort unsigned short
  #define int64_t long long
  #define uint64_t unsigned long long
#endif
extern &quot;C&quot; __global__ void __launch_bounds__(49) default_function_kernel0(float* __restrict__ data, float* __restrict__ kernel, float* __restrict__ compute, float* __restrict__ bias) {
  float conv2d_nchw[8];
  __shared__ float pad_temp_shared[5184];
  __shared__ float kernel_shared[4608];
  conv2d_nchw[0] = 0.000000e+00f;
  conv2d_nchw[4] = 0.000000e+00f;
  conv2d_nchw[1] = 0.000000e+00f;
  conv2d_nchw[5] = 0.000000e+00f;
  conv2d_nchw[2] = 0.000000e+00f;
  conv2d_nchw[6] = 0.000000e+00f;
  conv2d_nchw[3] = 0.000000e+00f;
  conv2d_nchw[7] = 0.000000e+00f;
  for (int rc_outer_outer = 0; rc_outer_outer &lt; 8; ++rc_outer_outer) {
    __syncthreads();
    pad_temp_shared[(((int)threadIdx.x) * 12)] = ((((3 &lt;= ((((int)threadIdx.x) * 4) % 27)) &amp;&amp; (((((int)threadIdx.x) * 12) % 81) &lt; 72)) &amp;&amp; (1 &lt;= (((int)threadIdx.x) % 3))) ? data[(((((rc_outer_outer * 3136) + (((((int)threadIdx.x) * 4) / 27) * 49)) + ((((((int)threadIdx.x) * 4) % 27) / 3) * 7)) + ((((int)threadIdx.x) % 3) * 3)) - 8)] : 0.000000e+00f);
    pad_temp_shared[((((int)threadIdx.x) * 12) + 1)] = (((3 &lt;= ((((int)threadIdx.x) * 4) % 27)) &amp;&amp; ((((((int)threadIdx.x) * 12) + 1) % 81) &lt; 72)) ? data[(((((rc_outer_outer * 3136) + (((((int)threadIdx.x) * 4) / 27) * 49)) + ((((((int)threadIdx.x) * 4) % 27) / 3) * 7)) + ((((int)threadIdx.x) % 3) * 3)) - 7)] : 0.000000e+00f);
    pad_temp_shared[((((int)threadIdx.x) * 12) + 2)] = ((((3 &lt;= ((((int)threadIdx.x) * 4) % 27)) &amp;&amp; ((((((int)threadIdx.x) * 12) + 2) % 81) &lt; 72)) &amp;&amp; ((((int)threadIdx.x) % 3) &lt; 2)) ? data[(((((rc_outer_outer * 3136) + (((((int)threadIdx.x) * 4) / 27) * 49)) + ((((((int)threadIdx.x) * 4) % 27) / 3) * 7)) + ((((int)threadIdx.x) % 3) * 3)) - 6)] : 0.000000e+00f);
    pad_temp_shared[((((int)threadIdx.x) * 12) + 3)] = (((((3 &lt;= (((((int)threadIdx.x) * 4) + 1) % 27)) &amp;&amp; ((((((int)threadIdx.x) * 12) + 3) % 81) &lt; 72)) &amp;&amp; (1 &lt;= (((((int)threadIdx.x) * 3) + 3) % 9))) &amp;&amp; ((((((int)threadIdx.x) * 3) + 3) % 9) &lt; 8)) ? data[(((((rc_outer_outer * 3136) + ((((((int)threadIdx.x) * 4) + 1) / 27) * 49)) + (((((((int)threadIdx.x) * 4) + 1) % 27) / 3) * 7)) + (((((int)threadIdx.x) * 3) + 3) % 9)) - 8)] : 0.000000e+00f);
    pad_temp_shared[((((int)threadIdx.x) * 12) + 4)] = (((((3 &lt;= (((((int)threadIdx.x) * 4) + 1) % 27)) &amp;&amp; ((((((int)threadIdx.x) * 12) + 4) % 81) &lt; 72)) &amp;&amp; (1 &lt;= (((((int)threadIdx.x) * 3) + 4) % 9))) &amp;&amp; ((((((int)threadIdx.x) * 3) + 4) % 9) &lt; 8)) ? data[(((((rc_outer_outer * 3136) + ((((((int)threadIdx.x) * 4) + 1) / 27) * 49)) + (((((((int)threadIdx.x) * 4) + 1) % 27) / 3) * 7)) + (((((int)threadIdx.x) * 3) + 4) % 9)) - 8)] : 0.000000e+00f);
    pad_temp_shared[((((int)threadIdx.x) * 12) + 5)] = (((((3 &lt;= (((((int)threadIdx.x) * 4) + 1) % 27)) &amp;&amp; ((((((int)threadIdx.x) * 12) + 5) % 81) &lt; 72)) &amp;&amp; (1 &lt;= (((((int)threadIdx.x) * 3) + 5) % 9))) &amp;&amp; ((((((int)threadIdx.x) * 3) + 5) % 9) &lt; 8)) ? data[(((((rc_outer_outer * 3136) + ((((((int)threadIdx.x) * 4) + 1) / 27) * 49)) + (((((((int)threadIdx.x) * 4) + 1) % 27) / 3) * 7)) + (((((int)threadIdx.x) * 3) + 5) % 9)) - 8)] : 0.000000e+00f);
    pad_temp_shared[((((int)threadIdx.x) * 12) + 6)] = (((((3 &lt;= (((((int)threadIdx.x) * 4) + 2) % 27)) &amp;&amp; ((((((int)threadIdx.x) * 12) + 6) % 81) &lt; 72)) &amp;&amp; (1 &lt;= (((((int)threadIdx.x) * 3) + 6) % 9))) &amp;&amp; ((((((int)threadIdx.x) * 3) + 6) % 9) &lt; 8)) ? data[(((((rc_outer_outer * 3136) + ((((((int)threadIdx.x) * 4) + 2) / 27) * 49)) + (((((((int)threadIdx.x) * 4) + 2) % 27) / 3) * 7)) + (((((int)threadIdx.x) * 3) + 6) % 9)) - 8)] : 0.000000e+00f);
    pad_temp_shared[((((int)threadIdx.x) * 12) + 7)] = (((((3 &lt;= (((((int)threadIdx.x) * 4) + 2) % 27)) &amp;&amp; ((((((int)threadIdx.x) * 12) + 7) % 81) &lt; 72)) &amp;&amp; (1 &lt;= (((((int)threadIdx.x) * 3) + 7) % 9))) &amp;&amp; ((((((int)threadIdx.x) * 3) + 7) % 9) &lt; 8)) ? data[(((((rc_outer_outer * 3136) + ((((((int)threadIdx.x) * 4) + 2) / 27) * 49)) + (((((((int)threadIdx.x) * 4) + 2) % 27) / 3) * 7)) + (((((int)threadIdx.x) * 3) + 7) % 9)) - 8)] : 0.000000e+00f);
    pad_temp_shared[((((int)threadIdx.x) * 12) + 8)] = (((((3 &lt;= (((((int)threadIdx.x) * 4) + 2) % 27)) &amp;&amp; ((((((int)threadIdx.x) * 12) + 8) % 81) &lt; 72)) &amp;&amp; (1 &lt;= (((((int)threadIdx.x) * 3) + 8) % 9))) &amp;&amp; ((((((int)threadIdx.x) * 3) + 8) % 9) &lt; 8)) ? data[(((((rc_outer_outer * 3136) + ((((((int)threadIdx.x) * 4) + 2) / 27) * 49)) + (((((((int)threadIdx.x) * 4) + 2) % 27) / 3) * 7)) + (((((int)threadIdx.x) * 3) + 8) % 9)) - 8)] : 0.000000e+00f);
    pad_temp_shared[((((int)threadIdx.x) * 12) + 9)] = ((((1 &lt;= ((((((int)threadIdx.x) * 4) / 3) + 1) % 9)) &amp;&amp; ((((((int)threadIdx.x) * 12) + 9) % 81) &lt; 72)) &amp;&amp; (1 &lt;= (((int)threadIdx.x) % 3))) ? data[(((((rc_outer_outer * 3136) + ((((((int)threadIdx.x) * 4) + 3) / 27) * 49)) + (((((((int)threadIdx.x) * 4) / 3) + 1) % 9) * 7)) + ((((int)threadIdx.x) % 3) * 3)) - 8)] : 0.000000e+00f);
    pad_temp_shared[((((int)threadIdx.x) * 12) + 10)] = (((1 &lt;= ((((((int)threadIdx.x) * 4) / 3) + 1) % 9)) &amp;&amp; ((((((int)threadIdx.x) * 12) + 10) % 81) &lt; 72)) ? data[(((((rc_outer_outer * 3136) + ((((((int)threadIdx.x) * 4) + 3) / 27) * 49)) + (((((((int)threadIdx.x) * 4) / 3) + 1) % 9) * 7)) + ((((int)threadIdx.x) % 3) * 3)) - 7)] : 0.000000e+00f);
    pad_temp_shared[((((int)threadIdx.x) * 12) + 11)] = ((((1 &lt;= ((((((int)threadIdx.x) * 4) / 3) + 1) % 9)) &amp;&amp; ((((((int)threadIdx.x) * 12) + 11) % 81) &lt; 72)) &amp;&amp; ((((int)threadIdx.x) % 3) &lt; 2)) ? data[(((((rc_outer_outer * 3136) + ((((((int)threadIdx.x) * 4) + 3) / 27) * 49)) + (((((((int)threadIdx.x) * 4) / 3) + 1) % 9) * 7)) + ((((int)threadIdx.x) % 3) * 3)) - 6)] : 0.000000e+00f);
    pad_temp_shared[((((int)threadIdx.x) * 12) + 588)] = (((((3 &lt;= (((((int)threadIdx.x) * 4) + 7) % 27)) &amp;&amp; ((((((int)threadIdx.x) * 12) + 21) % 81) &lt; 72)) &amp;&amp; (1 &lt;= (((((int)threadIdx.x) * 3) + 3) % 9))) &amp;&amp; ((((((int)threadIdx.x) * 3) + 3) % 9) &lt; 8)) ? data[(((((rc_outer_outer * 3136) + ((((((int)threadIdx.x) * 4) + 196) / 27) * 49)) + (((((((int)threadIdx.x) * 4) + 7) % 27) / 3) * 7)) + (((((int)threadIdx.x) * 3) + 3) % 9)) - 8)] : 0.000000e+00f);
    pad_temp_shared[((((int)threadIdx.x) * 12) + 589)] = (((((3 &lt;= (((((int)threadIdx.x) * 4) + 7) % 27)) &amp;&amp; ((((((int)threadIdx.x) * 12) + 22) % 81) &lt; 72)) &amp;&amp; (1 &lt;= (((((int)threadIdx.x) * 3) + 4) % 9))) &amp;&amp; ((((((int)threadIdx.x) * 3) + 4) % 9) &lt; 8)) ? data[(((((rc_outer_outer * 3136) + ((((((int)threadIdx.x) * 4) + 196) / 27) * 49)) + (((((((int)threadIdx.x) * 4) + 7) % 27) / 3) * 7)) + (((((int)threadIdx.x) * 3) + 4) % 9)) - 8)] : 0.000000e+00f);
    pad_temp_shared[((((int)threadIdx.x) * 12) + 590)] = (((((3 &lt;= (((((int)threadIdx.x) * 4) + 7) % 27)) &amp;&amp; ((((((int)threadIdx.x) * 12) + 23) % 81) &lt; 72)) &amp;&amp; (1 &lt;= (((((int)threadIdx.x) * 3) + 5) % 9))) &amp;&amp; ((((((int)threadIdx.x) * 3) + 5) % 9) &lt; 8)) ? data[(((((rc_outer_outer * 3136) + ((((((int)threadIdx.x) * 4) + 196) / 27) * 49)) + (((((((int)threadIdx.x) * 4) + 7) % 27) / 3) * 7)) + (((((int)threadIdx.x) * 3) + 5) % 9)) - 8)] : 0.000000e+00f);
    pad_temp_shared[((((int)threadIdx.x) * 12) + 591)] = (((((3 &lt;= (((((int)threadIdx.x) * 4) + 8) % 27)) &amp;&amp; ((((((int)threadIdx.x) * 12) + 24) % 81) &lt; 72)) &amp;&amp; (1 &lt;= (((((int)threadIdx.x) * 3) + 6) % 9))) &amp;&amp; ((((((int)threadIdx.x) * 3) + 6) % 9) &lt; 8)) ? data[(((((rc_outer_outer * 3136) + ((((((int)threadIdx.x) * 4) + 197) / 27) * 49)) + (((((((int)threadIdx.x) * 4) + 8) % 27) / 3) * 7)) + (((((int)threadIdx.x) * 3) + 6) % 9)) - 8)] : 0.000000e+00f);
    pad_temp_shared[((((int)threadIdx.x) * 12) + 592)] = (((((3 &lt;= (((((int)threadIdx.x) * 4) + 8) % 27)) &amp;&amp; ((((((int)threadIdx.x) * 12) + 25) % 81) &lt; 72)) &amp;&amp; (1 &lt;= (((((int)threadIdx.x) * 3) + 7) % 9))) &amp;&amp; ((((((int)threadIdx.x) * 3) + 7) % 9) &lt; 8)) ? data[(((((rc_outer_outer * 3136) + ((((((int)threadIdx.x) * 4) + 197) / 27) * 49)) + (((((((int)threadIdx.x) * 4) + 8) % 27) / 3) * 7)) + (((((int)threadIdx.x) * 3) + 7) % 9)) - 8)] : 0.000000e+00f);
    pad_temp_shared[((((int)threadIdx.x) * 12) + 593)] = (((((3 &lt;= (((((int)threadIdx.x) * 4) + 8) % 27)) &amp;&amp; ((((((int)threadIdx.x) * 12) + 26) % 81) &lt; 72)) &amp;&amp; (1 &lt;= (((((int)threadIdx.x) * 3) + 8) % 9))) &amp;&amp; ((((((int)threadIdx.x) * 3) + 8) % 9) &lt; 8)) ? data[(((((rc_outer_outer * 3136) + ((((((int)threadIdx.x) * 4) + 197) / 27) * 49)) + (((((((int)threadIdx.x) * 4) + 8) % 27) / 3) * 7)) + (((((int)threadIdx.x) * 3) + 8) % 9)) - 8)] : 0.000000e+00f);
    pad_temp_shared[((((int)threadIdx.x) * 12) + 594)] = ((((1 &lt;= ((((((int)threadIdx.x) * 4) / 3) + 3) % 9)) &amp;&amp; ((((((int)threadIdx.x) * 12) + 27) % 81) &lt; 72)) &amp;&amp; (1 &lt;= (((int)threadIdx.x) % 3))) ? data[(((((rc_outer_outer * 3136) + ((((((int)threadIdx.x) * 4) + 198) / 27) * 49)) + (((((((int)threadIdx.x) * 4) / 3) + 3) % 9) * 7)) + ((((int)threadIdx.x) % 3) * 3)) - 8)] : 0.000000e+00f);
    pad_temp_shared[((((int)threadIdx.x) * 12) + 595)] = (((1 &lt;= ((((((int)threadIdx.x) * 4) / 3) + 3) % 9)) &amp;&amp; ((((((int)threadIdx.x) * 12) + 28) % 81) &lt; 72)) ? data[(((((rc_outer_outer * 3136) + ((((((int)threadIdx.x) * 4) + 198) / 27) * 49)) + (((((((int)threadIdx.x) * 4) / 3) + 3) % 9) * 7)) + ((((int)threadIdx.x) % 3) * 3)) - 7)] : 0.000000e+00f);
    pad_temp_shared[((((int)threadIdx.x) * 12) + 596)] = ((((1 &lt;= ((((((int)threadIdx.x) * 4) / 3) + 3) % 9)) &amp;&amp; ((((((int)threadIdx.x) * 12) + 29) % 81) &lt; 72)) &amp;&amp; ((((int)threadIdx.x) % 3) &lt; 2)) ? data[(((((rc_outer_outer * 3136) + ((((((int)threadIdx.x) * 4) + 198) / 27) * 49)) + (((((((int)threadIdx.x) * 4) / 3) + 3) % 9) * 7)) + ((((int)threadIdx.x) % 3) * 3)) - 6)] : 0.000000e+00f);
    pad_temp_shared[((((int)threadIdx.x) * 12) + 597)] = (((((1 &lt;= (((((((int)threadIdx.x) * 4) + 196) / 3) + 1) % 9)) &amp;&amp; ((((((int)threadIdx.x) * 12) + 30) % 81) &lt; 72)) &amp;&amp; (1 &lt;= (((((int)threadIdx.x) * 3) + 3) % 9))) &amp;&amp; ((((((int)threadIdx.x) * 3) + 3) % 9) &lt; 8)) ? data[(((((rc_outer_outer * 3136) + ((((((int)threadIdx.x) * 4) + 199) / 27) * 49)) + ((((((((int)threadIdx.x) * 4) + 196) / 3) + 1) % 9) * 7)) + (((((int)threadIdx.x) * 3) + 3) % 9)) - 8)] : 0.000000e+00f);
    pad_temp_shared[((((int)threadIdx.x) * 12) + 598)] = (((((1 &lt;= (((((((int)threadIdx.x) * 4) + 196) / 3) + 1) % 9)) &amp;&amp; ((((((int)threadIdx.x) * 12) + 31) % 81) &lt; 72)) &amp;&amp; (1 &lt;= (((((int)threadIdx.x) * 3) + 4) % 9))) &amp;&amp; ((((((int)threadIdx.x) * 3) + 4) % 9) &lt; 8)) ? data[(((((rc_outer_outer * 3136) + ((((((int)threadIdx.x) * 4) + 199) / 27) * 49)) + ((((((((int)threadIdx.x) * 4) + 196) / 3) + 1) % 9) * 7)) + (((((int)threadIdx.x) * 3) + 4) % 9)) - 8)] : 0.000000e+00f);
    pad_temp_shared[((((int)threadIdx.x) * 12) + 599)] = (((((1 &lt;= (((((((int)threadIdx.x) * 4) + 196) / 3) + 1) % 9)) &amp;&amp; ((((((int)threadIdx.x) * 12) + 32) % 81) &lt; 72)) &amp;&amp; (1 &lt;= (((((int)threadIdx.x) * 3) + 5) % 9))) &amp;&amp; ((((((int)threadIdx.x) * 3) + 5) % 9) &lt; 8)) ? data[(((((rc_outer_outer * 3136) + ((((((int)threadIdx.x) * 4) + 199) / 27) * 49)) + ((((((((int)threadIdx.x) * 4) + 196) / 3) + 1) % 9) * 7)) + (((((int)threadIdx.x) * 3) + 5) % 9)) - 8)] : 0.000000e+00f);
    pad_temp_shared[((((int)threadIdx.x) * 12) + 1176)] = (((((3 &lt;= (((((int)threadIdx.x) * 4) + 14) % 27)) &amp;&amp; ((((((int)threadIdx.x) * 12) + 42) % 81) &lt; 72)) &amp;&amp; (1 &lt;= (((((int)threadIdx.x) * 3) + 6) % 9))) &amp;&amp; ((((((int)threadIdx.x) * 3) + 6) % 9) &lt; 8)) ? data[(((((rc_outer_outer * 3136) + ((((((int)threadIdx.x) * 4) + 392) / 27) * 49)) + (((((((int)threadIdx.x) * 4) + 14) % 27) / 3) * 7)) + (((((int)threadIdx.x) * 3) + 6) % 9)) - 8)] : 0.000000e+00f);
    pad_temp_shared[((((int)threadIdx.x) * 12) + 1177)] = (((((3 &lt;= (((((int)threadIdx.x) * 4) + 14) % 27)) &amp;&amp; ((((((int)threadIdx.x) * 12) + 43) % 81) &lt; 72)) &amp;&amp; (1 &lt;= (((((int)threadIdx.x) * 3) + 7) % 9))) &amp;&amp; ((((((int)threadIdx.x) * 3) + 7) % 9) &lt; 8)) ? data[(((((rc_outer_outer * 3136) + ((((((int)threadIdx.x) * 4) + 392) / 27) * 49)) + (((((((int)threadIdx.x) * 4) + 14) % 27) / 3) * 7)) + (((((int)threadIdx.x) * 3) + 7) % 9)) - 8)] : 0.000000e+00f);
    pad_temp_shared[((((int)threadIdx.x) * 12) + 1178)] = (((((3 &lt;= (((((int)threadIdx.x) * 4) + 14) % 27)) &amp;&amp; ((((((int)threadIdx.x) * 12) + 44) % 81) &lt; 72)) &amp;&amp; (1 &lt;= (((((int)threadIdx.x) * 3) + 8) % 9))) &amp;&amp; ((((((int)threadIdx.x) * 3) + 8) % 9) &lt; 8)) ? data[(((((rc_outer_outer * 3136) + ((((((int)threadIdx.x) * 4) + 392) / 27) * 49)) + (((((((int)threadIdx.x) * 4) + 14) % 27) / 3) * 7)) + (((((int)threadIdx.x) * 3) + 8) % 9)) - 8)] : 0.000000e+00f);
    pad_temp_shared[((((int)threadIdx.x) * 12) + 1179)] = ((((1 &lt;= ((((((int)threadIdx.x) * 4) / 3) + 5) % 9)) &amp;&amp; ((((((int)threadIdx.x) * 12) + 45) % 81) &lt; 72)) &amp;&amp; (1 &lt;= (((int)threadIdx.x) % 3))) ? data[(((((rc_outer_outer * 3136) + ((((((int)threadIdx.x) * 4) + 393) / 27) * 49)) + (((((((int)threadIdx.x) * 4) / 3) + 5) % 9) * 7)) + ((((int)threadIdx.x) % 3) * 3)) - 8)] : 0.000000e+00f);
    pad_temp_shared[((((int)threadIdx.x) * 12) + 1180)] = (((1 &lt;= ((((((int)threadIdx.x) * 4) / 3) + 5) % 9)) &amp;&amp; ((((((int)threadIdx.x) * 12) + 46) % 81) &lt; 72)) ? data[(((((rc_outer_outer * 3136) + ((((((int)threadIdx.x) * 4) + 393) / 27) * 49)) + (((((((int)threadIdx.x) * 4) / 3) + 5) % 9) * 7)) + ((((int)threadIdx.x) % 3) * 3)) - 7)] : 0.000000e+00f);
    pad_temp_shared[((((int)threadIdx.x) * 12) + 1181)] = ((((1 &lt;= ((((((int)threadIdx.x) * 4) / 3) + 5) % 9)) &amp;&amp; ((((((int)threadIdx.x) * 12) + 47) % 81) &lt; 72)) &amp;&amp; ((((int)threadIdx.x) % 3) &lt; 2)) ? data[(((((rc_outer_outer * 3136) + ((((((int)threadIdx.x) * 4) + 393) / 27) * 49)) + (((((((int)threadIdx.x) * 4) / 3) + 5) % 9) * 7)) + ((((int)threadIdx.x) % 3) * 3)) - 6)] : 0.000000e+00f);
    pad_temp_shared[((((int)threadIdx.x) * 12) + 1182)] = (((((3 &lt;= (((((int)threadIdx.x) * 4) + 16) % 27)) &amp;&amp; ((((((int)threadIdx.x) * 12) + 48) % 81) &lt; 72)) &amp;&amp; (1 &lt;= (((((int)threadIdx.x) * 3) + 3) % 9))) &amp;&amp; ((((((int)threadIdx.x) * 3) + 3) % 9) &lt; 8)) ? data[(((((rc_outer_outer * 3136) + ((((((int)threadIdx.x) * 4) + 394) / 27) * 49)) + (((((((int)threadIdx.x) * 4) + 16) % 27) / 3) * 7)) + (((((int)threadIdx.x) * 3) + 3) % 9)) - 8)] : 0.000000e+00f);
    pad_temp_shared[((((int)threadIdx.x) * 12) + 1183)] = (((((3 &lt;= (((((int)threadIdx.x) * 4) + 16) % 27)) &amp;&amp; ((((((int)threadIdx.x) * 12) + 49) % 81) &lt; 72)) &amp;&amp; (1 &lt;= (((((int)threadIdx.x) * 3) + 4) % 9))) &amp;&amp; ((((((int)threadIdx.x) * 3) + 4) % 9) &lt; 8)) ? data[(((((rc_outer_outer * 3136) + ((((((int)threadIdx.x) * 4) + 394) / 27) * 49)) + (((((((int)threadIdx.x) * 4) + 16) % 27) / 3) * 7)) + (((((int)threadIdx.x) * 3) + 4) % 9)) - 8)] : 0.000000e+00f);
    pad_temp_shared[((((int)threadIdx.x) * 12) + 1184)] = (((((3 &lt;= (((((int)threadIdx.x) * 4) + 16) % 27)) &amp;&amp; ((((((int)threadIdx.x) * 12) + 50) % 81) &lt; 72)) &amp;&amp; (1 &lt;= (((((int)threadIdx.x) * 3) + 5) % 9))) &amp;&amp; ((((((int)threadIdx.x) * 3) + 5) % 9) &lt; 8)) ? data[(((((rc_outer_outer * 3136) + ((((((int)threadIdx.x) * 4) + 394) / 27) * 49)) + (((((((int)threadIdx.x) * 4) + 16) % 27) / 3) * 7)) + (((((int)threadIdx.x) * 3) + 5) % 9)) - 8)] : 0.000000e+00f);
    pad_temp_shared[((((int)threadIdx.x) * 12) + 1185)] = (((((1 &lt;= (((((((int)threadIdx.x) * 4) + 392) / 3) + 1) % 9)) &amp;&amp; ((((((int)threadIdx.x) * 12) + 51) % 81) &lt; 72)) &amp;&amp; (1 &lt;= (((((int)threadIdx.x) * 3) + 6) % 9))) &amp;&amp; ((((((int)threadIdx.x) * 3) + 6) % 9) &lt; 8)) ? data[(((((rc_outer_outer * 3136) + ((((((int)threadIdx.x) * 4) + 395) / 27) * 49)) + ((((((((int)threadIdx.x) * 4) + 392) / 3) + 1) % 9) * 7)) + (((((int)threadIdx.x) * 3) + 6) % 9)) - 8)] : 0.000000e+00f);
    pad_temp_shared[((((int)threadIdx.x) * 12) + 1186)] = (((((1 &lt;= (((((((int)threadIdx.x) * 4) + 392) / 3) + 1) % 9)) &amp;&amp; ((((((int)threadIdx.x) * 12) + 52) % 81) &lt; 72)) &amp;&amp; (1 &lt;= (((((int)threadIdx.x) * 3) + 7) % 9))) &amp;&amp; ((((((int)threadIdx.x) * 3) + 7) % 9) &lt; 8)) ? data[(((((rc_outer_outer * 3136) + ((((((int)threadIdx.x) * 4) + 395) / 27) * 49)) + ((((((((int)threadIdx.x) * 4) + 392) / 3) + 1) % 9) * 7)) + (((((int)threadIdx.x) * 3) + 7) % 9)) - 8)] : 0.000000e+00f);
    pad_temp_shared[((((int)threadIdx.x) * 12) + 1187)] = (((((1 &lt;= (((((((int)threadIdx.x) * 4) + 392) / 3) + 1) % 9)) &amp;&amp; ((((((int)threadIdx.x) * 12) + 53) % 81) &lt; 72)) &amp;&amp; (1 &lt;= (((((int)threadIdx.x) * 3) + 8) % 9))) &amp;&amp; ((((((int)threadIdx.x) * 3) + 8) % 9) &lt; 8)) ? data[(((((rc_outer_outer * 3136) + ((((((int)threadIdx.x) * 4) + 395) / 27) * 49)) + ((((((((int)threadIdx.x) * 4) + 392) / 3) + 1) % 9) * 7)) + (((((int)threadIdx.x) * 3) + 8) % 9)) - 8)] : 0.000000e+00f);
    pad_temp_shared[((((int)threadIdx.x) * 12) + 1764)] = ((((1 &lt;= ((((((int)threadIdx.x) * 4) / 3) + 7) % 9)) &amp;&amp; ((((((int)threadIdx.x) * 12) + 63) % 81) &lt; 72)) &amp;&amp; (1 &lt;= (((int)threadIdx.x) % 3))) ? data[(((((rc_outer_outer * 3136) + ((((((int)threadIdx.x) * 4) + 588) / 27) * 49)) + (((((((int)threadIdx.x) * 4) / 3) + 7) % 9) * 7)) + ((((int)threadIdx.x) % 3) * 3)) - 8)] : 0.000000e+00f);
    pad_temp_shared[((((int)threadIdx.x) * 12) + 1765)] = (((1 &lt;= ((((((int)threadIdx.x) * 4) / 3) + 7) % 9)) &amp;&amp; ((((((int)threadIdx.x) * 12) + 64) % 81) &lt; 72)) ? data[(((((rc_outer_outer * 3136) + ((((((int)threadIdx.x) * 4) + 588) / 27) * 49)) + (((((((int)threadIdx.x) * 4) / 3) + 7) % 9) * 7)) + ((((int)threadIdx.x) % 3) * 3)) - 7)] : 0.000000e+00f);
    pad_temp_shared[((((int)threadIdx.x) * 12) + 1766)] = ((((1 &lt;= ((((((int)threadIdx.x) * 4) / 3) + 7) % 9)) &amp;&amp; ((((((int)threadIdx.x) * 12) + 65) % 81) &lt; 72)) &amp;&amp; ((((int)threadIdx.x) % 3) &lt; 2)) ? data[(((((rc_outer_outer * 3136) + ((((((int)threadIdx.x) * 4) + 588) / 27) * 49)) + (((((((int)threadIdx.x) * 4) / 3) + 7) % 9) * 7)) + ((((int)threadIdx.x) % 3) * 3)) - 6)] : 0.000000e+00f);
    pad_temp_shared[((((int)threadIdx.x) * 12) + 1767)] = (((((3 &lt;= (((((int)threadIdx.x) * 4) + 22) % 27)) &amp;&amp; ((((((int)threadIdx.x) * 12) + 66) % 81) &lt; 72)) &amp;&amp; (1 &lt;= (((((int)threadIdx.x) * 3) + 3) % 9))) &amp;&amp; ((((((int)threadIdx.x) * 3) + 3) % 9) &lt; 8)) ? data[(((((rc_outer_outer * 3136) + ((((((int)threadIdx.x) * 4) + 589) / 27) * 49)) + (((((((int)threadIdx.x) * 4) + 22) % 27) / 3) * 7)) + (((((int)threadIdx.x) * 3) + 3) % 9)) - 8)] : 0.000000e+00f);
    pad_temp_shared[((((int)threadIdx.x) * 12) + 1768)] = (((((3 &lt;= (((((int)threadIdx.x) * 4) + 22) % 27)) &amp;&amp; ((((((int)threadIdx.x) * 12) + 67) % 81) &lt; 72)) &amp;&amp; (1 &lt;= (((((int)threadIdx.x) * 3) + 4) % 9))) &amp;&amp; ((((((int)threadIdx.x) * 3) + 4) % 9) &lt; 8)) ? data[(((((rc_outer_outer * 3136) + ((((((int)threadIdx.x) * 4) + 589) / 27) * 49)) + (((((((int)threadIdx.x) * 4) + 22) % 27) / 3) * 7)) + (((((int)threadIdx.x) * 3) + 4) % 9)) - 8)] : 0.000000e+00f);
    pad_temp_shared[((((int)threadIdx.x) * 12) + 1769)] = (((((3 &lt;= (((((int)threadIdx.x) * 4) + 22) % 27)) &amp;&amp; ((((((int)threadIdx.x) * 12) + 68) % 81) &lt; 72)) &amp;&amp; (1 &lt;= (((((int)threadIdx.x) * 3) + 5) % 9))) &amp;&amp; ((((((int)threadIdx.x) * 3) + 5) % 9) &lt; 8)) ? data[(((((rc_outer_outer * 3136) + ((((((int)threadIdx.x) * 4) + 589) / 27) * 49)) + (((((((int)threadIdx.x) * 4) + 22) % 27) / 3) * 7)) + (((((int)threadIdx.x) * 3) + 5) % 9)) - 8)] : 0.000000e+00f);
    pad_temp_shared[((((int)threadIdx.x) * 12) + 1770)] = (((((3 &lt;= (((((int)threadIdx.x) * 4) + 23) % 27)) &amp;&amp; ((((((int)threadIdx.x) * 12) + 69) % 81) &lt; 72)) &amp;&amp; (1 &lt;= (((((int)threadIdx.x) * 3) + 6) % 9))) &amp;&amp; ((((((int)threadIdx.x) * 3) + 6) % 9) &lt; 8)) ? data[(((((rc_outer_outer * 3136) + ((((((int)threadIdx.x) * 4) + 590) / 27) * 49)) + (((((((int)threadIdx.x) * 4) + 23) % 27) / 3) * 7)) + (((((int)threadIdx.x) * 3) + 6) % 9)) - 8)] : 0.000000e+00f);
    pad_temp_shared[((((int)threadIdx.x) * 12) + 1771)] = (((((3 &lt;= (((((int)threadIdx.x) * 4) + 23) % 27)) &amp;&amp; ((((((int)threadIdx.x) * 12) + 70) % 81) &lt; 72)) &amp;&amp; (1 &lt;= (((((int)threadIdx.x) * 3) + 7) % 9))) &amp;&amp; ((((((int)threadIdx.x) * 3) + 7) % 9) &lt; 8)) ? data[(((((rc_outer_outer * 3136) + ((((((int)threadIdx.x) * 4) + 590) / 27) * 49)) + (((((((int)threadIdx.x) * 4) + 23) % 27) / 3) * 7)) + (((((int)threadIdx.x) * 3) + 7) % 9)) - 8)] : 0.000000e+00f);
    pad_temp_shared[((((int)threadIdx.x) * 12) + 1772)] = (((((3 &lt;= (((((int)threadIdx.x) * 4) + 23) % 27)) &amp;&amp; ((((((int)threadIdx.x) * 12) + 71) % 81) &lt; 72)) &amp;&amp; (1 &lt;= (((((int)threadIdx.x) * 3) + 8) % 9))) &amp;&amp; ((((((int)threadIdx.x) * 3) + 8) % 9) &lt; 8)) ? data[(((((rc_outer_outer * 3136) + ((((((int)threadIdx.x) * 4) + 590) / 27) * 49)) + (((((((int)threadIdx.x) * 4) + 23) % 27) / 3) * 7)) + (((((int)threadIdx.x) * 3) + 8) % 9)) - 8)] : 0.000000e+00f);
    pad_temp_shared[((((int)threadIdx.x) * 12) + 1773)] = ((((1 &lt;= ((((((int)threadIdx.x) * 4) / 3) + 8) % 9)) &amp;&amp; ((((((int)threadIdx.x) * 12) + 72) % 81) &lt; 72)) &amp;&amp; (1 &lt;= (((int)threadIdx.x) % 3))) ? data[(((((rc_outer_outer * 3136) + ((((((int)threadIdx.x) * 4) + 591) / 27) * 49)) + (((((((int)threadIdx.x) * 4) / 3) + 8) % 9) * 7)) + ((((int)threadIdx.x) % 3) * 3)) - 8)] : 0.000000e+00f);
    pad_temp_shared[((((int)threadIdx.x) * 12) + 1774)] = (((1 &lt;= ((((((int)threadIdx.x) * 4) / 3) + 8) % 9)) &amp;&amp; ((((((int)threadIdx.x) * 12) + 73) % 81) &lt; 72)) ? data[(((((rc_outer_outer * 3136) + ((((((int)threadIdx.x) * 4) + 591) / 27) * 49)) + (((((((int)threadIdx.x) * 4) / 3) + 8) % 9) * 7)) + ((((int)threadIdx.x) % 3) * 3)) - 7)] : 0.000000e+00f);
    pad_temp_shared[((((int)threadIdx.x) * 12) + 1775)] = ((((1 &lt;= ((((((int)threadIdx.x) * 4) / 3) + 8) % 9)) &amp;&amp; ((((((int)threadIdx.x) * 12) + 74) % 81) &lt; 72)) &amp;&amp; ((((int)threadIdx.x) % 3) &lt; 2)) ? data[(((((rc_outer_outer * 3136) + ((((((int)threadIdx.x) * 4) + 591) / 27) * 49)) + (((((((int)threadIdx.x) * 4) / 3) + 8) % 9) * 7)) + ((((int)threadIdx.x) % 3) * 3)) - 6)] : 0.000000e+00f);
    pad_temp_shared[((((int)threadIdx.x) * 12) + 2352)] = (((((3 &lt;= (((((int)threadIdx.x) * 4) + 1) % 27)) &amp;&amp; ((((((int)threadIdx.x) * 12) + 3) % 81) &lt; 72)) &amp;&amp; (1 &lt;= (((((int)threadIdx.x) * 3) + 3) % 9))) &amp;&amp; ((((((int)threadIdx.x) * 3) + 3) % 9) &lt; 8)) ? data[(((((rc_outer_outer * 3136) + ((((((int)threadIdx.x) * 4) + 784) / 27) * 49)) + (((((((int)threadIdx.x) * 4) + 1) % 27) / 3) * 7)) + (((((int)threadIdx.x) * 3) + 3) % 9)) - 8)] : 0.000000e+00f);
    pad_temp_shared[((((int)threadIdx.x) * 12) + 2353)] = (((((3 &lt;= (((((int)threadIdx.x) * 4) + 1) % 27)) &amp;&amp; ((((((int)threadIdx.x) * 12) + 4) % 81) &lt; 72)) &amp;&amp; (1 &lt;= (((((int)threadIdx.x) * 3) + 4) % 9))) &amp;&amp; ((((((int)threadIdx.x) * 3) + 4) % 9) &lt; 8)) ? data[(((((rc_outer_outer * 3136) + ((((((int)threadIdx.x) * 4) + 784) / 27) * 49)) + (((((((int)threadIdx.x) * 4) + 1) % 27) / 3) * 7)) + (((((int)threadIdx.x) * 3) + 4) % 9)) - 8)] : 0.000000e+00f);
    pad_temp_shared[((((int)threadIdx.x) * 12) + 2354)] = (((((3 &lt;= (((((int)threadIdx.x) * 4) + 1) % 27)) &amp;&amp; ((((((int)threadIdx.x) * 12) + 5) % 81) &lt; 72)) &amp;&amp; (1 &lt;= (((((int)threadIdx.x) * 3) + 5) % 9))) &amp;&amp; ((((((int)threadIdx.x) * 3) + 5) % 9) &lt; 8)) ? data[(((((rc_outer_outer * 3136) + ((((((int)threadIdx.x) * 4) + 784) / 27) * 49)) + (((((((int)threadIdx.x) * 4) + 1) % 27) / 3) * 7)) + (((((int)threadIdx.x) * 3) + 5) % 9)) - 8)] : 0.000000e+00f);
    pad_temp_shared[((((int)threadIdx.x) * 12) + 2355)] = (((((3 &lt;= (((((int)threadIdx.x) * 4) + 2) % 27)) &amp;&amp; ((((((int)threadIdx.x) * 12) + 6) % 81) &lt; 72)) &amp;&amp; (1 &lt;= (((((int)threadIdx.x) * 3) + 6) % 9))) &amp;&amp; ((((((int)threadIdx.x) * 3) + 6) % 9) &lt; 8)) ? data[(((((rc_outer_outer * 3136) + ((((((int)threadIdx.x) * 4) + 785) / 27) * 49)) + (((((((int)threadIdx.x) * 4) + 2) % 27) / 3) * 7)) + (((((int)threadIdx.x) * 3) + 6) % 9)) - 8)] : 0.000000e+00f);
    pad_temp_shared[((((int)threadIdx.x) * 12) + 2356)] = (((((3 &lt;= (((((int)threadIdx.x) * 4) + 2) % 27)) &amp;&amp; ((((((int)threadIdx.x) * 12) + 7) % 81) &lt; 72)) &amp;&amp; (1 &lt;= (((((int)threadIdx.x) * 3) + 7) % 9))) &amp;&amp; ((((((int)threadIdx.x) * 3) + 7) % 9) &lt; 8)) ? data[(((((rc_outer_outer * 3136) + ((((((int)threadIdx.x) * 4) + 785) / 27) * 49)) + (((((((int)threadIdx.x) * 4) + 2) % 27) / 3) * 7)) + (((((int)threadIdx.x) * 3) + 7) % 9)) - 8)] : 0.000000e+00f);
    pad_temp_shared[((((int)threadIdx.x) * 12) + 2357)] = (((((3 &lt;= (((((int)threadIdx.x) * 4) + 2) % 27)) &amp;&amp; ((((((int)threadIdx.x) * 12) + 8) % 81) &lt; 72)) &amp;&amp; (1 &lt;= (((((int)threadIdx.x) * 3) + 8) % 9))) &amp;&amp; ((((((int)threadIdx.x) * 3) + 8) % 9) &lt; 8)) ? data[(((((rc_outer_outer * 3136) + ((((((int)threadIdx.x) * 4) + 785) / 27) * 49)) + (((((((int)threadIdx.x) * 4) + 2) % 27) / 3) * 7)) + (((((int)threadIdx.x) * 3) + 8) % 9)) - 8)] : 0.000000e+00f);
    pad_temp_shared[((((int)threadIdx.x) * 12) + 2358)] = ((((1 &lt;= ((((((int)threadIdx.x) * 4) / 3) + 1) % 9)) &amp;&amp; ((((((int)threadIdx.x) * 12) + 9) % 81) &lt; 72)) &amp;&amp; (1 &lt;= (((int)threadIdx.x) % 3))) ? data[(((((rc_outer_outer * 3136) + ((((((int)threadIdx.x) * 4) + 786) / 27) * 49)) + (((((((int)threadIdx.x) * 4) / 3) + 1) % 9) * 7)) + ((((int)threadIdx.x) % 3) * 3)) - 8)] : 0.000000e+00f);
    pad_temp_shared[((((int)threadIdx.x) * 12) + 2359)] = (((1 &lt;= ((((((int)threadIdx.x) * 4) / 3) + 1) % 9)) &amp;&amp; ((((((int)threadIdx.x) * 12) + 10) % 81) &lt; 72)) ? data[(((((rc_outer_outer * 3136) + ((((((int)threadIdx.x) * 4) + 786) / 27) * 49)) + (((((((int)threadIdx.x) * 4) / 3) + 1) % 9) * 7)) + ((((int)threadIdx.x) % 3) * 3)) - 7)] : 0.000000e+00f);
    pad_temp_shared[((((int)threadIdx.x) * 12) + 2360)] = ((((1 &lt;= ((((((int)threadIdx.x) * 4) / 3) + 1) % 9)) &amp;&amp; ((((((int)threadIdx.x) * 12) + 11) % 81) &lt; 72)) &amp;&amp; ((((int)threadIdx.x) % 3) &lt; 2)) ? data[(((((rc_outer_outer * 3136) + ((((((int)threadIdx.x) * 4) + 786) / 27) * 49)) + (((((((int)threadIdx.x) * 4) / 3) + 1) % 9) * 7)) + ((((int)threadIdx.x) % 3) * 3)) - 6)] : 0.000000e+00f);
    pad_temp_shared[((((int)threadIdx.x) * 12) + 2361)] = (((((1 &lt;= (((((((int)threadIdx.x) * 4) + 784) / 3) + 1) % 9)) &amp;&amp; ((((((int)threadIdx.x) * 12) + 12) % 81) &lt; 72)) &amp;&amp; (1 &lt;= (((((int)threadIdx.x) * 3) + 3) % 9))) &amp;&amp; ((((((int)threadIdx.x) * 3) + 3) % 9) &lt; 8)) ? data[(((((rc_outer_outer * 3136) + ((((((int)threadIdx.x) * 4) + 787) / 27) * 49)) + ((((((((int)threadIdx.x) * 4) + 784) / 3) + 1) % 9) * 7)) + (((((int)threadIdx.x) * 3) + 3) % 9)) - 8)] : 0.000000e+00f);
    pad_temp_shared[((((int)threadIdx.x) * 12) + 2362)] = (((((1 &lt;= (((((((int)threadIdx.x) * 4) + 784) / 3) + 1) % 9)) &amp;&amp; ((((((int)threadIdx.x) * 12) + 13) % 81) &lt; 72)) &amp;&amp; (1 &lt;= (((((int)threadIdx.x) * 3) + 4) % 9))) &amp;&amp; ((((((int)threadIdx.x) * 3) + 4) % 9) &lt; 8)) ? data[(((((rc_outer_outer * 3136) + ((((((int)threadIdx.x) * 4) + 787) / 27) * 49)) + ((((((((int)threadIdx.x) * 4) + 784) / 3) + 1) % 9) * 7)) + (((((int)threadIdx.x) * 3) + 4) % 9)) - 8)] : 0.000000e+00f);
    pad_temp_shared[((((int)threadIdx.x) * 12) + 2363)] = (((((1 &lt;= (((((((int)threadIdx.x) * 4) + 784) / 3) + 1) % 9)) &amp;&amp; ((((((int)threadIdx.x) * 12) + 14) % 81) &lt; 72)) &amp;&amp; (1 &lt;= (((((int)threadIdx.x) * 3) + 5) % 9))) &amp;&amp; ((((((int)threadIdx.x) * 3) + 5) % 9) &lt; 8)) ? data[(((((rc_outer_outer * 3136) + ((((((int)threadIdx.x) * 4) + 787) / 27) * 49)) + ((((((((int)threadIdx.x) * 4) + 784) / 3) + 1) % 9) * 7)) + (((((int)threadIdx.x) * 3) + 5) % 9)) - 8)] : 0.000000e+00f);
    pad_temp_shared[((((int)threadIdx.x) * 12) + 2940)] = (((((3 &lt;= (((((int)threadIdx.x) * 4) + 8) % 27)) &amp;&amp; ((((((int)threadIdx.x) * 12) + 24) % 81) &lt; 72)) &amp;&amp; (1 &lt;= (((((int)threadIdx.x) * 3) + 6) % 9))) &amp;&amp; ((((((int)threadIdx.x) * 3) + 6) % 9) &lt; 8)) ? data[(((((rc_outer_outer * 3136) + ((((((int)threadIdx.x) * 4) + 980) / 27) * 49)) + (((((((int)threadIdx.x) * 4) + 8) % 27) / 3) * 7)) + (((((int)threadIdx.x) * 3) + 6) % 9)) - 8)] : 0.000000e+00f);
    pad_temp_shared[((((int)threadIdx.x) * 12) + 2941)] = (((((3 &lt;= (((((int)threadIdx.x) * 4) + 8) % 27)) &amp;&amp; ((((((int)threadIdx.x) * 12) + 25) % 81) &lt; 72)) &amp;&amp; (1 &lt;= (((((int)threadIdx.x) * 3) + 7) % 9))) &amp;&amp; ((((((int)threadIdx.x) * 3) + 7) % 9) &lt; 8)) ? data[(((((rc_outer_outer * 3136) + ((((((int)threadIdx.x) * 4) + 980) / 27) * 49)) + (((((((int)threadIdx.x) * 4) + 8) % 27) / 3) * 7)) + (((((int)threadIdx.x) * 3) + 7) % 9)) - 8)] : 0.000000e+00f);
    pad_temp_shared[((((int)threadIdx.x) * 12) + 2942)] = (((((3 &lt;= (((((int)threadIdx.x) * 4) + 8) % 27)) &amp;&amp; ((((((int)threadIdx.x) * 12) + 26) % 81) &lt; 72)) &amp;&amp; (1 &lt;= (((((int)threadIdx.x) * 3) + 8) % 9))) &amp;&amp; ((((((int)threadIdx.x) * 3) + 8) % 9) &lt; 8)) ? data[(((((rc_outer_outer * 3136) + ((((((int)threadIdx.x) * 4) + 980) / 27) * 49)) + (((((((int)threadIdx.x) * 4) + 8) % 27) / 3) * 7)) + (((((int)threadIdx.x) * 3) + 8) % 9)) - 8)] : 0.000000e+00f);
    pad_temp_shared[((((int)threadIdx.x) * 12) + 2943)] = ((((1 &lt;= ((((((int)threadIdx.x) * 4) / 3) + 3) % 9)) &amp;&amp; ((((((int)threadIdx.x) * 12) + 27) % 81) &lt; 72)) &amp;&amp; (1 &lt;= (((int)threadIdx.x) % 3))) ? data[(((((rc_outer_outer * 3136) + ((((((int)threadIdx.x) * 4) + 981) / 27) * 49)) + (((((((int)threadIdx.x) * 4) / 3) + 3) % 9) * 7)) + ((((int)threadIdx.x) % 3) * 3)) - 8)] : 0.000000e+00f);
    pad_temp_shared[((((int)threadIdx.x) * 12) + 2944)] = (((1 &lt;= ((((((int)threadIdx.x) * 4) / 3) + 3) % 9)) &amp;&amp; ((((((int)threadIdx.x) * 12) + 28) % 81) &lt; 72)) ? data[(((((rc_outer_outer * 3136) + ((((((int)threadIdx.x) * 4) + 981) / 27) * 49)) + (((((((int)threadIdx.x) * 4) / 3) + 3) % 9) * 7)) + ((((int)threadIdx.x) % 3) * 3)) - 7)] : 0.000000e+00f);
    pad_temp_shared[((((int)threadIdx.x) * 12) + 2945)] = ((((1 &lt;= ((((((int)threadIdx.x) * 4) / 3) + 3) % 9)) &amp;&amp; ((((((int)threadIdx.x) * 12) + 29) % 81) &lt; 72)) &amp;&amp; ((((int)threadIdx.x) % 3) &lt; 2)) ? data[(((((rc_outer_outer * 3136) + ((((((int)threadIdx.x) * 4) + 981) / 27) * 49)) + (((((((int)threadIdx.x) * 4) / 3) + 3) % 9) * 7)) + ((((int)threadIdx.x) % 3) * 3)) - 6)] : 0.000000e+00f);
    pad_temp_shared[((((int)threadIdx.x) * 12) + 2946)] = (((((3 &lt;= (((((int)threadIdx.x) * 4) + 10) % 27)) &amp;&amp; ((((((int)threadIdx.x) * 12) + 30) % 81) &lt; 72)) &amp;&amp; (1 &lt;= (((((int)threadIdx.x) * 3) + 3) % 9))) &amp;&amp; ((((((int)threadIdx.x) * 3) + 3) % 9) &lt; 8)) ? data[(((((rc_outer_outer * 3136) + ((((((int)threadIdx.x) * 4) + 982) / 27) * 49)) + (((((((int)threadIdx.x) * 4) + 10) % 27) / 3) * 7)) + (((((int)threadIdx.x) * 3) + 3) % 9)) - 8)] : 0.000000e+00f);
    pad_temp_shared[((((int)threadIdx.x) * 12) + 2947)] = (((((3 &lt;= (((((int)threadIdx.x) * 4) + 10) % 27)) &amp;&amp; ((((((int)threadIdx.x) * 12) + 31) % 81) &lt; 72)) &amp;&amp; (1 &lt;= (((((int)threadIdx.x) * 3) + 4) % 9))) &amp;&amp; ((((((int)threadIdx.x) * 3) + 4) % 9) &lt; 8)) ? data[(((((rc_outer_outer * 3136) + ((((((int)threadIdx.x) * 4) + 982) / 27) * 49)) + (((((((int)threadIdx.x) * 4) + 10) % 27) / 3) * 7)) + (((((int)threadIdx.x) * 3) + 4) % 9)) - 8)] : 0.000000e+00f);
    pad_temp_shared[((((int)threadIdx.x) * 12) + 2948)] = (((((3 &lt;= (((((int)threadIdx.x) * 4) + 10) % 27)) &amp;&amp; ((((((int)threadIdx.x) * 12) + 32) % 81) &lt; 72)) &amp;&amp; (1 &lt;= (((((int)threadIdx.x) * 3) + 5) % 9))) &amp;&amp; ((((((int)threadIdx.x) * 3) + 5) % 9) &lt; 8)) ? data[(((((rc_outer_outer * 3136) + ((((((int)threadIdx.x) * 4) + 982) / 27) * 49)) + (((((((int)threadIdx.x) * 4) + 10) % 27) / 3) * 7)) + (((((int)threadIdx.x) * 3) + 5) % 9)) - 8)] : 0.000000e+00f);
    pad_temp_shared[((((int)threadIdx.x) * 12) + 2949)] = (((((1 &lt;= (((((((int)threadIdx.x) * 4) + 980) / 3) + 1) % 9)) &amp;&amp; ((((((int)threadIdx.x) * 12) + 33) % 81) &lt; 72)) &amp;&amp; (1 &lt;= (((((int)threadIdx.x) * 3) + 6) % 9))) &amp;&amp; ((((((int)threadIdx.x) * 3) + 6) % 9) &lt; 8)) ? data[(((((rc_outer_outer * 3136) + ((((((int)threadIdx.x) * 4) + 983) / 27) * 49)) + ((((((((int)threadIdx.x) * 4) + 980) / 3) + 1) % 9) * 7)) + (((((int)threadIdx.x) * 3) + 6) % 9)) - 8)] : 0.000000e+00f);
    pad_temp_shared[((((int)threadIdx.x) * 12) + 2950)] = (((((1 &lt;= (((((((int)threadIdx.x) * 4) + 980) / 3) + 1) % 9)) &amp;&amp; ((((((int)threadIdx.x) * 12) + 34) % 81) &lt; 72)) &amp;&amp; (1 &lt;= (((((int)threadIdx.x) * 3) + 7) % 9))) &amp;&amp; ((((((int)threadIdx.x) * 3) + 7) % 9) &lt; 8)) ? data[(((((rc_outer_outer * 3136) + ((((((int)threadIdx.x) * 4) + 983) / 27) * 49)) + ((((((((int)threadIdx.x) * 4) + 980) / 3) + 1) % 9) * 7)) + (((((int)threadIdx.x) * 3) + 7) % 9)) - 8)] : 0.000000e+00f);
    pad_temp_shared[((((int)threadIdx.x) * 12) + 2951)] = (((((1 &lt;= (((((((int)threadIdx.x) * 4) + 980) / 3) + 1) % 9)) &amp;&amp; ((((((int)threadIdx.x) * 12) + 35) % 81) &lt; 72)) &amp;&amp; (1 &lt;= (((((int)threadIdx.x) * 3) + 8) % 9))) &amp;&amp; ((((((int)threadIdx.x) * 3) + 8) % 9) &lt; 8)) ? data[(((((rc_outer_outer * 3136) + ((((((int)threadIdx.x) * 4) + 983) / 27) * 49)) + ((((((((int)threadIdx.x) * 4) + 980) / 3) + 1) % 9) * 7)) + (((((int)threadIdx.x) * 3) + 8) % 9)) - 8)] : 0.000000e+00f);
    pad_temp_shared[((((int)threadIdx.x) * 12) + 3528)] = ((((1 &lt;= ((((((int)threadIdx.x) * 4) / 3) + 5) % 9)) &amp;&amp; ((((((int)threadIdx.x) * 12) + 45) % 81) &lt; 72)) &amp;&amp; (1 &lt;= (((int)threadIdx.x) % 3))) ? data[(((((rc_outer_outer * 3136) + ((((((int)threadIdx.x) * 4) + 1176) / 27) * 49)) + (((((((int)threadIdx.x) * 4) / 3) + 5) % 9) * 7)) + ((((int)threadIdx.x) % 3) * 3)) - 8)] : 0.000000e+00f);
    pad_temp_shared[((((int)threadIdx.x) * 12) + 3529)] = (((1 &lt;= ((((((int)threadIdx.x) * 4) / 3) + 5) % 9)) &amp;&amp; ((((((int)threadIdx.x) * 12) + 46) % 81) &lt; 72)) ? data[(((((rc_outer_outer * 3136) + ((((((int)threadIdx.x) * 4) + 1176) / 27) * 49)) + (((((((int)threadIdx.x) * 4) / 3) + 5) % 9) * 7)) + ((((int)threadIdx.x) % 3) * 3)) - 7)] : 0.000000e+00f);
    pad_temp_shared[((((int)threadIdx.x) * 12) + 3530)] = ((((1 &lt;= ((((((int)threadIdx.x) * 4) / 3) + 5) % 9)) &amp;&amp; ((((((int)threadIdx.x) * 12) + 47) % 81) &lt; 72)) &amp;&amp; ((((int)threadIdx.x) % 3) &lt; 2)) ? data[(((((rc_outer_outer * 3136) + ((((((int)threadIdx.x) * 4) + 1176) / 27) * 49)) + (((((((int)threadIdx.x) * 4) / 3) + 5) % 9) * 7)) + ((((int)threadIdx.x) % 3) * 3)) - 6)] : 0.000000e+00f);
    pad_temp_shared[((((int)threadIdx.x) * 12) + 3531)] = (((((3 &lt;= (((((int)threadIdx.x) * 4) + 16) % 27)) &amp;&amp; ((((((int)threadIdx.x) * 12) + 48) % 81) &lt; 72)) &amp;&amp; (1 &lt;= (((((int)threadIdx.x) * 3) + 3) % 9))) &amp;&amp; ((((((int)threadIdx.x) * 3) + 3) % 9) &lt; 8)) ? data[(((((rc_outer_outer * 3136) + ((((((int)threadIdx.x) * 4) + 1177) / 27) * 49)) + (((((((int)threadIdx.x) * 4) + 16) % 27) / 3) * 7)) + (((((int)threadIdx.x) * 3) + 3) % 9)) - 8)] : 0.000000e+00f);
    pad_temp_shared[((((int)threadIdx.x) * 12) + 3532)] = (((((3 &lt;= (((((int)threadIdx.x) * 4) + 16) % 27)) &amp;&amp; ((((((int)threadIdx.x) * 12) + 49) % 81) &lt; 72)) &amp;&amp; (1 &lt;= (((((int)threadIdx.x) * 3) + 4) % 9))) &amp;&amp; ((((((int)threadIdx.x) * 3) + 4) % 9) &lt; 8)) ? data[(((((rc_outer_outer * 3136) + ((((((int)threadIdx.x) * 4) + 1177) / 27) * 49)) + (((((((int)threadIdx.x) * 4) + 16) % 27) / 3) * 7)) + (((((int)threadIdx.x) * 3) + 4) % 9)) - 8)] : 0.000000e+00f);
    pad_temp_shared[((((int)threadIdx.x) * 12) + 3533)] = (((((3 &lt;= (((((int)threadIdx.x) * 4) + 16) % 27)) &amp;&amp; ((((((int)threadIdx.x) * 12) + 50) % 81) &lt; 72)) &amp;&amp; (1 &lt;= (((((int)threadIdx.x) * 3) + 5) % 9))) &amp;&amp; ((((((int)threadIdx.x) * 3) + 5) % 9) &lt; 8)) ? data[(((((rc_outer_outer * 3136) + ((((((int)threadIdx.x) * 4) + 1177) / 27) * 49)) + (((((((int)threadIdx.x) * 4) + 16) % 27) / 3) * 7)) + (((((int)threadIdx.x) * 3) + 5) % 9)) - 8)] : 0.000000e+00f);
    pad_temp_shared[((((int)threadIdx.x) * 12) + 3534)] = (((((3 &lt;= (((((int)threadIdx.x) * 4) + 17) % 27)) &amp;&amp; ((((((int)threadIdx.x) * 12) + 51) % 81) &lt; 72)) &amp;&amp; (1 &lt;= (((((int)threadIdx.x) * 3) + 6) % 9))) &amp;&amp; ((((((int)threadIdx.x) * 3) + 6) % 9) &lt; 8)) ? data[(((((rc_outer_outer * 3136) + ((((((int)threadIdx.x) * 4) + 1178) / 27) * 49)) + (((((((int)threadIdx.x) * 4) + 17) % 27) / 3) * 7)) + (((((int)threadIdx.x) * 3) + 6) % 9)) - 8)] : 0.000000e+00f);
    pad_temp_shared[((((int)threadIdx.x) * 12) + 3535)] = (((((3 &lt;= (((((int)threadIdx.x) * 4) + 17) % 27)) &amp;&amp; ((((((int)threadIdx.x) * 12) + 52) % 81) &lt; 72)) &amp;&amp; (1 &lt;= (((((int)threadIdx.x) * 3) + 7) % 9))) &amp;&amp; ((((((int)threadIdx.x) * 3) + 7) % 9) &lt; 8)) ? data[(((((rc_outer_outer * 3136) + ((((((int)threadIdx.x) * 4) + 1178) / 27) * 49)) + (((((((int)threadIdx.x) * 4) + 17) % 27) / 3) * 7)) + (((((int)threadIdx.x) * 3) + 7) % 9)) - 8)] : 0.000000e+00f);
    pad_temp_shared[((((int)threadIdx.x) * 12) + 3536)] = (((((3 &lt;= (((((int)threadIdx.x) * 4) + 17) % 27)) &amp;&amp; ((((((int)threadIdx.x) * 12) + 53) % 81) &lt; 72)) &amp;&amp; (1 &lt;= (((((int)threadIdx.x) * 3) + 8) % 9))) &amp;&amp; ((((((int)threadIdx.x) * 3) + 8) % 9) &lt; 8)) ? data[(((((rc_outer_outer * 3136) + ((((((int)threadIdx.x) * 4) + 1178) / 27) * 49)) + (((((((int)threadIdx.x) * 4) + 17) % 27) / 3) * 7)) + (((((int)threadIdx.x) * 3) + 8) % 9)) - 8)] : 0.000000e+00f);
    pad_temp_shared[((((int)threadIdx.x) * 12) + 3537)] = ((((1 &lt;= ((((((int)threadIdx.x) * 4) / 3) + 6) % 9)) &amp;&amp; ((((((int)threadIdx.x) * 12) + 54) % 81) &lt; 72)) &amp;&amp; (1 &lt;= (((int)threadIdx.x) % 3))) ? data[(((((rc_outer_outer * 3136) + ((((((int)threadIdx.x) * 4) + 1179) / 27) * 49)) + (((((((int)threadIdx.x) * 4) / 3) + 6) % 9) * 7)) + ((((int)threadIdx.x) % 3) * 3)) - 8)] : 0.000000e+00f);
    pad_temp_shared[((((int)threadIdx.x) * 12) + 3538)] = (((1 &lt;= ((((((int)threadIdx.x) * 4) / 3) + 6) % 9)) &amp;&amp; ((((((int)threadIdx.x) * 12) + 55) % 81) &lt; 72)) ? data[(((((rc_outer_outer * 3136) + ((((((int)threadIdx.x) * 4) + 1179) / 27) * 49)) + (((((((int)threadIdx.x) * 4) / 3) + 6) % 9) * 7)) + ((((int)threadIdx.x) % 3) * 3)) - 7)] : 0.000000e+00f);
    pad_temp_shared[((((int)threadIdx.x) * 12) + 3539)] = ((((1 &lt;= ((((((int)threadIdx.x) * 4) / 3) + 6) % 9)) &amp;&amp; ((((((int)threadIdx.x) * 12) + 56) % 81) &lt; 72)) &amp;&amp; ((((int)threadIdx.x) % 3) &lt; 2)) ? data[(((((rc_outer_outer * 3136) + ((((((int)threadIdx.x) * 4) + 1179) / 27) * 49)) + (((((((int)threadIdx.x) * 4) / 3) + 6) % 9) * 7)) + ((((int)threadIdx.x) % 3) * 3)) - 6)] : 0.000000e+00f);
    pad_temp_shared[((((int)threadIdx.x) * 12) + 4116)] = (((((3 &lt;= (((((int)threadIdx.x) * 4) + 22) % 27)) &amp;&amp; ((((((int)threadIdx.x) * 12) + 66) % 81) &lt; 72)) &amp;&amp; (1 &lt;= (((((int)threadIdx.x) * 3) + 3) % 9))) &amp;&amp; ((((((int)threadIdx.x) * 3) + 3) % 9) &lt; 8)) ? data[(((((rc_outer_outer * 3136) + ((((((int)threadIdx.x) * 4) + 1372) / 27) * 49)) + (((((((int)threadIdx.x) * 4) + 22) % 27) / 3) * 7)) + (((((int)threadIdx.x) * 3) + 3) % 9)) - 8)] : 0.000000e+00f);
    pad_temp_shared[((((int)threadIdx.x) * 12) + 4117)] = (((((3 &lt;= (((((int)threadIdx.x) * 4) + 22) % 27)) &amp;&amp; ((((((int)threadIdx.x) * 12) + 67) % 81) &lt; 72)) &amp;&amp; (1 &lt;= (((((int)threadIdx.x) * 3) + 4) % 9))) &amp;&amp; ((((((int)threadIdx.x) * 3) + 4) % 9) &lt; 8)) ? data[(((((rc_outer_outer * 3136) + ((((((int)threadIdx.x) * 4) + 1372) / 27) * 49)) + (((((((int)threadIdx.x) * 4) + 22) % 27) / 3) * 7)) + (((((int)threadIdx.x) * 3) + 4) % 9)) - 8)] : 0.000000e+00f);
    pad_temp_shared[((((int)threadIdx.x) * 12) + 4118)] = (((((3 &lt;= (((((int)threadIdx.x) * 4) + 22) % 27)) &amp;&amp; ((((((int)threadIdx.x) * 12) + 68) % 81) &lt; 72)) &amp;&amp; (1 &lt;= (((((int)threadIdx.x) * 3) + 5) % 9))) &amp;&amp; ((((((int)threadIdx.x) * 3) + 5) % 9) &lt; 8)) ? data[(((((rc_outer_outer * 3136) + ((((((int)threadIdx.x) * 4) + 1372) / 27) * 49)) + (((((((int)threadIdx.x) * 4) + 22) % 27) / 3) * 7)) + (((((int)threadIdx.x) * 3) + 5) % 9)) - 8)] : 0.000000e+00f);
    pad_temp_shared[((((int)threadIdx.x) * 12) + 4119)] = (((((3 &lt;= (((((int)threadIdx.x) * 4) + 23) % 27)) &amp;&amp; ((((((int)threadIdx.x) * 12) + 69) % 81) &lt; 72)) &amp;&amp; (1 &lt;= (((((int)threadIdx.x) * 3) + 6) % 9))) &amp;&amp; ((((((int)threadIdx.x) * 3) + 6) % 9) &lt; 8)) ? data[(((((rc_outer_outer * 3136) + ((((((int)threadIdx.x) * 4) + 1373) / 27) * 49)) + (((((((int)threadIdx.x) * 4) + 23) % 27) / 3) * 7)) + (((((int)threadIdx.x) * 3) + 6) % 9)) - 8)] : 0.000000e+00f);
    pad_temp_shared[((((int)threadIdx.x) * 12) + 4120)] = (((((3 &lt;= (((((int)threadIdx.x) * 4) + 23) % 27)) &amp;&amp; ((((((int)threadIdx.x) * 12) + 70) % 81) &lt; 72)) &amp;&amp; (1 &lt;= (((((int)threadIdx.x) * 3) + 7) % 9))) &amp;&amp; ((((((int)threadIdx.x) * 3) + 7) % 9) &lt; 8)) ? data[(((((rc_outer_outer * 3136) + ((((((int)threadIdx.x) * 4) + 1373) / 27) * 49)) + (((((((int)threadIdx.x) * 4) + 23) % 27) / 3) * 7)) + (((((int)threadIdx.x) * 3) + 7) % 9)) - 8)] : 0.000000e+00f);
    pad_temp_shared[((((int)threadIdx.x) * 12) + 4121)] = (((((3 &lt;= (((((int)threadIdx.x) * 4) + 23) % 27)) &amp;&amp; ((((((int)threadIdx.x) * 12) + 71) % 81) &lt; 72)) &amp;&amp; (1 &lt;= (((((int)threadIdx.x) * 3) + 8) % 9))) &amp;&amp; ((((((int)threadIdx.x) * 3) + 8) % 9) &lt; 8)) ? data[(((((rc_outer_outer * 3136) + ((((((int)threadIdx.x) * 4) + 1373) / 27) * 49)) + (((((((int)threadIdx.x) * 4) + 23) % 27) / 3) * 7)) + (((((int)threadIdx.x) * 3) + 8) % 9)) - 8)] : 0.000000e+00f);
    pad_temp_shared[((((int)threadIdx.x) * 12) + 4122)] = ((((1 &lt;= ((((((int)threadIdx.x) * 4) / 3) + 8) % 9)) &amp;&amp; ((((((int)threadIdx.x) * 12) + 72) % 81) &lt; 72)) &amp;&amp; (1 &lt;= (((int)threadIdx.x) % 3))) ? data[(((((rc_outer_outer * 3136) + ((((((int)threadIdx.x) * 4) + 1374) / 27) * 49)) + (((((((int)threadIdx.x) * 4) / 3) + 8) % 9) * 7)) + ((((int)threadIdx.x) % 3) * 3)) - 8)] : 0.000000e+00f);
    pad_temp_shared[((((int)threadIdx.x) * 12) + 4123)] = (((1 &lt;= ((((((int)threadIdx.x) * 4) / 3) + 8) % 9)) &amp;&amp; ((((((int)threadIdx.x) * 12) + 73) % 81) &lt; 72)) ? data[(((((rc_outer_outer * 3136) + ((((((int)threadIdx.x) * 4) + 1374) / 27) * 49)) + (((((((int)threadIdx.x) * 4) / 3) + 8) % 9) * 7)) + ((((int)threadIdx.x) % 3) * 3)) - 7)] : 0.000000e+00f);
    pad_temp_shared[((((int)threadIdx.x) * 12) + 4124)] = ((((1 &lt;= ((((((int)threadIdx.x) * 4) / 3) + 8) % 9)) &amp;&amp; ((((((int)threadIdx.x) * 12) + 74) % 81) &lt; 72)) &amp;&amp; ((((int)threadIdx.x) % 3) &lt; 2)) ? data[(((((rc_outer_outer * 3136) + ((((((int)threadIdx.x) * 4) + 1374) / 27) * 49)) + (((((((int)threadIdx.x) * 4) / 3) + 8) % 9) * 7)) + ((((int)threadIdx.x) % 3) * 3)) - 6)] : 0.000000e+00f);
    pad_temp_shared[((((int)threadIdx.x) * 12) + 4125)] = (((((1 &lt;= (((((((int)threadIdx.x) * 4) + 1372) / 3) + 1) % 9)) &amp;&amp; ((((((int)threadIdx.x) * 12) + 75) % 81) &lt; 72)) &amp;&amp; (1 &lt;= (((((int)threadIdx.x) * 3) + 3) % 9))) &amp;&amp; ((((((int)threadIdx.x) * 3) + 3) % 9) &lt; 8)) ? data[(((((rc_outer_outer * 3136) + ((((((int)threadIdx.x) * 4) + 1375) / 27) * 49)) + ((((((((int)threadIdx.x) * 4) + 1372) / 3) + 1) % 9) * 7)) + (((((int)threadIdx.x) * 3) + 3) % 9)) - 8)] : 0.000000e+00f);
    pad_temp_shared[((((int)threadIdx.x) * 12) + 4126)] = (((((1 &lt;= (((((((int)threadIdx.x) * 4) + 1372) / 3) + 1) % 9)) &amp;&amp; ((((((int)threadIdx.x) * 12) + 76) % 81) &lt; 72)) &amp;&amp; (1 &lt;= (((((int)threadIdx.x) * 3) + 4) % 9))) &amp;&amp; ((((((int)threadIdx.x) * 3) + 4) % 9) &lt; 8)) ? data[(((((rc_outer_outer * 3136) + ((((((int)threadIdx.x) * 4) + 1375) / 27) * 49)) + ((((((((int)threadIdx.x) * 4) + 1372) / 3) + 1) % 9) * 7)) + (((((int)threadIdx.x) * 3) + 4) % 9)) - 8)] : 0.000000e+00f);
    pad_temp_shared[((((int)threadIdx.x) * 12) + 4127)] = (((((1 &lt;= (((((((int)threadIdx.x) * 4) + 1372) / 3) + 1) % 9)) &amp;&amp; ((((((int)threadIdx.x) * 12) + 77) % 81) &lt; 72)) &amp;&amp; (1 &lt;= (((((int)threadIdx.x) * 3) + 5) % 9))) &amp;&amp; ((((((int)threadIdx.x) * 3) + 5) % 9) &lt; 8)) ? data[(((((rc_outer_outer * 3136) + ((((((int)threadIdx.x) * 4) + 1375) / 27) * 49)) + ((((((((int)threadIdx.x) * 4) + 1372) / 3) + 1) % 9) * 7)) + (((((int)threadIdx.x) * 3) + 5) % 9)) - 8)] : 0.000000e+00f);
    if (((int)threadIdx.x) &lt; 40) {
      pad_temp_shared[((((int)threadIdx.x) * 12) + 4704)] = (((((3 &lt;= (((((int)threadIdx.x) * 4) + 2) % 27)) &amp;&amp; ((((((int)threadIdx.x) * 12) + 6) % 81) &lt; 72)) &amp;&amp; (1 &lt;= (((((int)threadIdx.x) * 3) + 6) % 9))) &amp;&amp; ((((((int)threadIdx.x) * 3) + 6) % 9) &lt; 8)) ? data[(((((rc_outer_outer * 3136) + ((((((int)threadIdx.x) * 4) + 1568) / 27) * 49)) + (((((((int)threadIdx.x) * 4) + 2) % 27) / 3) * 7)) + (((((int)threadIdx.x) * 3) + 6) % 9)) - 8)] : 0.000000e+00f);
    }
    if (((int)threadIdx.x) &lt; 40) {
      pad_temp_shared[((((int)threadIdx.x) * 12) + 4705)] = (((((3 &lt;= (((((int)threadIdx.x) * 4) + 2) % 27)) &amp;&amp; ((((((int)threadIdx.x) * 12) + 7) % 81) &lt; 72)) &amp;&amp; (1 &lt;= (((((int)threadIdx.x) * 3) + 7) % 9))) &amp;&amp; ((((((int)threadIdx.x) * 3) + 7) % 9) &lt; 8)) ? data[(((((rc_outer_outer * 3136) + ((((((int)threadIdx.x) * 4) + 1568) / 27) * 49)) + (((((((int)threadIdx.x) * 4) + 2) % 27) / 3) * 7)) + (((((int)threadIdx.x) * 3) + 7) % 9)) - 8)] : 0.000000e+00f);
    }
    if (((int)threadIdx.x) &lt; 40) {
      pad_temp_shared[((((int)threadIdx.x) * 12) + 4706)] = (((((3 &lt;= (((((int)threadIdx.x) * 4) + 2) % 27)) &amp;&amp; ((((((int)threadIdx.x) * 12) + 8) % 81) &lt; 72)) &amp;&amp; (1 &lt;= (((((int)threadIdx.x) * 3) + 8) % 9))) &amp;&amp; ((((((int)threadIdx.x) * 3) + 8) % 9) &lt; 8)) ? data[(((((rc_outer_outer * 3136) + ((((((int)threadIdx.x) * 4) + 1568) / 27) * 49)) + (((((((int)threadIdx.x) * 4) + 2) % 27) / 3) * 7)) + (((((int)threadIdx.x) * 3) + 8) % 9)) - 8)] : 0.000000e+00f);
    }
    if (((int)threadIdx.x) &lt; 40) {
      pad_temp_shared[((((int)threadIdx.x) * 12) + 4707)] = ((((1 &lt;= ((((((int)threadIdx.x) * 4) / 3) + 1) % 9)) &amp;&amp; ((((((int)threadIdx.x) * 12) + 9) % 81) &lt; 72)) &amp;&amp; (1 &lt;= (((int)threadIdx.x) % 3))) ? data[(((((rc_outer_outer * 3136) + ((((((int)threadIdx.x) * 4) + 1569) / 27) * 49)) + (((((((int)threadIdx.x) * 4) / 3) + 1) % 9) * 7)) + ((((int)threadIdx.x) % 3) * 3)) - 8)] : 0.000000e+00f);
    }
    if (((int)threadIdx.x) &lt; 40) {
      pad_temp_shared[((((int)threadIdx.x) * 12) + 4708)] = (((1 &lt;= ((((((int)threadIdx.x) * 4) / 3) + 1) % 9)) &amp;&amp; ((((((int)threadIdx.x) * 12) + 10) % 81) &lt; 72)) ? data[(((((rc_outer_outer * 3136) + ((((((int)threadIdx.x) * 4) + 1569) / 27) * 49)) + (((((((int)threadIdx.x) * 4) / 3) + 1) % 9) * 7)) + ((((int)threadIdx.x) % 3) * 3)) - 7)] : 0.000000e+00f);
    }
    if (((int)threadIdx.x) &lt; 40) {
      pad_temp_shared[((((int)threadIdx.x) * 12) + 4709)] = ((((1 &lt;= ((((((int)threadIdx.x) * 4) / 3) + 1) % 9)) &amp;&amp; ((((((int)threadIdx.x) * 12) + 11) % 81) &lt; 72)) &amp;&amp; ((((int)threadIdx.x) % 3) &lt; 2)) ? data[(((((rc_outer_outer * 3136) + ((((((int)threadIdx.x) * 4) + 1569) / 27) * 49)) + (((((((int)threadIdx.x) * 4) / 3) + 1) % 9) * 7)) + ((((int)threadIdx.x) % 3) * 3)) - 6)] : 0.000000e+00f);
    }
    if (((int)threadIdx.x) &lt; 40) {
      pad_temp_shared[((((int)threadIdx.x) * 12) + 4710)] = (((((3 &lt;= (((((int)threadIdx.x) * 4) + 4) % 27)) &amp;&amp; ((((((int)threadIdx.x) * 12) + 12) % 81) &lt; 72)) &amp;&amp; (1 &lt;= (((((int)threadIdx.x) * 3) + 3) % 9))) &amp;&amp; ((((((int)threadIdx.x) * 3) + 3) % 9) &lt; 8)) ? data[(((((rc_outer_outer * 3136) + ((((((int)threadIdx.x) * 4) + 1570) / 27) * 49)) + (((((((int)threadIdx.x) * 4) + 4) % 27) / 3) * 7)) + (((((int)threadIdx.x) * 3) + 3) % 9)) - 8)] : 0.000000e+00f);
    }
    if (((int)threadIdx.x) &lt; 40) {
      pad_temp_shared[((((int)threadIdx.x) * 12) + 4711)] = (((((3 &lt;= (((((int)threadIdx.x) * 4) + 4) % 27)) &amp;&amp; ((((((int)threadIdx.x) * 12) + 13) % 81) &lt; 72)) &amp;&amp; (1 &lt;= (((((int)threadIdx.x) * 3) + 4) % 9))) &amp;&amp; ((((((int)threadIdx.x) * 3) + 4) % 9) &lt; 8)) ? data[(((((rc_outer_outer * 3136) + ((((((int)threadIdx.x) * 4) + 1570) / 27) * 49)) + (((((((int)threadIdx.x) * 4) + 4) % 27) / 3) * 7)) + (((((int)threadIdx.x) * 3) + 4) % 9)) - 8)] : 0.000000e+00f);
    }
    if (((int)threadIdx.x) &lt; 40) {
      pad_temp_shared[((((int)threadIdx.x) * 12) + 4712)] = (((((3 &lt;= (((((int)threadIdx.x) * 4) + 4) % 27)) &amp;&amp; ((((((int)threadIdx.x) * 12) + 14) % 81) &lt; 72)) &amp;&amp; (1 &lt;= (((((int)threadIdx.x) * 3) + 5) % 9))) &amp;&amp; ((((((int)threadIdx.x) * 3) + 5) % 9) &lt; 8)) ? data[(((((rc_outer_outer * 3136) + ((((((int)threadIdx.x) * 4) + 1570) / 27) * 49)) + (((((((int)threadIdx.x) * 4) + 4) % 27) / 3) * 7)) + (((((int)threadIdx.x) * 3) + 5) % 9)) - 8)] : 0.000000e+00f);
    }
    if (((int)threadIdx.x) &lt; 40) {
      pad_temp_shared[((((int)threadIdx.x) * 12) + 4713)] = (((((1 &lt;= (((((((int)threadIdx.x) * 4) + 1568) / 3) + 1) % 9)) &amp;&amp; ((((((int)threadIdx.x) * 12) + 15) % 81) &lt; 72)) &amp;&amp; (1 &lt;= (((((int)threadIdx.x) * 3) + 6) % 9))) &amp;&amp; ((((((int)threadIdx.x) * 3) + 6) % 9) &lt; 8)) ? data[(((((rc_outer_outer * 3136) + ((((((int)threadIdx.x) * 4) + 1571) / 27) * 49)) + ((((((((int)threadIdx.x) * 4) + 1568) / 3) + 1) % 9) * 7)) + (((((int)threadIdx.x) * 3) + 6) % 9)) - 8)] : 0.000000e+00f);
    }
    if (((int)threadIdx.x) &lt; 40) {
      pad_temp_shared[((((int)threadIdx.x) * 12) + 4714)] = (((((1 &lt;= (((((((int)threadIdx.x) * 4) + 1568) / 3) + 1) % 9)) &amp;&amp; ((((((int)threadIdx.x) * 12) + 16) % 81) &lt; 72)) &amp;&amp; (1 &lt;= (((((int)threadIdx.x) * 3) + 7) % 9))) &amp;&amp; ((((((int)threadIdx.x) * 3) + 7) % 9) &lt; 8)) ? data[(((((rc_outer_outer * 3136) + ((((((int)threadIdx.x) * 4) + 1571) / 27) * 49)) + ((((((((int)threadIdx.x) * 4) + 1568) / 3) + 1) % 9) * 7)) + (((((int)threadIdx.x) * 3) + 7) % 9)) - 8)] : 0.000000e+00f);
    }
    if (((int)threadIdx.x) &lt; 40) {
      pad_temp_shared[((((int)threadIdx.x) * 12) + 4715)] = (((((1 &lt;= (((((((int)threadIdx.x) * 4) + 1568) / 3) + 1) % 9)) &amp;&amp; ((((((int)threadIdx.x) * 12) + 17) % 81) &lt; 72)) &amp;&amp; (1 &lt;= (((((int)threadIdx.x) * 3) + 8) % 9))) &amp;&amp; ((((((int)threadIdx.x) * 3) + 8) % 9) &lt; 8)) ? data[(((((rc_outer_outer * 3136) + ((((((int)threadIdx.x) * 4) + 1571) / 27) * 49)) + ((((((((int)threadIdx.x) * 4) + 1568) / 3) + 1) % 9) * 7)) + (((((int)threadIdx.x) * 3) + 8) % 9)) - 8)] : 0.000000e+00f);
    }
    kernel_shared[(((int)threadIdx.x) * 3)] = kernel[(((((int)blockIdx.x) * 36864) + (rc_outer_outer * 576)) + (((int)threadIdx.x) * 3))];
    kernel_shared[((((int)threadIdx.x) * 3) + 1)] = kernel[((((((int)blockIdx.x) * 36864) + (rc_outer_outer * 576)) + (((int)threadIdx.x) * 3)) + 1)];
    kernel_shared[((((int)threadIdx.x) * 3) + 2)] = kernel[((((((int)blockIdx.x) * 36864) + (rc_outer_outer * 576)) + (((int)threadIdx.x) * 3)) + 2)];
    kernel_shared[((((int)threadIdx.x) * 3) + 147)] = kernel[((((((int)blockIdx.x) * 36864) + (rc_outer_outer * 576)) + (((int)threadIdx.x) * 3)) + 147)];
    kernel_shared[((((int)threadIdx.x) * 3) + 148)] = kernel[((((((int)blockIdx.x) * 36864) + (rc_outer_outer * 576)) + (((int)threadIdx.x) * 3)) + 148)];
    kernel_shared[((((int)threadIdx.x) * 3) + 149)] = kernel[((((((int)blockIdx.x) * 36864) + (rc_outer_outer * 576)) + (((int)threadIdx.x) * 3)) + 149)];
    kernel_shared[((((int)threadIdx.x) * 3) + 294)] = kernel[((((((int)blockIdx.x) * 36864) + (rc_outer_outer * 576)) + (((int)threadIdx.x) * 3)) + 294)];
    kernel_shared[((((int)threadIdx.x) * 3) + 295)] = kernel[((((((int)blockIdx.x) * 36864) + (rc_outer_outer * 576)) + (((int)threadIdx.x) * 3)) + 295)];
    kernel_shared[((((int)threadIdx.x) * 3) + 296)] = kernel[((((((int)blockIdx.x) * 36864) + (rc_outer_outer * 576)) + (((int)threadIdx.x) * 3)) + 296)];
    kernel_shared[((((int)threadIdx.x) * 3) + 441)] = kernel[((((((int)blockIdx.x) * 36864) + (((((int)threadIdx.x) + 147) / 192) * 4608)) + (rc_outer_outer * 576)) + (((((int)threadIdx.x) + 147) % 192) * 3))];
    kernel_shared[((((int)threadIdx.x) * 3) + 442)] = kernel[(((((((int)blockIdx.x) * 36864) + (((((int)threadIdx.x) + 147) / 192) * 4608)) + (rc_outer_outer * 576)) + (((((int)threadIdx.x) + 147) % 192) * 3)) + 1)];
    kernel_shared[((((int)threadIdx.x) * 3) + 443)] = kernel[(((((((int)blockIdx.x) * 36864) + (((((int)threadIdx.x) + 147) / 192) * 4608)) + (rc_outer_outer * 576)) + (((((int)threadIdx.x) + 147) % 192) * 3)) + 2)];
    kernel_shared[((((int)threadIdx.x) * 3) + 588)] = kernel[(((((((int)blockIdx.x) * 36864) + (((((int)threadIdx.x) + 196) / 192) * 4608)) + (rc_outer_outer * 576)) + (((int)threadIdx.x) * 3)) + 12)];
    kernel_shared[((((int)threadIdx.x) * 3) + 589)] = kernel[(((((((int)blockIdx.x) * 36864) + (((((int)threadIdx.x) + 196) / 192) * 4608)) + (rc_outer_outer * 576)) + (((int)threadIdx.x) * 3)) + 13)];
    kernel_shared[((((int)threadIdx.x) * 3) + 590)] = kernel[(((((((int)blockIdx.x) * 36864) + (((((int)threadIdx.x) + 196) / 192) * 4608)) + (rc_outer_outer * 576)) + (((int)threadIdx.x) * 3)) + 14)];
    kernel_shared[((((int)threadIdx.x) * 3) + 735)] = kernel[(((((((int)blockIdx.x) * 36864) + (((((int)threadIdx.x) + 245) / 192) * 4608)) + (rc_outer_outer * 576)) + (((int)threadIdx.x) * 3)) + 159)];
    kernel_shared[((((int)threadIdx.x) * 3) + 736)] = kernel[(((((((int)blockIdx.x) * 36864) + (((((int)threadIdx.x) + 245) / 192) * 4608)) + (rc_outer_outer * 576)) + (((int)threadIdx.x) * 3)) + 160)];
    kernel_shared[((((int)threadIdx.x) * 3) + 737)] = kernel[(((((((int)blockIdx.x) * 36864) + (((((int)threadIdx.x) + 245) / 192) * 4608)) + (rc_outer_outer * 576)) + (((int)threadIdx.x) * 3)) + 161)];
    kernel_shared[((((int)threadIdx.x) * 3) + 882)] = kernel[(((((((int)blockIdx.x) * 36864) + (((((int)threadIdx.x) + 294) / 192) * 4608)) + (rc_outer_outer * 576)) + (((int)threadIdx.x) * 3)) + 306)];
    kernel_shared[((((int)threadIdx.x) * 3) + 883)] = kernel[(((((((int)blockIdx.x) * 36864) + (((((int)threadIdx.x) + 294) / 192) * 4608)) + (rc_outer_outer * 576)) + (((int)threadIdx.x) * 3)) + 307)];
    kernel_shared[((((int)threadIdx.x) * 3) + 884)] = kernel[(((((((int)blockIdx.x) * 36864) + (((((int)threadIdx.x) + 294) / 192) * 4608)) + (rc_outer_outer * 576)) + (((int)threadIdx.x) * 3)) + 308)];
    kernel_shared[((((int)threadIdx.x) * 3) + 1029)] = kernel[((((((int)blockIdx.x) * 36864) + (((((int)threadIdx.x) + 343) / 192) * 4608)) + (rc_outer_outer * 576)) + (((((int)threadIdx.x) + 151) % 192) * 3))];
    kernel_shared[((((int)threadIdx.x) * 3) + 1030)] = kernel[(((((((int)blockIdx.x) * 36864) + (((((int)threadIdx.x) + 343) / 192) * 4608)) + (rc_outer_outer * 576)) + (((((int)threadIdx.x) + 151) % 192) * 3)) + 1)];
    kernel_shared[((((int)threadIdx.x) * 3) + 1031)] = kernel[(((((((int)blockIdx.x) * 36864) + (((((int)threadIdx.x) + 343) / 192) * 4608)) + (rc_outer_outer * 576)) + (((((int)threadIdx.x) + 151) % 192) * 3)) + 2)];
    kernel_shared[((((int)threadIdx.x) * 3) + 1176)] = kernel[(((((((int)blockIdx.x) * 36864) + (((((int)threadIdx.x) + 392) / 192) * 4608)) + (rc_outer_outer * 576)) + (((int)threadIdx.x) * 3)) + 24)];
    kernel_shared[((((int)threadIdx.x) * 3) + 1177)] = kernel[(((((((int)blockIdx.x) * 36864) + (((((int)threadIdx.x) + 392) / 192) * 4608)) + (rc_outer_outer * 576)) + (((int)threadIdx.x) * 3)) + 25)];
    kernel_shared[((((int)threadIdx.x) * 3) + 1178)] = kernel[(((((((int)blockIdx.x) * 36864) + (((((int)threadIdx.x) + 392) / 192) * 4608)) + (rc_outer_outer * 576)) + (((int)threadIdx.x) * 3)) + 26)];
    kernel_shared[((((int)threadIdx.x) * 3) + 1323)] = kernel[(((((((int)blockIdx.x) * 36864) + (((((int)threadIdx.x) + 441) / 192) * 4608)) + (rc_outer_outer * 576)) + (((int)threadIdx.x) * 3)) + 171)];
    kernel_shared[((((int)threadIdx.x) * 3) + 1324)] = kernel[(((((((int)blockIdx.x) * 36864) + (((((int)threadIdx.x) + 441) / 192) * 4608)) + (rc_outer_outer * 576)) + (((int)threadIdx.x) * 3)) + 172)];
    kernel_shared[((((int)threadIdx.x) * 3) + 1325)] = kernel[(((((((int)blockIdx.x) * 36864) + (((((int)threadIdx.x) + 441) / 192) * 4608)) + (rc_outer_outer * 576)) + (((int)threadIdx.x) * 3)) + 173)];
    kernel_shared[((((int)threadIdx.x) * 3) + 1470)] = kernel[(((((((int)blockIdx.x) * 36864) + (((((int)threadIdx.x) + 490) / 192) * 4608)) + (rc_outer_outer * 576)) + (((int)threadIdx.x) * 3)) + 318)];
    kernel_shared[((((int)threadIdx.x) * 3) + 1471)] = kernel[(((((((int)blockIdx.x) * 36864) + (((((int)threadIdx.x) + 490) / 192) * 4608)) + (rc_outer_outer * 576)) + (((int)threadIdx.x) * 3)) + 319)];
    kernel_shared[((((int)threadIdx.x) * 3) + 1472)] = kernel[(((((((int)blockIdx.x) * 36864) + (((((int)threadIdx.x) + 490) / 192) * 4608)) + (rc_outer_outer * 576)) + (((int)threadIdx.x) * 3)) + 320)];
    kernel_shared[((((int)threadIdx.x) * 3) + 1617)] = kernel[((((((int)blockIdx.x) * 36864) + (((((int)threadIdx.x) + 539) / 192) * 4608)) + (rc_outer_outer * 576)) + (((((int)threadIdx.x) + 155) % 192) * 3))];
    kernel_shared[((((int)threadIdx.x) * 3) + 1618)] = kernel[(((((((int)blockIdx.x) * 36864) + (((((int)threadIdx.x) + 539) / 192) * 4608)) + (rc_outer_outer * 576)) + (((((int)threadIdx.x) + 155) % 192) * 3)) + 1)];
    kernel_shared[((((int)threadIdx.x) * 3) + 1619)] = kernel[(((((((int)blockIdx.x) * 36864) + (((((int)threadIdx.x) + 539) / 192) * 4608)) + (rc_outer_outer * 576)) + (((((int)threadIdx.x) + 155) % 192) * 3)) + 2)];
    kernel_shared[((((int)threadIdx.x) * 3) + 1764)] = kernel[(((((((int)blockIdx.x) * 36864) + (((((int)threadIdx.x) + 588) / 192) * 4608)) + (rc_outer_outer * 576)) + (((int)threadIdx.x) * 3)) + 36)];
    kernel_shared[((((int)threadIdx.x) * 3) + 1765)] = kernel[(((((((int)blockIdx.x) * 36864) + (((((int)threadIdx.x) + 588) / 192) * 4608)) + (rc_outer_outer * 576)) + (((int)threadIdx.x) * 3)) + 37)];
    kernel_shared[((((int)threadIdx.x) * 3) + 1766)] = kernel[(((((((int)blockIdx.x) * 36864) + (((((int)threadIdx.x) + 588) / 192) * 4608)) + (rc_outer_outer * 576)) + (((int)threadIdx.x) * 3)) + 38)];
    kernel_shared[((((int)threadIdx.x) * 3) + 1911)] = kernel[(((((((int)blockIdx.x) * 36864) + (((((int)threadIdx.x) + 637) / 192) * 4608)) + (rc_outer_outer * 576)) + (((int)threadIdx.x) * 3)) + 183)];
    kernel_shared[((((int)threadIdx.x) * 3) + 1912)] = kernel[(((((((int)blockIdx.x) * 36864) + (((((int)threadIdx.x) + 637) / 192) * 4608)) + (rc_outer_outer * 576)) + (((int)threadIdx.x) * 3)) + 184)];
    kernel_shared[((((int)threadIdx.x) * 3) + 1913)] = kernel[(((((((int)blockIdx.x) * 36864) + (((((int)threadIdx.x) + 637) / 192) * 4608)) + (rc_outer_outer * 576)) + (((int)threadIdx.x) * 3)) + 185)];
    kernel_shared[((((int)threadIdx.x) * 3) + 2058)] = kernel[(((((((int)blockIdx.x) * 36864) + (((((int)threadIdx.x) + 686) / 192) * 4608)) + (rc_outer_outer * 576)) + (((int)threadIdx.x) * 3)) + 330)];
    kernel_shared[((((int)threadIdx.x) * 3) + 2059)] = kernel[(((((((int)blockIdx.x) * 36864) + (((((int)threadIdx.x) + 686) / 192) * 4608)) + (rc_outer_outer * 576)) + (((int)threadIdx.x) * 3)) + 331)];
    kernel_shared[((((int)threadIdx.x) * 3) + 2060)] = kernel[(((((((int)blockIdx.x) * 36864) + (((((int)threadIdx.x) + 686) / 192) * 4608)) + (rc_outer_outer * 576)) + (((int)threadIdx.x) * 3)) + 332)];
    kernel_shared[((((int)threadIdx.x) * 3) + 2205)] = kernel[((((((int)blockIdx.x) * 36864) + (((((int)threadIdx.x) + 735) / 192) * 4608)) + (rc_outer_outer * 576)) + (((((int)threadIdx.x) + 159) % 192) * 3))];
    kernel_shared[((((int)threadIdx.x) * 3) + 2206)] = kernel[(((((((int)blockIdx.x) * 36864) + (((((int)threadIdx.x) + 735) / 192) * 4608)) + (rc_outer_outer * 576)) + (((((int)threadIdx.x) + 159) % 192) * 3)) + 1)];
    kernel_shared[((((int)threadIdx.x) * 3) + 2207)] = kernel[(((((((int)blockIdx.x) * 36864) + (((((int)threadIdx.x) + 735) / 192) * 4608)) + (rc_outer_outer * 576)) + (((((int)threadIdx.x) + 159) % 192) * 3)) + 2)];
    kernel_shared[((((int)threadIdx.x) * 3) + 2352)] = kernel[(((((((int)blockIdx.x) * 36864) + (((((int)threadIdx.x) + 784) / 192) * 4608)) + (rc_outer_outer * 576)) + (((int)threadIdx.x) * 3)) + 48)];
    kernel_shared[((((int)threadIdx.x) * 3) + 2353)] = kernel[(((((((int)blockIdx.x) * 36864) + (((((int)threadIdx.x) + 784) / 192) * 4608)) + (rc_outer_outer * 576)) + (((int)threadIdx.x) * 3)) + 49)];
    kernel_shared[((((int)threadIdx.x) * 3) + 2354)] = kernel[(((((((int)blockIdx.x) * 36864) + (((((int)threadIdx.x) + 784) / 192) * 4608)) + (rc_outer_outer * 576)) + (((int)threadIdx.x) * 3)) + 50)];
    kernel_shared[((((int)threadIdx.x) * 3) + 2499)] = kernel[(((((((int)blockIdx.x) * 36864) + (((((int)threadIdx.x) + 833) / 192) * 4608)) + (rc_outer_outer * 576)) + (((int)threadIdx.x) * 3)) + 195)];
    kernel_shared[((((int)threadIdx.x) * 3) + 2500)] = kernel[(((((((int)blockIdx.x) * 36864) + (((((int)threadIdx.x) + 833) / 192) * 4608)) + (rc_outer_outer * 576)) + (((int)threadIdx.x) * 3)) + 196)];
    kernel_shared[((((int)threadIdx.x) * 3) + 2501)] = kernel[(((((((int)blockIdx.x) * 36864) + (((((int)threadIdx.x) + 833) / 192) * 4608)) + (rc_outer_outer * 576)) + (((int)threadIdx.x) * 3)) + 197)];
    kernel_shared[((((int)threadIdx.x) * 3) + 2646)] = kernel[(((((((int)blockIdx.x) * 36864) + (((((int)threadIdx.x) + 882) / 192) * 4608)) + (rc_outer_outer * 576)) + (((int)threadIdx.x) * 3)) + 342)];
    kernel_shared[((((int)threadIdx.x) * 3) + 2647)] = kernel[(((((((int)blockIdx.x) * 36864) + (((((int)threadIdx.x) + 882) / 192) * 4608)) + (rc_outer_outer * 576)) + (((int)threadIdx.x) * 3)) + 343)];
    kernel_shared[((((int)threadIdx.x) * 3) + 2648)] = kernel[(((((((int)blockIdx.x) * 36864) + (((((int)threadIdx.x) + 882) / 192) * 4608)) + (rc_outer_outer * 576)) + (((int)threadIdx.x) * 3)) + 344)];
    kernel_shared[((((int)threadIdx.x) * 3) + 2793)] = kernel[((((((int)blockIdx.x) * 36864) + (((((int)threadIdx.x) + 931) / 192) * 4608)) + (rc_outer_outer * 576)) + (((((int)threadIdx.x) + 163) % 192) * 3))];
    kernel_shared[((((int)threadIdx.x) * 3) + 2794)] = kernel[(((((((int)blockIdx.x) * 36864) + (((((int)threadIdx.x) + 931) / 192) * 4608)) + (rc_outer_outer * 576)) + (((((int)threadIdx.x) + 163) % 192) * 3)) + 1)];
    kernel_shared[((((int)threadIdx.x) * 3) + 2795)] = kernel[(((((((int)blockIdx.x) * 36864) + (((((int)threadIdx.x) + 931) / 192) * 4608)) + (rc_outer_outer * 576)) + (((((int)threadIdx.x) + 163) % 192) * 3)) + 2)];
    kernel_shared[((((int)threadIdx.x) * 3) + 2940)] = kernel[(((((((int)blockIdx.x) * 36864) + (((((int)threadIdx.x) + 980) / 192) * 4608)) + (rc_outer_outer * 576)) + (((int)threadIdx.x) * 3)) + 60)];
    kernel_shared[((((int)threadIdx.x) * 3) + 2941)] = kernel[(((((((int)blockIdx.x) * 36864) + (((((int)threadIdx.x) + 980) / 192) * 4608)) + (rc_outer_outer * 576)) + (((int)threadIdx.x) * 3)) + 61)];
    kernel_shared[((((int)threadIdx.x) * 3) + 2942)] = kernel[(((((((int)blockIdx.x) * 36864) + (((((int)threadIdx.x) + 980) / 192) * 4608)) + (rc_outer_outer * 576)) + (((int)threadIdx.x) * 3)) + 62)];
    kernel_shared[((((int)threadIdx.x) * 3) + 3087)] = kernel[(((((((int)blockIdx.x) * 36864) + (((((int)threadIdx.x) + 1029) / 192) * 4608)) + (rc_outer_outer * 576)) + (((int)threadIdx.x) * 3)) + 207)];
    kernel_shared[((((int)threadIdx.x) * 3) + 3088)] = kernel[(((((((int)blockIdx.x) * 36864) + (((((int)threadIdx.x) + 1029) / 192) * 4608)) + (rc_outer_outer * 576)) + (((int)threadIdx.x) * 3)) + 208)];
    kernel_shared[((((int)threadIdx.x) * 3) + 3089)] = kernel[(((((((int)blockIdx.x) * 36864) + (((((int)threadIdx.x) + 1029) / 192) * 4608)) + (rc_outer_outer * 576)) + (((int)threadIdx.x) * 3)) + 209)];
    kernel_shared[((((int)threadIdx.x) * 3) + 3234)] = kernel[(((((((int)blockIdx.x) * 36864) + (((((int)threadIdx.x) + 1078) / 192) * 4608)) + (rc_outer_outer * 576)) + (((int)threadIdx.x) * 3)) + 354)];
    kernel_shared[((((int)threadIdx.x) * 3) + 3235)] = kernel[(((((((int)blockIdx.x) * 36864) + (((((int)threadIdx.x) + 1078) / 192) * 4608)) + (rc_outer_outer * 576)) + (((int)threadIdx.x) * 3)) + 355)];
    kernel_shared[((((int)threadIdx.x) * 3) + 3236)] = kernel[(((((((int)blockIdx.x) * 36864) + (((((int)threadIdx.x) + 1078) / 192) * 4608)) + (rc_outer_outer * 576)) + (((int)threadIdx.x) * 3)) + 356)];
    kernel_shared[((((int)threadIdx.x) * 3) + 3381)] = kernel[((((((int)blockIdx.x) * 36864) + (((((int)threadIdx.x) + 1127) / 192) * 4608)) + (rc_outer_outer * 576)) + (((((int)threadIdx.x) + 167) % 192) * 3))];
    kernel_shared[((((int)threadIdx.x) * 3) + 3382)] = kernel[(((((((int)blockIdx.x) * 36864) + (((((int)threadIdx.x) + 1127) / 192) * 4608)) + (rc_outer_outer * 576)) + (((((int)threadIdx.x) + 167) % 192) * 3)) + 1)];
    kernel_shared[((((int)threadIdx.x) * 3) + 3383)] = kernel[(((((((int)blockIdx.x) * 36864) + (((((int)threadIdx.x) + 1127) / 192) * 4608)) + (rc_outer_outer * 576)) + (((((int)threadIdx.x) + 167) % 192) * 3)) + 2)];
    kernel_shared[((((int)threadIdx.x) * 3) + 3528)] = kernel[(((((((int)blockIdx.x) * 36864) + (((((int)threadIdx.x) + 1176) / 192) * 4608)) + (rc_outer_outer * 576)) + (((int)threadIdx.x) * 3)) + 72)];
    kernel_shared[((((int)threadIdx.x) * 3) + 3529)] = kernel[(((((((int)blockIdx.x) * 36864) + (((((int)threadIdx.x) + 1176) / 192) * 4608)) + (rc_outer_outer * 576)) + (((int)threadIdx.x) * 3)) + 73)];
    kernel_shared[((((int)threadIdx.x) * 3) + 3530)] = kernel[(((((((int)blockIdx.x) * 36864) + (((((int)threadIdx.x) + 1176) / 192) * 4608)) + (rc_outer_outer * 576)) + (((int)threadIdx.x) * 3)) + 74)];
    kernel_shared[((((int)threadIdx.x) * 3) + 3675)] = kernel[(((((((int)blockIdx.x) * 36864) + (((((int)threadIdx.x) + 1225) / 192) * 4608)) + (rc_outer_outer * 576)) + (((int)threadIdx.x) * 3)) + 219)];
    kernel_shared[((((int)threadIdx.x) * 3) + 3676)] = kernel[(((((((int)blockIdx.x) * 36864) + (((((int)threadIdx.x) + 1225) / 192) * 4608)) + (rc_outer_outer * 576)) + (((int)threadIdx.x) * 3)) + 220)];
    kernel_shared[((((int)threadIdx.x) * 3) + 3677)] = kernel[(((((((int)blockIdx.x) * 36864) + (((((int)threadIdx.x) + 1225) / 192) * 4608)) + (rc_outer_outer * 576)) + (((int)threadIdx.x) * 3)) + 221)];
    kernel_shared[((((int)threadIdx.x) * 3) + 3822)] = kernel[(((((((int)blockIdx.x) * 36864) + (((((int)threadIdx.x) + 1274) / 192) * 4608)) + (rc_outer_outer * 576)) + (((int)threadIdx.x) * 3)) + 366)];
    kernel_shared[((((int)threadIdx.x) * 3) + 3823)] = kernel[(((((((int)blockIdx.x) * 36864) + (((((int)threadIdx.x) + 1274) / 192) * 4608)) + (rc_outer_outer * 576)) + (((int)threadIdx.x) * 3)) + 367)];
    kernel_shared[((((int)threadIdx.x) * 3) + 3824)] = kernel[(((((((int)blockIdx.x) * 36864) + (((((int)threadIdx.x) + 1274) / 192) * 4608)) + (rc_outer_outer * 576)) + (((int)threadIdx.x) * 3)) + 368)];
    kernel_shared[((((int)threadIdx.x) * 3) + 3969)] = kernel[((((((int)blockIdx.x) * 36864) + (((((int)threadIdx.x) + 1323) / 192) * 4608)) + (rc_outer_outer * 576)) + (((((int)threadIdx.x) + 171) % 192) * 3))];
    kernel_shared[((((int)threadIdx.x) * 3) + 3970)] = kernel[(((((((int)blockIdx.x) * 36864) + (((((int)threadIdx.x) + 1323) / 192) * 4608)) + (rc_outer_outer * 576)) + (((((int)threadIdx.x) + 171) % 192) * 3)) + 1)];
    kernel_shared[((((int)threadIdx.x) * 3) + 3971)] = kernel[(((((((int)blockIdx.x) * 36864) + (((((int)threadIdx.x) + 1323) / 192) * 4608)) + (rc_outer_outer * 576)) + (((((int)threadIdx.x) + 171) % 192) * 3)) + 2)];
    kernel_shared[((((int)threadIdx.x) * 3) + 4116)] = kernel[(((((((int)blockIdx.x) * 36864) + (((((int)threadIdx.x) + 1372) / 192) * 4608)) + (rc_outer_outer * 576)) + (((int)threadIdx.x) * 3)) + 84)];
    kernel_shared[((((int)threadIdx.x) * 3) + 4117)] = kernel[(((((((int)blockIdx.x) * 36864) + (((((int)threadIdx.x) + 1372) / 192) * 4608)) + (rc_outer_outer * 576)) + (((int)threadIdx.x) * 3)) + 85)];
    kernel_shared[((((int)threadIdx.x) * 3) + 4118)] = kernel[(((((((int)blockIdx.x) * 36864) + (((((int)threadIdx.x) + 1372) / 192) * 4608)) + (rc_outer_outer * 576)) + (((int)threadIdx.x) * 3)) + 86)];
    kernel_shared[((((int)threadIdx.x) * 3) + 4263)] = kernel[(((((((int)blockIdx.x) * 36864) + (((((int)threadIdx.x) + 1421) / 192) * 4608)) + (rc_outer_outer * 576)) + (((int)threadIdx.x) * 3)) + 231)];
    kernel_shared[((((int)threadIdx.x) * 3) + 4264)] = kernel[(((((((int)blockIdx.x) * 36864) + (((((int)threadIdx.x) + 1421) / 192) * 4608)) + (rc_outer_outer * 576)) + (((int)threadIdx.x) * 3)) + 232)];
    kernel_shared[((((int)threadIdx.x) * 3) + 4265)] = kernel[(((((((int)blockIdx.x) * 36864) + (((((int)threadIdx.x) + 1421) / 192) * 4608)) + (rc_outer_outer * 576)) + (((int)threadIdx.x) * 3)) + 233)];
    kernel_shared[((((int)threadIdx.x) * 3) + 4410)] = kernel[(((((((int)blockIdx.x) * 36864) + (((((int)threadIdx.x) + 1470) / 192) * 4608)) + (rc_outer_outer * 576)) + (((int)threadIdx.x) * 3)) + 378)];
    kernel_shared[((((int)threadIdx.x) * 3) + 4411)] = kernel[(((((((int)blockIdx.x) * 36864) + (((((int)threadIdx.x) + 1470) / 192) * 4608)) + (rc_outer_outer * 576)) + (((int)threadIdx.x) * 3)) + 379)];
    kernel_shared[((((int)threadIdx.x) * 3) + 4412)] = kernel[(((((((int)blockIdx.x) * 36864) + (((((int)threadIdx.x) + 1470) / 192) * 4608)) + (rc_outer_outer * 576)) + (((int)threadIdx.x) * 3)) + 380)];
    if (((int)threadIdx.x) &lt; 17) {
      kernel_shared[((((int)threadIdx.x) * 3) + 4557)] = kernel[(((((((int)blockIdx.x) * 36864) + (((((int)threadIdx.x) + 1519) / 192) * 4608)) + (rc_outer_outer * 576)) + (((int)threadIdx.x) * 3)) + 525)];
      kernel_shared[((((int)threadIdx.x) * 3) + 4558)] = kernel[(((((((int)blockIdx.x) * 36864) + (((((int)threadIdx.x) + 1519) / 192) * 4608)) + (rc_outer_outer * 576)) + (((int)threadIdx.x) * 3)) + 526)];
      kernel_shared[((((int)threadIdx.x) * 3) + 4559)] = kernel[(((((((int)blockIdx.x) * 36864) + (((((int)threadIdx.x) + 1519) / 192) * 4608)) + (rc_outer_outer * 576)) + (((int)threadIdx.x) * 3)) + 527)];
    }
    __syncthreads();
    for (int rc_outer_inner = 0; rc_outer_inner &lt; 64; ++rc_outer_inner) {
      conv2d_nchw[0] = (conv2d_nchw[0] + (pad_temp_shared[(((rc_outer_inner * 81) + ((((int)threadIdx.x) / 7) * 9)) + (((int)threadIdx.x) % 7))] * kernel_shared[(rc_outer_inner * 9)]));
      conv2d_nchw[4] = (conv2d_nchw[4] + (pad_temp_shared[(((rc_outer_inner * 81) + ((((int)threadIdx.x) / 7) * 9)) + (((int)threadIdx.x) % 7))] * kernel_shared[((rc_outer_inner * 9) + 2304)]));
      conv2d_nchw[1] = (conv2d_nchw[1] + (pad_temp_shared[(((rc_outer_inner * 81) + ((((int)threadIdx.x) / 7) * 9)) + (((int)threadIdx.x) % 7))] * kernel_shared[((rc_outer_inner * 9) + 576)]));
      conv2d_nchw[5] = (conv2d_nchw[5] + (pad_temp_shared[(((rc_outer_inner * 81) + ((((int)threadIdx.x) / 7) * 9)) + (((int)threadIdx.x) % 7))] * kernel_shared[((rc_outer_inner * 9) + 2880)]));
      conv2d_nchw[0] = (conv2d_nchw[0] + (pad_temp_shared[((((rc_outer_inner * 81) + ((((int)threadIdx.x) / 7) * 9)) + (((int)threadIdx.x) % 7)) + 1)] * kernel_shared[((rc_outer_inner * 9) + 1)]));
      conv2d_nchw[4] = (conv2d_nchw[4] + (pad_temp_shared[((((rc_outer_inner * 81) + ((((int)threadIdx.x) / 7) * 9)) + (((int)threadIdx.x) % 7)) + 1)] * kernel_shared[((rc_outer_inner * 9) + 2305)]));
      conv2d_nchw[1] = (conv2d_nchw[1] + (pad_temp_shared[((((rc_outer_inner * 81) + ((((int)threadIdx.x) / 7) * 9)) + (((int)threadIdx.x) % 7)) + 1)] * kernel_shared[((rc_outer_inner * 9) + 577)]));
      conv2d_nchw[5] = (conv2d_nchw[5] + (pad_temp_shared[((((rc_outer_inner * 81) + ((((int)threadIdx.x) / 7) * 9)) + (((int)threadIdx.x) % 7)) + 1)] * kernel_shared[((rc_outer_inner * 9) + 2881)]));
      conv2d_nchw[0] = (conv2d_nchw[0] + (pad_temp_shared[((((rc_outer_inner * 81) + ((((int)threadIdx.x) / 7) * 9)) + (((int)threadIdx.x) % 7)) + 2)] * kernel_shared[((rc_outer_inner * 9) + 2)]));
      conv2d_nchw[4] = (conv2d_nchw[4] + (pad_temp_shared[((((rc_outer_inner * 81) + ((((int)threadIdx.x) / 7) * 9)) + (((int)threadIdx.x) % 7)) + 2)] * kernel_shared[((rc_outer_inner * 9) + 2306)]));
      conv2d_nchw[1] = (conv2d_nchw[1] + (pad_temp_shared[((((rc_outer_inner * 81) + ((((int)threadIdx.x) / 7) * 9)) + (((int)threadIdx.x) % 7)) + 2)] * kernel_shared[((rc_outer_inner * 9) + 578)]));
      conv2d_nchw[5] = (conv2d_nchw[5] + (pad_temp_shared[((((rc_outer_inner * 81) + ((((int)threadIdx.x) / 7) * 9)) + (((int)threadIdx.x) % 7)) + 2)] * kernel_shared[((rc_outer_inner * 9) + 2882)]));
      conv2d_nchw[2] = (conv2d_nchw[2] + (pad_temp_shared[(((rc_outer_inner * 81) + ((((int)threadIdx.x) / 7) * 9)) + (((int)threadIdx.x) % 7))] * kernel_shared[((rc_outer_inner * 9) + 1152)]));
      conv2d_nchw[6] = (conv2d_nchw[6] + (pad_temp_shared[(((rc_outer_inner * 81) + ((((int)threadIdx.x) / 7) * 9)) + (((int)threadIdx.x) % 7))] * kernel_shared[((rc_outer_inner * 9) + 3456)]));
      conv2d_nchw[3] = (conv2d_nchw[3] + (pad_temp_shared[(((rc_outer_inner * 81) + ((((int)threadIdx.x) / 7) * 9)) + (((int)threadIdx.x) % 7))] * kernel_shared[((rc_outer_inner * 9) + 1728)]));
      conv2d_nchw[7] = (conv2d_nchw[7] + (pad_temp_shared[(((rc_outer_inner * 81) + ((((int)threadIdx.x) / 7) * 9)) + (((int)threadIdx.x) % 7))] * kernel_shared[((rc_outer_inner * 9) + 4032)]));
      conv2d_nchw[2] = (conv2d_nchw[2] + (pad_temp_shared[((((rc_outer_inner * 81) + ((((int)threadIdx.x) / 7) * 9)) + (((int)threadIdx.x) % 7)) + 1)] * kernel_shared[((rc_outer_inner * 9) + 1153)]));
      conv2d_nchw[6] = (conv2d_nchw[6] + (pad_temp_shared[((((rc_outer_inner * 81) + ((((int)threadIdx.x) / 7) * 9)) + (((int)threadIdx.x) % 7)) + 1)] * kernel_shared[((rc_outer_inner * 9) + 3457)]));
      conv2d_nchw[3] = (conv2d_nchw[3] + (pad_temp_shared[((((rc_outer_inner * 81) + ((((int)threadIdx.x) / 7) * 9)) + (((int)threadIdx.x) % 7)) + 1)] * kernel_shared[((rc_outer_inner * 9) + 1729)]));
      conv2d_nchw[7] = (conv2d_nchw[7] + (pad_temp_shared[((((rc_outer_inner * 81) + ((((int)threadIdx.x) / 7) * 9)) + (((int)threadIdx.x) % 7)) + 1)] * kernel_shared[((rc_outer_inner * 9) + 4033)]));
      conv2d_nchw[2] = (conv2d_nchw[2] + (pad_temp_shared[((((rc_outer_inner * 81) + ((((int)threadIdx.x) / 7) * 9)) + (((int)threadIdx.x) % 7)) + 2)] * kernel_shared[((rc_outer_inner * 9) + 1154)]));
      conv2d_nchw[6] = (conv2d_nchw[6] + (pad_temp_shared[((((rc_outer_inner * 81) + ((((int)threadIdx.x) / 7) * 9)) + (((int)threadIdx.x) % 7)) + 2)] * kernel_shared[((rc_outer_inner * 9) + 3458)]));
      conv2d_nchw[3] = (conv2d_nchw[3] + (pad_temp_shared[((((rc_outer_inner * 81) + ((((int)threadIdx.x) / 7) * 9)) + (((int)threadIdx.x) % 7)) + 2)] * kernel_shared[((rc_outer_inner * 9) + 1730)]));
      conv2d_nchw[7] = (conv2d_nchw[7] + (pad_temp_shared[((((rc_outer_inner * 81) + ((((int)threadIdx.x) / 7) * 9)) + (((int)threadIdx.x) % 7)) + 2)] * kernel_shared[((rc_outer_inner * 9) + 4034)]));
      conv2d_nchw[0] = (conv2d_nchw[0] + (pad_temp_shared[((((rc_outer_inner * 81) + ((((int)threadIdx.x) / 7) * 9)) + (((int)threadIdx.x) % 7)) + 9)] * kernel_shared[((rc_outer_inner * 9) + 3)]));
      conv2d_nchw[4] = (conv2d_nchw[4] + (pad_temp_shared[((((rc_outer_inner * 81) + ((((int)threadIdx.x) / 7) * 9)) + (((int)threadIdx.x) % 7)) + 9)] * kernel_shared[((rc_outer_inner * 9) + 2307)]));
      conv2d_nchw[1] = (conv2d_nchw[1] + (pad_temp_shared[((((rc_outer_inner * 81) + ((((int)threadIdx.x) / 7) * 9)) + (((int)threadIdx.x) % 7)) + 9)] * kernel_shared[((rc_outer_inner * 9) + 579)]));
      conv2d_nchw[5] = (conv2d_nchw[5] + (pad_temp_shared[((((rc_outer_inner * 81) + ((((int)threadIdx.x) / 7) * 9)) + (((int)threadIdx.x) % 7)) + 9)] * kernel_shared[((rc_outer_inner * 9) + 2883)]));
      conv2d_nchw[0] = (conv2d_nchw[0] + (pad_temp_shared[((((rc_outer_inner * 81) + ((((int)threadIdx.x) / 7) * 9)) + (((int)threadIdx.x) % 7)) + 10)] * kernel_shared[((rc_outer_inner * 9) + 4)]));
      conv2d_nchw[4] = (conv2d_nchw[4] + (pad_temp_shared[((((rc_outer_inner * 81) + ((((int)threadIdx.x) / 7) * 9)) + (((int)threadIdx.x) % 7)) + 10)] * kernel_shared[((rc_outer_inner * 9) + 2308)]));
      conv2d_nchw[1] = (conv2d_nchw[1] + (pad_temp_shared[((((rc_outer_inner * 81) + ((((int)threadIdx.x) / 7) * 9)) + (((int)threadIdx.x) % 7)) + 10)] * kernel_shared[((rc_outer_inner * 9) + 580)]));
      conv2d_nchw[5] = (conv2d_nchw[5] + (pad_temp_shared[((((rc_outer_inner * 81) + ((((int)threadIdx.x) / 7) * 9)) + (((int)threadIdx.x) % 7)) + 10)] * kernel_shared[((rc_outer_inner * 9) + 2884)]));
      conv2d_nchw[0] = (conv2d_nchw[0] + (pad_temp_shared[((((rc_outer_inner * 81) + ((((int)threadIdx.x) / 7) * 9)) + (((int)threadIdx.x) % 7)) + 11)] * kernel_shared[((rc_outer_inner * 9) + 5)]));
      conv2d_nchw[4] = (conv2d_nchw[4] + (pad_temp_shared[((((rc_outer_inner * 81) + ((((int)threadIdx.x) / 7) * 9)) + (((int)threadIdx.x) % 7)) + 11)] * kernel_shared[((rc_outer_inner * 9) + 2309)]));
      conv2d_nchw[1] = (conv2d_nchw[1] + (pad_temp_shared[((((rc_outer_inner * 81) + ((((int)threadIdx.x) / 7) * 9)) + (((int)threadIdx.x) % 7)) + 11)] * kernel_shared[((rc_outer_inner * 9) + 581)]));
      conv2d_nchw[5] = (conv2d_nchw[5] + (pad_temp_shared[((((rc_outer_inner * 81) + ((((int)threadIdx.x) / 7) * 9)) + (((int)threadIdx.x) % 7)) + 11)] * kernel_shared[((rc_outer_inner * 9) + 2885)]));
      conv2d_nchw[2] = (conv2d_nchw[2] + (pad_temp_shared[((((rc_outer_inner * 81) + ((((int)threadIdx.x) / 7) * 9)) + (((int)threadIdx.x) % 7)) + 9)] * kernel_shared[((rc_outer_inner * 9) + 1155)]));
      conv2d_nchw[6] = (conv2d_nchw[6] + (pad_temp_shared[((((rc_outer_inner * 81) + ((((int)threadIdx.x) / 7) * 9)) + (((int)threadIdx.x) % 7)) + 9)] * kernel_shared[((rc_outer_inner * 9) + 3459)]));
      conv2d_nchw[3] = (conv2d_nchw[3] + (pad_temp_shared[((((rc_outer_inner * 81) + ((((int)threadIdx.x) / 7) * 9)) + (((int)threadIdx.x) % 7)) + 9)] * kernel_shared[((rc_outer_inner * 9) + 1731)]));
      conv2d_nchw[7] = (conv2d_nchw[7] + (pad_temp_shared[((((rc_outer_inner * 81) + ((((int)threadIdx.x) / 7) * 9)) + (((int)threadIdx.x) % 7)) + 9)] * kernel_shared[((rc_outer_inner * 9) + 4035)]));
      conv2d_nchw[2] = (conv2d_nchw[2] + (pad_temp_shared[((((rc_outer_inner * 81) + ((((int)threadIdx.x) / 7) * 9)) + (((int)threadIdx.x) % 7)) + 10)] * kernel_shared[((rc_outer_inner * 9) + 1156)]));
      conv2d_nchw[6] = (conv2d_nchw[6] + (pad_temp_shared[((((rc_outer_inner * 81) + ((((int)threadIdx.x) / 7) * 9)) + (((int)threadIdx.x) % 7)) + 10)] * kernel_shared[((rc_outer_inner * 9) + 3460)]));
      conv2d_nchw[3] = (conv2d_nchw[3] + (pad_temp_shared[((((rc_outer_inner * 81) + ((((int)threadIdx.x) / 7) * 9)) + (((int)threadIdx.x) % 7)) + 10)] * kernel_shared[((rc_outer_inner * 9) + 1732)]));
      conv2d_nchw[7] = (conv2d_nchw[7] + (pad_temp_shared[((((rc_outer_inner * 81) + ((((int)threadIdx.x) / 7) * 9)) + (((int)threadIdx.x) % 7)) + 10)] * kernel_shared[((rc_outer_inner * 9) + 4036)]));
      conv2d_nchw[2] = (conv2d_nchw[2] + (pad_temp_shared[((((rc_outer_inner * 81) + ((((int)threadIdx.x) / 7) * 9)) + (((int)threadIdx.x) % 7)) + 11)] * kernel_shared[((rc_outer_inner * 9) + 1157)]));
      conv2d_nchw[6] = (conv2d_nchw[6] + (pad_temp_shared[((((rc_outer_inner * 81) + ((((int)threadIdx.x) / 7) * 9)) + (((int)threadIdx.x) % 7)) + 11)] * kernel_shared[((rc_outer_inner * 9) + 3461)]));
      conv2d_nchw[3] = (conv2d_nchw[3] + (pad_temp_shared[((((rc_outer_inner * 81) + ((((int)threadIdx.x) / 7) * 9)) + (((int)threadIdx.x) % 7)) + 11)] * kernel_shared[((rc_outer_inner * 9) + 1733)]));
      conv2d_nchw[7] = (conv2d_nchw[7] + (pad_temp_shared[((((rc_outer_inner * 81) + ((((int)threadIdx.x) / 7) * 9)) + (((int)threadIdx.x) % 7)) + 11)] * kernel_shared[((rc_outer_inner * 9) + 4037)]));
      conv2d_nchw[0] = (conv2d_nchw[0] + (pad_temp_shared[((((rc_outer_inner * 81) + ((((int)threadIdx.x) / 7) * 9)) + (((int)threadIdx.x) % 7)) + 18)] * kernel_shared[((rc_outer_inner * 9) + 6)]));
      conv2d_nchw[4] = (conv2d_nchw[4] + (pad_temp_shared[((((rc_outer_inner * 81) + ((((int)threadIdx.x) / 7) * 9)) + (((int)threadIdx.x) % 7)) + 18)] * kernel_shared[((rc_outer_inner * 9) + 2310)]));
      conv2d_nchw[1] = (conv2d_nchw[1] + (pad_temp_shared[((((rc_outer_inner * 81) + ((((int)threadIdx.x) / 7) * 9)) + (((int)threadIdx.x) % 7)) + 18)] * kernel_shared[((rc_outer_inner * 9) + 582)]));
      conv2d_nchw[5] = (conv2d_nchw[5] + (pad_temp_shared[((((rc_outer_inner * 81) + ((((int)threadIdx.x) / 7) * 9)) + (((int)threadIdx.x) % 7)) + 18)] * kernel_shared[((rc_outer_inner * 9) + 2886)]));
      conv2d_nchw[0] = (conv2d_nchw[0] + (pad_temp_shared[((((rc_outer_inner * 81) + ((((int)threadIdx.x) / 7) * 9)) + (((int)threadIdx.x) % 7)) + 19)] * kernel_shared[((rc_outer_inner * 9) + 7)]));
      conv2d_nchw[4] = (conv2d_nchw[4] + (pad_temp_shared[((((rc_outer_inner * 81) + ((((int)threadIdx.x) / 7) * 9)) + (((int)threadIdx.x) % 7)) + 19)] * kernel_shared[((rc_outer_inner * 9) + 2311)]));
      conv2d_nchw[1] = (conv2d_nchw[1] + (pad_temp_shared[((((rc_outer_inner * 81) + ((((int)threadIdx.x) / 7) * 9)) + (((int)threadIdx.x) % 7)) + 19)] * kernel_shared[((rc_outer_inner * 9) + 583)]));
      conv2d_nchw[5] = (conv2d_nchw[5] + (pad_temp_shared[((((rc_outer_inner * 81) + ((((int)threadIdx.x) / 7) * 9)) + (((int)threadIdx.x) % 7)) + 19)] * kernel_shared[((rc_outer_inner * 9) + 2887)]));
      conv2d_nchw[0] = (conv2d_nchw[0] + (pad_temp_shared[((((rc_outer_inner * 81) + ((((int)threadIdx.x) / 7) * 9)) + (((int)threadIdx.x) % 7)) + 20)] * kernel_shared[((rc_outer_inner * 9) + 8)]));
      conv2d_nchw[4] = (conv2d_nchw[4] + (pad_temp_shared[((((rc_outer_inner * 81) + ((((int)threadIdx.x) / 7) * 9)) + (((int)threadIdx.x) % 7)) + 20)] * kernel_shared[((rc_outer_inner * 9) + 2312)]));
      conv2d_nchw[1] = (conv2d_nchw[1] + (pad_temp_shared[((((rc_outer_inner * 81) + ((((int)threadIdx.x) / 7) * 9)) + (((int)threadIdx.x) % 7)) + 20)] * kernel_shared[((rc_outer_inner * 9) + 584)]));
      conv2d_nchw[5] = (conv2d_nchw[5] + (pad_temp_shared[((((rc_outer_inner * 81) + ((((int)threadIdx.x) / 7) * 9)) + (((int)threadIdx.x) % 7)) + 20)] * kernel_shared[((rc_outer_inner * 9) + 2888)]));
      conv2d_nchw[2] = (conv2d_nchw[2] + (pad_temp_shared[((((rc_outer_inner * 81) + ((((int)threadIdx.x) / 7) * 9)) + (((int)threadIdx.x) % 7)) + 18)] * kernel_shared[((rc_outer_inner * 9) + 1158)]));
      conv2d_nchw[6] = (conv2d_nchw[6] + (pad_temp_shared[((((rc_outer_inner * 81) + ((((int)threadIdx.x) / 7) * 9)) + (((int)threadIdx.x) % 7)) + 18)] * kernel_shared[((rc_outer_inner * 9) + 3462)]));
      conv2d_nchw[3] = (conv2d_nchw[3] + (pad_temp_shared[((((rc_outer_inner * 81) + ((((int)threadIdx.x) / 7) * 9)) + (((int)threadIdx.x) % 7)) + 18)] * kernel_shared[((rc_outer_inner * 9) + 1734)]));
      conv2d_nchw[7] = (conv2d_nchw[7] + (pad_temp_shared[((((rc_outer_inner * 81) + ((((int)threadIdx.x) / 7) * 9)) + (((int)threadIdx.x) % 7)) + 18)] * kernel_shared[((rc_outer_inner * 9) + 4038)]));
      conv2d_nchw[2] = (conv2d_nchw[2] + (pad_temp_shared[((((rc_outer_inner * 81) + ((((int)threadIdx.x) / 7) * 9)) + (((int)threadIdx.x) % 7)) + 19)] * kernel_shared[((rc_outer_inner * 9) + 1159)]));
      conv2d_nchw[6] = (conv2d_nchw[6] + (pad_temp_shared[((((rc_outer_inner * 81) + ((((int)threadIdx.x) / 7) * 9)) + (((int)threadIdx.x) % 7)) + 19)] * kernel_shared[((rc_outer_inner * 9) + 3463)]));
      conv2d_nchw[3] = (conv2d_nchw[3] + (pad_temp_shared[((((rc_outer_inner * 81) + ((((int)threadIdx.x) / 7) * 9)) + (((int)threadIdx.x) % 7)) + 19)] * kernel_shared[((rc_outer_inner * 9) + 1735)]));
      conv2d_nchw[7] = (conv2d_nchw[7] + (pad_temp_shared[((((rc_outer_inner * 81) + ((((int)threadIdx.x) / 7) * 9)) + (((int)threadIdx.x) % 7)) + 19)] * kernel_shared[((rc_outer_inner * 9) + 4039)]));
      conv2d_nchw[2] = (conv2d_nchw[2] + (pad_temp_shared[((((rc_outer_inner * 81) + ((((int)threadIdx.x) / 7) * 9)) + (((int)threadIdx.x) % 7)) + 20)] * kernel_shared[((rc_outer_inner * 9) + 1160)]));
      conv2d_nchw[6] = (conv2d_nchw[6] + (pad_temp_shared[((((rc_outer_inner * 81) + ((((int)threadIdx.x) / 7) * 9)) + (((int)threadIdx.x) % 7)) + 20)] * kernel_shared[((rc_outer_inner * 9) + 3464)]));
      conv2d_nchw[3] = (conv2d_nchw[3] + (pad_temp_shared[((((rc_outer_inner * 81) + ((((int)threadIdx.x) / 7) * 9)) + (((int)threadIdx.x) % 7)) + 20)] * kernel_shared[((rc_outer_inner * 9) + 1736)]));
      conv2d_nchw[7] = (conv2d_nchw[7] + (pad_temp_shared[((((rc_outer_inner * 81) + ((((int)threadIdx.x) / 7) * 9)) + (((int)threadIdx.x) % 7)) + 20)] * kernel_shared[((rc_outer_inner * 9) + 4040)]));
    }
  }
  for (int i1_inner = 0; i1_inner &lt; 4; ++i1_inner) {
    compute[(((((int)blockIdx.x) * 392) + (i1_inner * 49)) + ((int)threadIdx.x))] = max((conv2d_nchw[i1_inner] + bias[((((int)blockIdx.x) * 8) + i1_inner)]), 0.000000e+00f);
    compute[((((((int)blockIdx.x) * 392) + (i1_inner * 49)) + ((int)threadIdx.x)) + 196)] = max((conv2d_nchw[(i1_inner + 4)] + bias[(((((int)blockIdx.x) * 8) + i1_inner) + 4)]), 0.000000e+00f);
  }
}
</pre></div>
</div>
<p>A more complicated example is to resume the search.
In this case, we need to create the search policy and cost model by ourselves
and resume the status of search policy and cost model with the log file.
In the example below we resume the status and do more 5 trials.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">resume_search</span><span class="p">(</span><a href="../../reference/api/python/auto_scheduler.html#tvm.auto_scheduler.SearchTask" title="tvm.auto_scheduler.SearchTask" class="sphx-glr-backref-module-tvm-auto_scheduler sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">task</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">log_file</span></a><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Resume search:&quot;</span><span class="p">)</span>
    <span class="n">cost_model</span> <span class="o">=</span> <a href="../../reference/api/python/auto_scheduler.html#tvm.auto_scheduler.XGBModel" title="tvm.auto_scheduler.XGBModel" class="sphx-glr-backref-module-tvm-auto_scheduler sphx-glr-backref-type-py-class"><span class="n">auto_scheduler</span><span class="o">.</span><span class="n">XGBModel</span></a><span class="p">()</span>
    <span class="n">cost_model</span><span class="o">.</span><span class="n">update_from_file</span><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">log_file</span></a><span class="p">)</span>
    <span class="n">search_policy</span> <span class="o">=</span> <a href="../../reference/api/python/auto_scheduler.html#tvm.auto_scheduler.SketchPolicy" title="tvm.auto_scheduler.SketchPolicy" class="sphx-glr-backref-module-tvm-auto_scheduler sphx-glr-backref-type-py-class"><span class="n">auto_scheduler</span><span class="o">.</span><span class="n">SketchPolicy</span></a><span class="p">(</span>
        <a href="../../reference/api/python/auto_scheduler.html#tvm.auto_scheduler.SearchTask" title="tvm.auto_scheduler.SearchTask" class="sphx-glr-backref-module-tvm-auto_scheduler sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">task</span></a><span class="p">,</span> <span class="n">cost_model</span><span class="p">,</span> <span class="n">init_search_callbacks</span><span class="o">=</span><span class="p">[</span><a href="../../reference/api/python/auto_scheduler.html#tvm.auto_scheduler.PreloadMeasuredStates" title="tvm.auto_scheduler.PreloadMeasuredStates" class="sphx-glr-backref-module-tvm-auto_scheduler sphx-glr-backref-type-py-class"><span class="n">auto_scheduler</span><span class="o">.</span><span class="n">PreloadMeasuredStates</span></a><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">log_file</span></a><span class="p">)]</span>
    <span class="p">)</span>
    <span class="n">measure_ctx</span> <span class="o">=</span> <a href="../../reference/api/python/auto_scheduler.html#tvm.auto_scheduler.LocalRPCMeasureContext" title="tvm.auto_scheduler.LocalRPCMeasureContext" class="sphx-glr-backref-module-tvm-auto_scheduler sphx-glr-backref-type-py-class"><span class="n">auto_scheduler</span><span class="o">.</span><span class="n">LocalRPCMeasureContext</span></a><span class="p">(</span><span class="n">min_repeat_ms</span><span class="o">=</span><span class="mi">300</span><span class="p">)</span>
    <a href="../../reference/api/python/auto_scheduler.html#tvm.auto_scheduler.TuningOptions" title="tvm.auto_scheduler.TuningOptions" class="sphx-glr-backref-module-tvm-auto_scheduler sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">tune_option</span></a> <span class="o">=</span> <a href="../../reference/api/python/auto_scheduler.html#tvm.auto_scheduler.TuningOptions" title="tvm.auto_scheduler.TuningOptions" class="sphx-glr-backref-module-tvm-auto_scheduler sphx-glr-backref-type-py-class"><span class="n">auto_scheduler</span><span class="o">.</span><span class="n">TuningOptions</span></a><span class="p">(</span>
        <span class="n">num_measure_trials</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
        <span class="n">runner</span><span class="o">=</span><span class="n">measure_ctx</span><span class="o">.</span><span class="n">runner</span><span class="p">,</span>
        <span class="n">measure_callbacks</span><span class="o">=</span><span class="p">[</span><a href="../../reference/api/python/auto_scheduler.html#tvm.auto_scheduler.RecordToFile" title="tvm.auto_scheduler.RecordToFile" class="sphx-glr-backref-module-tvm-auto_scheduler sphx-glr-backref-type-py-class"><span class="n">auto_scheduler</span><span class="o">.</span><span class="n">RecordToFile</span></a><span class="p">(</span><a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">log_file</span></a><span class="p">)],</span>
    <span class="p">)</span>
    <a href="../../reference/api/python/auto_scheduler.html#tvm.auto_scheduler.SearchTask.tune" title="tvm.auto_scheduler.SearchTask.tune" class="sphx-glr-backref-module-tvm-auto_scheduler sphx-glr-backref-type-py-method"><span class="n">task</span><span class="o">.</span><span class="n">tune</span></a><span class="p">(</span><a href="../../reference/api/python/auto_scheduler.html#tvm.auto_scheduler.TuningOptions" title="tvm.auto_scheduler.TuningOptions" class="sphx-glr-backref-module-tvm-auto_scheduler sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">tune_option</span></a><span class="p">,</span> <span class="n">search_policy</span><span class="o">=</span><span class="n">search_policy</span><span class="p">)</span>

    <span class="c1"># Kill the measurement process</span>
    <span class="k">del</span> <span class="n">measure_ctx</span>


<span class="n">resume_search</span><span class="p">(</span><a href="../../reference/api/python/auto_scheduler.html#tvm.auto_scheduler.SearchTask" title="tvm.auto_scheduler.SearchTask" class="sphx-glr-backref-module-tvm-auto_scheduler sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">task</span></a><span class="p">,</span> <a href="https://docs.python.org/3/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">log_file</span></a><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Resume search:
/venv/apache-tvm-py3.7/lib/python3.7/site-packages/xgboost/training.py:17: UserWarning: Old style callback is deprecated.  See: https://xgboost.readthedocs.io/en/latest/python/callbacks.html
  warnings.warn(f&#39;Old style callback is deprecated.  See: {link}&#39;, UserWarning)
Get devices for measurement successfully!
</pre></div>
</div>
<p class="sphx-glr-timing"><strong>Total running time of the script:</strong> ( 3 minutes  33.216 seconds)</p>
<div class="sphx-glr-footer sphx-glr-footer-example docutils container" id="sphx-glr-download-how-to-tune-with-autoscheduler-tune-conv2d-layer-cuda-py">
<div class="sphx-glr-download sphx-glr-download-python docutils container">
<p><a class="reference download internal" download="" href="../../_downloads/e3e540f3b477c0c52d8eb73e674e8ffd/tune_conv2d_layer_cuda.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">tune_conv2d_layer_cuda.py</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-jupyter docutils container">
<p><a class="reference download internal" download="" href="../../_downloads/5f1f7bd7d90710fd404f7bcdc4965622/tune_conv2d_layer_cuda.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">tune_conv2d_layer_cuda.ipynb</span></code></a></p>
</div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.github.io">Gallery generated by Sphinx-Gallery</a></p>
</div>
</div>


           </div>
           
          </div>
          

<footer>

    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="tune_network_x86.html" class="btn btn-neutral float-right" title="Auto-scheduling a Neural Network for x86 CPU" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="index.html" class="btn btn-neutral float-left" title="Use AutoScheduler for Template-Free Scheduling" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>

<div id="button" class="backtop"><img src="../../_static/img/right.svg" alt="backtop"/> </div>
<section class="footerSec">
    <div class="footerHeader">
      <div class="d-flex align-md-items-center justify-content-between flex-column flex-md-row">
        <div class="copywrite d-flex align-items-center">
          <h5 id="copy-right-info">© 2022 Apache Software Foundation | All rights reserved</h5>
        </div>
      </div>

    </div>

    <div>
      <div class="footernote">Copyright © 2022 The Apache Software Foundation. Apache TVM, Apache, the Apache feather, and the Apache TVM project logo are either trademarks or registered trademarks of the Apache Software Foundation.</div>
    </div>

</section>
</footer>
        </div>
      </div>

    </section>

  </div>
  

    <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.12.9/umd/popper.min.js" integrity="sha384-ApNbgh9B+Y1QKtv3Rn7W3mgPxhU9K/ScQsAP7hUibX39j7fakFPskvXusvfa0b4Q" crossorigin="anonymous"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/js/bootstrap.min.js" integrity="sha384-JZR6Spejh4U02d8jOt6vLEHfe/JQGiRRSQQxSfFWpi1MquVdAyjUar5+76PVCmYl" crossorigin="anonymous"></script>

  </body>
  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
    <!-- Theme Analytics -->
    <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-75982049-2', 'auto');
    ga('send', 'pageview');
    </script>

    
   

</body>
</html>