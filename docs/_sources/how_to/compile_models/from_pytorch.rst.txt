
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "how_to/compile_models/from_pytorch.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        Click :ref:`here <sphx_glr_download_how_to_compile_models_from_pytorch.py>`
        to download the full example code

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_how_to_compile_models_from_pytorch.py:


Compile PyTorch Models
======================
**Author**: `Alex Wong <https://github.com/alexwong/>`_

This article is an introductory tutorial to deploy PyTorch models with Relay.

For us to begin with, PyTorch should be installed.
TorchVision is also required since we will be using it as our model zoo.

A quick solution is to install via pip

.. code-block:: bash

    pip install torch==1.7.0
    pip install torchvision==0.8.1

or please refer to official site
https://pytorch.org/get-started/locally/

PyTorch versions should be backwards compatible but should be used
with the proper TorchVision version.

Currently, TVM supports PyTorch 1.7 and 1.4. Other versions may
be unstable.

.. GENERATED FROM PYTHON SOURCE LINES 43-56

.. code-block:: default



    import tvm
    from tvm import relay

    import numpy as np

    from tvm.contrib.download import download_testdata

    # PyTorch imports
    import torch
    import torchvision








.. GENERATED FROM PYTHON SOURCE LINES 62-64

Load a pretrained PyTorch model
-------------------------------

.. GENERATED FROM PYTHON SOURCE LINES 64-73

.. code-block:: default

    model_name = "resnet18"
    model = getattr(torchvision.models, model_name)(pretrained=True)
    model = model.eval()

    # We grab the TorchScripted model via tracing
    input_shape = [1, 3, 224, 224]
    input_data = torch.randn(input_shape)
    scripted_model = torch.jit.trace(model, input_data).eval()





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Downloading: "https://download.pytorch.org/models/resnet18-f37072fd.pth" to /workspace/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth
      0%|          | 0.00/44.7M [00:00<?, ?B/s]      0%|          | 40.0k/44.7M [00:00<02:43, 286kB/s]      0%|          | 96.0k/44.7M [00:00<02:03, 379kB/s]      0%|          | 208k/44.7M [00:00<01:11, 649kB/s]       1%|          | 352k/44.7M [00:00<00:50, 913kB/s]      1%|1         | 624k/44.7M [00:00<00:30, 1.50MB/s]      2%|2         | 1.03M/44.7M [00:00<00:18, 2.41MB/s]      4%|3         | 1.78M/44.7M [00:00<00:11, 4.08MB/s]      7%|6         | 3.02M/44.7M [00:00<00:06, 6.74MB/s]      9%|9         | 4.08M/44.7M [00:00<00:05, 8.04MB/s]     12%|#1        | 5.20M/44.7M [00:01<00:04, 9.11MB/s]     14%|#4        | 6.35M/44.7M [00:01<00:04, 10.0MB/s]     17%|#6        | 7.55M/44.7M [00:01<00:03, 10.8MB/s]     19%|#9        | 8.68M/44.7M [00:01<00:03, 11.0MB/s]     22%|##1       | 9.76M/44.7M [00:01<00:03, 11.1MB/s]     24%|##4       | 10.9M/44.7M [00:01<00:03, 11.3MB/s]     27%|##6       | 12.1M/44.7M [00:01<00:02, 11.5MB/s]     30%|##9       | 13.2M/44.7M [00:01<00:02, 11.5MB/s]     32%|###2      | 14.3M/44.7M [00:01<00:02, 11.6MB/s]     35%|###4      | 15.5M/44.7M [00:02<00:02, 11.7MB/s]     37%|###7      | 16.6M/44.7M [00:02<00:02, 11.8MB/s]     40%|###9      | 17.8M/44.7M [00:02<00:02, 11.8MB/s]     42%|####2     | 18.9M/44.7M [00:02<00:02, 11.8MB/s]     45%|####4     | 20.0M/44.7M [00:02<00:02, 11.8MB/s]     47%|####7     | 21.2M/44.7M [00:02<00:02, 11.9MB/s]     50%|####9     | 22.3M/44.7M [00:02<00:01, 11.9MB/s]     53%|#####2    | 23.5M/44.7M [00:02<00:01, 11.8MB/s]     55%|#####5    | 24.6M/44.7M [00:02<00:01, 11.7MB/s]     58%|#####7    | 25.8M/44.7M [00:02<00:01, 11.9MB/s]     60%|######    | 26.9M/44.7M [00:03<00:01, 11.9MB/s]     63%|######2   | 28.1M/44.7M [00:03<00:01, 11.9MB/s]     65%|######5   | 29.2M/44.7M [00:03<00:01, 11.8MB/s]     68%|######7   | 30.3M/44.7M [00:03<00:01, 11.8MB/s]     70%|#######   | 31.5M/44.7M [00:03<00:01, 11.9MB/s]     73%|#######3  | 32.6M/44.7M [00:03<00:01, 11.8MB/s]     76%|#######5  | 33.8M/44.7M [00:03<00:00, 11.8MB/s]     78%|#######8  | 34.9M/44.7M [00:03<00:00, 11.8MB/s]     81%|########  | 36.0M/44.7M [00:03<00:00, 11.9MB/s]     83%|########3 | 37.2M/44.7M [00:03<00:00, 11.8MB/s]     86%|########5 | 38.3M/44.7M [00:04<00:00, 11.8MB/s]     88%|########8 | 39.5M/44.7M [00:04<00:00, 11.7MB/s]     91%|#########1| 40.7M/44.7M [00:04<00:00, 12.0MB/s]     94%|#########3| 41.8M/44.7M [00:04<00:00, 11.9MB/s]     96%|#########6| 43.0M/44.7M [00:04<00:00, 11.8MB/s]     99%|#########8| 44.1M/44.7M [00:04<00:00, 11.8MB/s]    100%|##########| 44.7M/44.7M [00:04<00:00, 10.2MB/s]




.. GENERATED FROM PYTHON SOURCE LINES 74-77

Load a test image
-----------------
Classic cat example!

.. GENERATED FROM PYTHON SOURCE LINES 77-97

.. code-block:: default

    from PIL import Image

    img_url = "https://github.com/dmlc/mxnet.js/blob/main/data/cat.png?raw=true"
    img_path = download_testdata(img_url, "cat.png", module="data")
    img = Image.open(img_path).resize((224, 224))

    # Preprocess the image and convert to tensor
    from torchvision import transforms

    my_preprocess = transforms.Compose(
        [
            transforms.Resize(256),
            transforms.CenterCrop(224),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
        ]
    )
    img = my_preprocess(img)
    img = np.expand_dims(img, 0)








.. GENERATED FROM PYTHON SOURCE LINES 98-101

Import the graph to Relay
-------------------------
Convert PyTorch graph to Relay graph. The input name can be arbitrary.

.. GENERATED FROM PYTHON SOURCE LINES 101-105

.. code-block:: default

    input_name = "input0"
    shape_list = [(input_name, img.shape)]
    mod, params = relay.frontend.from_pytorch(scripted_model, shape_list)








.. GENERATED FROM PYTHON SOURCE LINES 106-109

Relay Build
-----------
Compile the graph to llvm target with given input specification.

.. GENERATED FROM PYTHON SOURCE LINES 109-114

.. code-block:: default

    target = tvm.target.Target("llvm", host="llvm")
    dev = tvm.cpu(0)
    with tvm.transform.PassContext(opt_level=3):
        lib = relay.build(mod, target=target, params=params)





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    /workspace/python/tvm/driver/build_module.py:267: UserWarning: target_host parameter is going to be deprecated. Please pass in tvm.target.Target(target, host=target_host) instead.
      "target_host parameter is going to be deprecated. "




.. GENERATED FROM PYTHON SOURCE LINES 115-118

Execute the portable graph on TVM
---------------------------------
Now we can try deploying the compiled model on target.

.. GENERATED FROM PYTHON SOURCE LINES 118-129

.. code-block:: default

    from tvm.contrib import graph_executor

    dtype = "float32"
    m = graph_executor.GraphModule(lib["default"](dev))
    # Set inputs
    m.set_input(input_name, tvm.nd.array(img.astype(dtype)))
    # Execute
    m.run()
    # Get outputs
    tvm_output = m.get_output(0)








.. GENERATED FROM PYTHON SOURCE LINES 130-133

Look up synset name
-------------------
Look up prediction top 1 index in 1000 class synset.

.. GENERATED FROM PYTHON SOURCE LINES 133-178

.. code-block:: default

    synset_url = "".join(
        [
            "https://raw.githubusercontent.com/Cadene/",
            "pretrained-models.pytorch/master/data/",
            "imagenet_synsets.txt",
        ]
    )
    synset_name = "imagenet_synsets.txt"
    synset_path = download_testdata(synset_url, synset_name, module="data")
    with open(synset_path) as f:
        synsets = f.readlines()

    synsets = [x.strip() for x in synsets]
    splits = [line.split(" ") for line in synsets]
    key_to_classname = {spl[0]: " ".join(spl[1:]) for spl in splits}

    class_url = "".join(
        [
            "https://raw.githubusercontent.com/Cadene/",
            "pretrained-models.pytorch/master/data/",
            "imagenet_classes.txt",
        ]
    )
    class_name = "imagenet_classes.txt"
    class_path = download_testdata(class_url, class_name, module="data")
    with open(class_path) as f:
        class_id_to_key = f.readlines()

    class_id_to_key = [x.strip() for x in class_id_to_key]

    # Get top-1 result for TVM
    top1_tvm = np.argmax(tvm_output.numpy()[0])
    tvm_class_key = class_id_to_key[top1_tvm]

    # Convert input to PyTorch variable and get PyTorch result for comparison
    with torch.no_grad():
        torch_img = torch.from_numpy(img)
        output = model(torch_img)

        # Get top-1 result for PyTorch
        top1_torch = np.argmax(output.numpy())
        torch_class_key = class_id_to_key[top1_torch]

    print("Relay top-1 id: {}, class name: {}".format(top1_tvm, key_to_classname[tvm_class_key]))
    print("Torch top-1 id: {}, class name: {}".format(top1_torch, key_to_classname[torch_class_key]))




.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Relay top-1 id: 281, class name: tabby, tabby cat
    Torch top-1 id: 281, class name: tabby, tabby cat





.. _sphx_glr_download_how_to_compile_models_from_pytorch.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example


    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: from_pytorch.py <from_pytorch.py>`

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: from_pytorch.ipynb <from_pytorch.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
