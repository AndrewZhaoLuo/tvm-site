





<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8">
  <meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Auto-scheduling a Convolution Layer for GPU &mdash; tvm 0.8.dev0 documentation</title>
  

  
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/css/bootstrap.min.css" integrity="sha384-Gn5384xqQ1aoWXA+058RXPxPg6fy4IWvTNh0E263XmFcJlSAwiGgFAW/dAiS6JXm" crossorigin="anonymous">
  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/gallery.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/css/tlcpack_theme.css" type="text/css" />

  
  
    <link rel="shortcut icon" href="../../_static/tvm-logo-square.png"/>
  

  
  
  
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
        <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
        <script src="../../_static/jquery.js"></script>
        <script src="../../_static/underscore.js"></script>
        <script src="../../_static/doctools.js"></script>
    
    <script type="text/javascript" src="../../_static/js/theme.js"></script>

    
    <script type="text/javascript" src="../../_static/js/tlcpack_theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Auto-scheduling a Neural Network for x86 CPU" href="tune_network_x86.html" />
    <link rel="prev" title="Auto-tuning a Convolutional Network for Mobile GPU" href="../autotvm/tune_relay_mobile_gpu.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    
<header class="header">
    <div class="innercontainer">
      <div class="headerInner d-flex justify-content-between align-items-center">
          <div class="headerLogo">
               <a href="https://tvm.apache.org/"><img src=https://tvm.apache.org/assets/images/logo.svg alt="logo"></a>
          </div>

          <div id="headMenu" class="headerNav">
            <button type="button" id="closeHeadMenu" class="navCloseBtn"><img src="../../_static/img/close-icon.svg" alt="Close"></button>
             <ul class="nav">
                <li class="nav-item">
                   <a class="nav-link" href=https://tvm.apache.org/community>Community</a>
                </li>
                <li class="nav-item">
                   <a class="nav-link" href=https://tvm.apache.org/download>Download</a>
                </li>
                <li class="nav-item">
                   <a class="nav-link" href=https://tvm.apache.org/vta>VTA</a>
                </li>
                <li class="nav-item">
                   <a class="nav-link" href=https://tvm.apache.org/blog>Blog</a>
                </li>
                <li class="nav-item">
                   <a class="nav-link" href=https://tvm.apache.org/docs>Docs</a>
                </li>
                <li class="nav-item">
                   <a class="nav-link" href=https://tvmconf.org>Conference</a>
                </li>
                <li class="nav-item">
                   <a class="nav-link" href=https://github.com/apache/tvm/>Github</a>
                </li>
             </ul>
               <div class="responsivetlcdropdown">
                 <button type="button" class="btn-link">
                   ASF
                 </button>
                 <ul>
                     <li>
                       <a href=https://apache.org/>Apache Homepage</a>
                     </li>
                     <li>
                       <a href=https://www.apache.org/licenses/>License</a>
                     </li>
                     <li>
                       <a href=https://www.apache.org/foundation/sponsorship.html>Sponsorship</a>
                     </li>
                     <li>
                       <a href=https://www.apache.org/security/>Security</a>
                     </li>
                     <li>
                       <a href=https://www.apache.org/foundation/thanks.html>Thanks</a>
                     </li>
                     <li>
                       <a href=https://www.apache.org/events/current-event>Events</a>
                     </li>
                 </ul>
               </div>
          </div>
            <div class="responsiveMenuIcon">
              <button type="button" id="menuBtn" class="btn-menu"><img src="../../_static/img/menu-icon.svg" alt="Menu Icon"></button>
            </div>

            <div class="tlcDropdown">
              <div class="dropdown">
                <button type="button" class="btn-link dropdown-toggle" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                  ASF
                </button>
                <div class="dropdown-menu dropdown-menu-right">
                  <ul>
                     <li>
                       <a href=https://apache.org/>Apache Homepage</a>
                     </li>
                     <li>
                       <a href=https://www.apache.org/licenses/>License</a>
                     </li>
                     <li>
                       <a href=https://www.apache.org/foundation/sponsorship.html>Sponsorship</a>
                     </li>
                     <li>
                       <a href=https://www.apache.org/security/>Security</a>
                     </li>
                     <li>
                       <a href=https://www.apache.org/foundation/thanks.html>Thanks</a>
                     </li>
                     <li>
                       <a href=https://www.apache.org/events/current-event>Events</a>
                     </li>
                  </ul>
                </div>
              </div>
          </div>
       </div>
    </div>
 </header>
 
    <nav data-toggle="wy-nav-shift" class="wy-nav-side fixed">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../../index.html">
          

          
            
            <img src="../../_static/tvm-logo-small.png" class="logo" alt="Logo"/>
          
          </a>

          
            
            
                <div class="version">
                  0.8.dev0
                </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">How to</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../install/index.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../contribute/index.html">Contribute to TVM</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../deploy/index.html">Deploy and Integration</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../dev/how_to.html">Developer How-To Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../errors.html">What do to when encountering TVM Errors</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../faq.html">Frequently Asked Questions</a></li>
</ul>
<p class="caption"><span class="caption-text">Tutorials</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../index.html">Getting Started With TVM</a></li>
<li class="toctree-l1"><a class="reference internal" href="../index.html#compile-deep-learning-models">Compile Deep Learning Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../index.html#tensor-expression-and-schedules">Tensor Expression and Schedules</a></li>
<li class="toctree-l1"><a class="reference internal" href="../index.html#optimize-tensor-operators">Optimize Tensor Operators</a></li>
<li class="toctree-l1"><a class="reference internal" href="../index.html#autotvm-template-based-auto-tuning">AutoTVM : Template-based Auto Tuning</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../index.html#autoscheduler-template-free-auto-scheduling">AutoScheduler : Template-free Auto Scheduling</a><ul class="current">
<li class="toctree-l2 current"><a class="current reference internal" href="#">Auto-scheduling a Convolution Layer for GPU</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#define-the-computation">Define the computation</a></li>
<li class="toctree-l3"><a class="reference internal" href="#create-the-search-task">Create the search task</a></li>
<li class="toctree-l3"><a class="reference internal" href="#run-the-search">Run the search</a></li>
<li class="toctree-l3"><a class="reference internal" href="#check-correctness-and-evaluate-performance">Check correctness and evaluate performance</a></li>
<li class="toctree-l3"><a class="reference internal" href="#using-the-record-file">Using the record file</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="tune_network_x86.html">Auto-scheduling a Neural Network for x86 CPU</a></li>
<li class="toctree-l2"><a class="reference internal" href="tune_network_cuda.html">Auto-scheduling a Neural Network for NVIDIA GPU</a></li>
<li class="toctree-l2"><a class="reference internal" href="tune_network_arm.html">Auto-scheduling a Neural Network for ARM CPU</a></li>
<li class="toctree-l2"><a class="reference internal" href="tune_network_mali.html">Auto-scheduling a Neural Network for mali GPU</a></li>
<li class="toctree-l2"><a class="reference internal" href="tune_sparse_x86.html">Auto-scheduling Sparse Matrix Multiplication on CPU with Custom Sketch Rule</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../index.html#developer-tutorials">Developer Tutorials</a></li>
<li class="toctree-l1"><a class="reference internal" href="../index.html#topi-tvm-operator-inventory">TOPI: TVM Operator Inventory</a></li>
<li class="toctree-l1"><a class="reference internal" href="../index.html#microtvm">microTVM</a></li>
</ul>
<p class="caption"><span class="caption-text">References</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../langref/index.html">Language Reference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api/python/index.html">Python API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api/links.html">Links to Other API References</a></li>
</ul>
<p class="caption"><span class="caption-text">Deep Dive</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../dev/index.html">Design and Architecture</a></li>
</ul>
<p class="caption"><span class="caption-text">MISC</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../microtvm/index.html">microTVM: TVM on bare-metal</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../vta/index.html">VTA: Deep Learning Accelerator Stack</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../genindex.html">Index</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">
      
      <nav class="wy-nav-top" aria-label="top navigation" data-toggle="wy-nav-top">
        
            <div class="togglemenu">

            </div>
            <div class="nav-content">
              <!-- tvm -->
              Table of content
            </div>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        

          




















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../index.html">Docs</a> <span class="br-arrow">></span></li>
        
          <li><a href="../index.html">Getting Started With TVM</a> <span class="br-arrow">></span></li>
        
      <li>Auto-scheduling a Convolution Layer for GPU</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../../_sources/tutorials/auto_scheduler/tune_conv2d_layer_cuda.rst.txt" rel="nofollow"> <img src="../../_static//img/source.svg" alt="viewsource"/></a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">Note</p>
<p>Click <a class="reference internal" href="#sphx-glr-download-tutorials-auto-scheduler-tune-conv2d-layer-cuda-py"><span class="std std-ref">here</span></a> to download the full example code</p>
</div>
<section class="sphx-glr-example-title" id="auto-scheduling-a-convolution-layer-for-gpu">
<span id="auto-scheduler-conv-gpu"></span><span id="sphx-glr-tutorials-auto-scheduler-tune-conv2d-layer-cuda-py"></span><h1>Auto-scheduling a Convolution Layer for GPU<a class="headerlink" href="#auto-scheduling-a-convolution-layer-for-gpu" title="Permalink to this headline">¶</a></h1>
<p><strong>Author</strong>: <a class="reference external" href="https://github.com/merrymercy">Lianmin Zheng</a>,             <a class="reference external" href="https://github.com/jcf94/">Chengfan Jia</a></p>
<p>This is a tutorial on how to use the auto-scheduler for GPUs.</p>
<p>Different from the template-based <a class="reference internal" href="../index.html#tutorials-autotvm-sec"><span class="std std-ref">autotvm</span></a> which relies on
manual templates to define the search space, the auto-scheduler does not require any templates.
Users only need to write the computation declaration without any schedule commands or templates.
The auto-scheduler can automatically generate a large search space and
find a good schedule in the space.</p>
<p>We use a convolution layer as an example in this tutorial.</p>
<p>Note that this tutorial will not run on Windows or recent versions of macOS. To
get it to run, you will need to wrap the body of this tutorial in a <code class="code docutils literal notranslate"><span class="pre">if</span>
<span class="pre">__name__</span> <span class="pre">==</span> <span class="pre">&quot;__main__&quot;:</span></code> block.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">tvm</span>
<span class="kn">from</span> <span class="nn">tvm</span> <span class="k">import</span> <span class="n">te</span><span class="p">,</span> <span class="n">auto_scheduler</span><span class="p">,</span> <span class="n">topi</span>
<span class="kn">from</span> <span class="nn">tvm.topi.testing</span> <span class="k">import</span> <span class="n">conv2d_nchw_python</span>
</pre></div>
</div>
<section id="define-the-computation">
<h2>Define the computation<a class="headerlink" href="#define-the-computation" title="Permalink to this headline">¶</a></h2>
<p>To begin with, let us define the computation of a convolution layer.
The function should return the list of input/output tensors.
From these tensors, the auto-scheduler can get the whole computational graph.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nd">@auto_scheduler</span><span class="o">.</span><span class="n">register_workload</span>
<span class="k">def</span> <span class="nf">conv2d_layer</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">H</span><span class="p">,</span> <span class="n">W</span><span class="p">,</span> <span class="n">CO</span><span class="p">,</span> <span class="n">CI</span><span class="p">,</span> <span class="n">KH</span><span class="p">,</span> <span class="n">KW</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="p">):</span>
    <span class="n">data</span> <span class="o">=</span> <a href="../../api/python/te.html#tvm.te.placeholder" title="View documentation for tvm.te.placeholder"><span class="n">te</span><span class="o">.</span><span class="n">placeholder</span></a><span class="p">((</span><span class="n">N</span><span class="p">,</span> <span class="n">CI</span><span class="p">,</span> <span class="n">H</span><span class="p">,</span> <span class="n">W</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;data&quot;</span><span class="p">)</span>
    <span class="n">kernel</span> <span class="o">=</span> <a href="../../api/python/te.html#tvm.te.placeholder" title="View documentation for tvm.te.placeholder"><span class="n">te</span><span class="o">.</span><span class="n">placeholder</span></a><span class="p">((</span><span class="n">CO</span><span class="p">,</span> <span class="n">CI</span><span class="p">,</span> <span class="n">KH</span><span class="p">,</span> <span class="n">KW</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;kernel&quot;</span><span class="p">)</span>
    <span class="n">bias</span> <span class="o">=</span> <a href="../../api/python/te.html#tvm.te.placeholder" title="View documentation for tvm.te.placeholder"><span class="n">te</span><span class="o">.</span><span class="n">placeholder</span></a><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="n">CO</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;bias&quot;</span><span class="p">)</span>
    <span class="n">conv</span> <span class="o">=</span> <a href="../../api/python/topi.html#tvm.topi.nn.conv2d_nchw" title="View documentation for tvm.topi.nn.conv2d_nchw"><span class="n">topi</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">conv2d_nchw</span></a><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">kernel</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">dilation</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">out_dtype</span><span class="o">=</span><span class="s2">&quot;float32&quot;</span><span class="p">)</span>
    <span class="n">out</span> <span class="o">=</span> <a href="../../api/python/topi.html#tvm.topi.nn.relu" title="View documentation for tvm.topi.nn.relu"><span class="n">topi</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">relu</span></a><span class="p">(</span><span class="n">conv</span> <span class="o">+</span> <span class="n">bias</span><span class="p">)</span>
    <span class="k">return</span> <span class="p">[</span><span class="n">data</span><span class="p">,</span> <span class="n">kernel</span><span class="p">,</span> <span class="n">bias</span><span class="p">,</span> <span class="n">out</span><span class="p">]</span>
</pre></div>
</div>
</section>
<section id="create-the-search-task">
<h2>Create the search task<a class="headerlink" href="#create-the-search-task" title="Permalink to this headline">¶</a></h2>
<p>We then create a search task for the last convolution layer in the resnet.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">target</span> <span class="o">=</span> <a href="../../api/python/target.html#tvm.target.Target" title="View documentation for tvm.target.Target"><span class="n">tvm</span><span class="o">.</span><span class="n">target</span><span class="o">.</span><span class="n">Target</span></a><span class="p">(</span><span class="s2">&quot;cuda&quot;</span><span class="p">)</span>

<span class="c1"># Use the last layer in ResNet-50</span>
<span class="n">N</span><span class="p">,</span> <span class="n">H</span><span class="p">,</span> <span class="n">W</span><span class="p">,</span> <span class="n">CO</span><span class="p">,</span> <span class="n">CI</span><span class="p">,</span> <span class="n">KH</span><span class="p">,</span> <span class="n">KW</span><span class="p">,</span> <span class="n">strides</span><span class="p">,</span> <span class="n">padding</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">512</span><span class="p">,</span> <span class="mi">512</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">task</span> <span class="o">=</span> <a href="../../api/python/auto_scheduler.html#tvm.auto_scheduler.SearchTask" title="View documentation for tvm.auto_scheduler.SearchTask"><span class="n">auto_scheduler</span><span class="o">.</span><span class="n">SearchTask</span></a><span class="p">(</span>
    <span class="n">func</span><span class="o">=</span><span class="n">conv2d_layer</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">H</span><span class="p">,</span> <span class="n">W</span><span class="p">,</span> <span class="n">CO</span><span class="p">,</span> <span class="n">CI</span><span class="p">,</span> <span class="n">KH</span><span class="p">,</span> <span class="n">KW</span><span class="p">,</span> <span class="n">strides</span><span class="p">,</span> <span class="n">padding</span><span class="p">),</span> <span class="n">target</span><span class="o">=</span><span class="n">target</span>
<span class="p">)</span>

<span class="c1"># Inspect the computational graph</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Computational DAG:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">task</span><span class="o">.</span><span class="n">compute_dag</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Computational DAG:
data = PLACEHOLDER [1, 512, 7, 7]
pad_temp(i0, i1, i2, i3) = tir.if_then_else(((((i2 &gt;= 1) &amp;&amp; (i2 &lt; 8)) &amp;&amp; (i3 &gt;= 1)) &amp;&amp; (i3 &lt; 8)), data[i0, i1, (i2 - 1), (i3 - 1)], 0f)
kernel = PLACEHOLDER [512, 512, 3, 3]
compute(nn, ff, yy, xx) += (pad_temp[nn, rc, (yy + ry), (xx + rx)]*kernel[ff, rc, ry, rx])
bias = PLACEHOLDER [1, 512, 1, 1]
T_add(ax0, ax1, ax2, ax3) = (compute[ax0, ax1, ax2, ax3] + bias[ax0, ax1, 0, 0])
compute(i0, i1, i2, i3) = max(T_add[i0, i1, i2, i3], 0f)
</pre></div>
</div>
<p>Next, we set parameters for the auto-scheduler. These parameters
mainly specify how we do the measurement during the search.</p>
<ul class="simple">
<li><p><code class="code docutils literal notranslate"><span class="pre">measure_ctx</span></code> launches a different process for measurement to
provide isolation. It can protect the master process from GPU crashes
during measurement and avoid other runtime conflicts.</p></li>
<li><p><code class="code docutils literal notranslate"><span class="pre">min_repeat_ms</span></code> defines the minimum duration of one “repeat” in every measurement.
This can warmup the GPU, which is necessary to get accurate measurement results.
Typically, we recommend a value &gt;= 300 ms.</p></li>
<li><p><code class="code docutils literal notranslate"><span class="pre">num_measure_trials</span></code> is the number of measurement trials we can use during the search.
We only make 10 trials in this tutorial for a fast demonstration. In practice, 1000 is a
good value for the search to converge. You can do more trials according to your time budget.</p></li>
<li><p>In addition, we use <code class="code docutils literal notranslate"><span class="pre">RecordToFile</span></code> to dump measurement records into a file <cite>conv2d.json</cite>.
The measurement records can be used to query the history best, resume the search,
and do more analyses later.</p></li>
<li><p>see <a class="reference internal" href="../../api/python/auto_scheduler.html#tvm.auto_scheduler.TuningOptions" title="tvm.auto_scheduler.TuningOptions"><code class="xref any py py-class docutils literal notranslate"><span class="pre">auto_scheduler.TuningOptions</span></code></a>,
<a class="reference internal" href="../../api/python/auto_scheduler.html#tvm.auto_scheduler.LocalRPCMeasureContext" title="tvm.auto_scheduler.LocalRPCMeasureContext"><code class="xref any py py-class docutils literal notranslate"><span class="pre">auto_scheduler.LocalRPCMeasureContext</span></code></a> for more parameters.</p></li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">log_file</span> <span class="o">=</span> <span class="s2">&quot;conv2d.json&quot;</span>
<span class="n">measure_ctx</span> <span class="o">=</span> <a href="../../api/python/auto_scheduler.html#tvm.auto_scheduler.LocalRPCMeasureContext" title="View documentation for tvm.auto_scheduler.LocalRPCMeasureContext"><span class="n">auto_scheduler</span><span class="o">.</span><span class="n">LocalRPCMeasureContext</span></a><span class="p">(</span><span class="n">min_repeat_ms</span><span class="o">=</span><span class="mi">300</span><span class="p">)</span>
<span class="n">tune_option</span> <span class="o">=</span> <a href="../../api/python/auto_scheduler.html#tvm.auto_scheduler.TuningOptions" title="View documentation for tvm.auto_scheduler.TuningOptions"><span class="n">auto_scheduler</span><span class="o">.</span><span class="n">TuningOptions</span></a><span class="p">(</span>
    <span class="n">num_measure_trials</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>  <span class="c1"># change this to 1000 to achieve the best performance</span>
    <span class="n">runner</span><span class="o">=</span><span class="n">measure_ctx</span><span class="o">.</span><span class="n">runner</span><span class="p">,</span>
    <span class="n">measure_callbacks</span><span class="o">=</span><span class="p">[</span><a href="../../api/python/auto_scheduler.html#tvm.auto_scheduler.RecordToFile" title="View documentation for tvm.auto_scheduler.RecordToFile"><span class="n">auto_scheduler</span><span class="o">.</span><span class="n">RecordToFile</span></a><span class="p">(</span><span class="n">log_file</span><span class="p">)],</span>
    <span class="n">verbose</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Get devices for measurement successfully!
</pre></div>
</div>
</section>
<section id="run-the-search">
<h2>Run the search<a class="headerlink" href="#run-the-search" title="Permalink to this headline">¶</a></h2>
<p>Now we get all inputs ready. Pretty simple, isn’t it?
We can kick off the search and let the auto-scheduler do its magic.
After some measurement trials, we can load the best schedule from the log
file and apply it.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Run auto-tuning (search)</span>
<span class="n">task</span><span class="o">.</span><span class="n">tune</span><span class="p">(</span><span class="n">tune_option</span><span class="p">)</span>
<span class="c1"># Apply the best schedule</span>
<span class="n">sch</span><span class="p">,</span> <span class="n">args</span> <span class="o">=</span> <span class="n">task</span><span class="o">.</span><span class="n">apply_best</span><span class="p">(</span><span class="n">log_file</span><span class="p">)</span>

<span class="c1"># Kill the measurement process</span>
<span class="k">del</span> <span class="n">measure_ctx</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>
</pre></div>
</div>
<p>We can lower the schedule to see the IR after auto-scheduling.
The auto-scheduler correctly performs optimizations including multi-level tiling,
cooperative fetching, unrolling and operator fusion.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Lowered TIR:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><a href="../../api/python/driver.html#tvm.lower" title="View documentation for tvm.lower"><span class="n">tvm</span><span class="o">.</span><span class="n">lower</span></a><span class="p">(</span><span class="n">sch</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="n">simple_mode</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Lowered TIR:
primfn(data_1: handle, kernel_1: handle, bias_1: handle, compute_1: handle) -&gt; ()
  attr = {&quot;global_symbol&quot;: &quot;main&quot;, &quot;tir.noalias&quot;: True}
  buffers = {compute: Buffer(compute_2: Pointer(float32), float32, [1, 512, 7, 7], []),
             data: Buffer(data_2: Pointer(float32), float32, [1, 512, 7, 7], []),
             bias: Buffer(bias_2: Pointer(float32), float32, [1, 512, 1, 1], []),
             kernel: Buffer(kernel_2: Pointer(float32), float32, [512, 512, 3, 3], [])}
  buffer_map = {data_1: data, kernel_1: kernel, bias_1: bias, compute_1: compute} {
  attr [IterVar(blockIdx.x: int32, (nullptr), &quot;ThreadIndex&quot;, &quot;blockIdx.x&quot;)] &quot;thread_extent&quot; = 64;
  attr [compute_3: Pointer(float32)] &quot;storage_scope&quot; = &quot;local&quot;;
  allocate(compute_3, float32, [7]);
  attr [pad_temp.shared: Pointer(float32)] &quot;storage_scope&quot; = &quot;shared&quot;;
  allocate(pad_temp.shared, float32, [1008]);
  attr [kernel.shared: Pointer(float32)] &quot;storage_scope&quot; = &quot;shared&quot;;
  allocate(kernel.shared, float32, [384]);
  attr [IterVar(threadIdx.x: int32, (nullptr), &quot;ThreadIndex&quot;, &quot;threadIdx.x&quot;)] &quot;thread_extent&quot; = 56 {
    compute_3[0] = 0f32
    compute_3[1] = 0f32
    compute_3[2] = 0f32
    compute_3[3] = 0f32
    compute_3[4] = 0f32
    compute_3[5] = 0f32
    compute_3[6] = 0f32
    for (rc.outer.outer: int32, 0, 32) {
      for (rx.outer.outer: int32, 0, 3) {
        attr [IterVar(threadIdx.x_1: int32, (nullptr), &quot;ThreadIndex&quot;, &quot;threadIdx.x&quot;)] &quot;thread_extent&quot; = 56;
        pad_temp.shared[threadIdx.x_1] = @tir.if_then_else((((7 &lt;= threadIdx.x_1) &amp;&amp; (1 &lt;= (rx.outer.outer + floormod(threadIdx.x_1, 7)))) &amp;&amp; ((rx.outer.outer + floormod(threadIdx.x_1, 7)) &lt; 8)), (float32*)data_2[((((rc.outer.outer*784) + threadIdx.x_1) + rx.outer.outer) - 8)], 0f32, dtype=float32)
        attr [IterVar(threadIdx.x_1, (nullptr), &quot;ThreadIndex&quot;, &quot;threadIdx.x&quot;)] &quot;thread_extent&quot; = 56;
        pad_temp.shared[(threadIdx.x_1 + 56)] = @tir.if_then_else(((((1 &lt;= floormod((floordiv(threadIdx.x_1, 7) + 8), 9)) &amp;&amp; (floormod((floordiv(threadIdx.x_1, 7) + 8), 9) &lt; 8)) &amp;&amp; (1 &lt;= (rx.outer.outer + floormod(threadIdx.x_1, 7)))) &amp;&amp; ((rx.outer.outer + floormod(threadIdx.x_1, 7)) &lt; 8)), (float32*)data_2[((((((rc.outer.outer*784) + (floordiv((floordiv(threadIdx.x_1, 7) + 8), 9)*49)) + (floormod((floordiv(threadIdx.x_1, 7) + 8), 9)*7)) + rx.outer.outer) + floormod(threadIdx.x_1, 7)) - 8)], 0f32, dtype=float32)
        attr [IterVar(threadIdx.x_1, (nullptr), &quot;ThreadIndex&quot;, &quot;threadIdx.x&quot;)] &quot;thread_extent&quot; = 56;
        pad_temp.shared[(threadIdx.x_1 + 112)] = @tir.if_then_else(((((1 &lt;= floormod((floordiv(threadIdx.x_1, 7) + 7), 9)) &amp;&amp; (floormod((floordiv(threadIdx.x_1, 7) + 7), 9) &lt; 8)) &amp;&amp; (1 &lt;= (rx.outer.outer + floormod(threadIdx.x_1, 7)))) &amp;&amp; ((rx.outer.outer + floormod(threadIdx.x_1, 7)) &lt; 8)), (float32*)data_2[((((((rc.outer.outer*784) + (floordiv((floordiv(threadIdx.x_1, 7) + 16), 9)*49)) + (floormod((floordiv(threadIdx.x_1, 7) + 7), 9)*7)) + rx.outer.outer) + floormod(threadIdx.x_1, 7)) - 8)], 0f32, dtype=float32)
        attr [IterVar(threadIdx.x_1, (nullptr), &quot;ThreadIndex&quot;, &quot;threadIdx.x&quot;)] &quot;thread_extent&quot; = 56;
        pad_temp.shared[(threadIdx.x_1 + 168)] = @tir.if_then_else(((((1 &lt;= floormod((floordiv(threadIdx.x_1, 7) + 6), 9)) &amp;&amp; (floormod((floordiv(threadIdx.x_1, 7) + 6), 9) &lt; 8)) &amp;&amp; (1 &lt;= (rx.outer.outer + floormod(threadIdx.x_1, 7)))) &amp;&amp; ((rx.outer.outer + floormod(threadIdx.x_1, 7)) &lt; 8)), (float32*)data_2[((((((rc.outer.outer*784) + (floordiv((floordiv(threadIdx.x_1, 7) + 24), 9)*49)) + (floormod((floordiv(threadIdx.x_1, 7) + 6), 9)*7)) + rx.outer.outer) + floormod(threadIdx.x_1, 7)) - 8)], 0f32, dtype=float32)
        attr [IterVar(threadIdx.x_1, (nullptr), &quot;ThreadIndex&quot;, &quot;threadIdx.x&quot;)] &quot;thread_extent&quot; = 56;
        pad_temp.shared[(threadIdx.x_1 + 224)] = @tir.if_then_else(((((1 &lt;= floormod((floordiv(threadIdx.x_1, 7) + 5), 9)) &amp;&amp; (floormod((floordiv(threadIdx.x_1, 7) + 5), 9) &lt; 8)) &amp;&amp; (1 &lt;= (rx.outer.outer + floormod(threadIdx.x_1, 7)))) &amp;&amp; ((rx.outer.outer + floormod(threadIdx.x_1, 7)) &lt; 8)), (float32*)data_2[((((((rc.outer.outer*784) + (floordiv((floordiv(threadIdx.x_1, 7) + 32), 9)*49)) + (floormod((floordiv(threadIdx.x_1, 7) + 5), 9)*7)) + rx.outer.outer) + floormod(threadIdx.x_1, 7)) - 8)], 0f32, dtype=float32)
        attr [IterVar(threadIdx.x_1, (nullptr), &quot;ThreadIndex&quot;, &quot;threadIdx.x&quot;)] &quot;thread_extent&quot; = 56;
        pad_temp.shared[(threadIdx.x_1 + 280)] = @tir.if_then_else(((((1 &lt;= floormod((floordiv(threadIdx.x_1, 7) + 4), 9)) &amp;&amp; (floormod((floordiv(threadIdx.x_1, 7) + 4), 9) &lt; 8)) &amp;&amp; (1 &lt;= (rx.outer.outer + floormod(threadIdx.x_1, 7)))) &amp;&amp; ((rx.outer.outer + floormod(threadIdx.x_1, 7)) &lt; 8)), (float32*)data_2[((((((rc.outer.outer*784) + (floordiv((floordiv(threadIdx.x_1, 7) + 40), 9)*49)) + (floormod((floordiv(threadIdx.x_1, 7) + 4), 9)*7)) + rx.outer.outer) + floormod(threadIdx.x_1, 7)) - 8)], 0f32, dtype=float32)
        attr [IterVar(threadIdx.x_1, (nullptr), &quot;ThreadIndex&quot;, &quot;threadIdx.x&quot;)] &quot;thread_extent&quot; = 56;
        pad_temp.shared[(threadIdx.x_1 + 336)] = @tir.if_then_else(((((1 &lt;= floormod((floordiv(threadIdx.x_1, 7) + 3), 9)) &amp;&amp; (floormod((floordiv(threadIdx.x_1, 7) + 3), 9) &lt; 8)) &amp;&amp; (1 &lt;= (rx.outer.outer + floormod(threadIdx.x_1, 7)))) &amp;&amp; ((rx.outer.outer + floormod(threadIdx.x_1, 7)) &lt; 8)), (float32*)data_2[((((((rc.outer.outer*784) + (floordiv((floordiv(threadIdx.x_1, 7) + 48), 9)*49)) + (floormod((floordiv(threadIdx.x_1, 7) + 3), 9)*7)) + rx.outer.outer) + floormod(threadIdx.x_1, 7)) - 8)], 0f32, dtype=float32)
        attr [IterVar(threadIdx.x_1, (nullptr), &quot;ThreadIndex&quot;, &quot;threadIdx.x&quot;)] &quot;thread_extent&quot; = 56;
        pad_temp.shared[(threadIdx.x_1 + 392)] = @tir.if_then_else(((((1 &lt;= floormod((floordiv(threadIdx.x_1, 7) + 2), 9)) &amp;&amp; (floormod((floordiv(threadIdx.x_1, 7) + 2), 9) &lt; 8)) &amp;&amp; (1 &lt;= (rx.outer.outer + floormod(threadIdx.x_1, 7)))) &amp;&amp; ((rx.outer.outer + floormod(threadIdx.x_1, 7)) &lt; 8)), (float32*)data_2[((((((rc.outer.outer*784) + (floordiv((floordiv(threadIdx.x_1, 7) + 56), 9)*49)) + (floormod((floordiv(threadIdx.x_1, 7) + 2), 9)*7)) + rx.outer.outer) + floormod(threadIdx.x_1, 7)) - 8)], 0f32, dtype=float32)
        attr [IterVar(threadIdx.x_1, (nullptr), &quot;ThreadIndex&quot;, &quot;threadIdx.x&quot;)] &quot;thread_extent&quot; = 56;
        pad_temp.shared[(threadIdx.x_1 + 448)] = @tir.if_then_else((((floormod((floordiv(threadIdx.x_1, 7) + 1), 9) &lt; 8) &amp;&amp; (1 &lt;= (rx.outer.outer + floormod(threadIdx.x_1, 7)))) &amp;&amp; ((rx.outer.outer + floormod(threadIdx.x_1, 7)) &lt; 8)), (float32*)data_2[((((((rc.outer.outer*784) + (floordiv((floordiv(threadIdx.x_1, 7) + 64), 9)*49)) + (floormod((floordiv(threadIdx.x_1, 7) + 1), 9)*7)) + rx.outer.outer) + floormod(threadIdx.x_1, 7)) - 8)], 0f32, dtype=float32)
        attr [IterVar(threadIdx.x_1, (nullptr), &quot;ThreadIndex&quot;, &quot;threadIdx.x&quot;)] &quot;thread_extent&quot; = 56;
        pad_temp.shared[(threadIdx.x_1 + 504)] = @tir.if_then_else((((7 &lt;= threadIdx.x_1) &amp;&amp; (1 &lt;= (rx.outer.outer + floormod(threadIdx.x_1, 7)))) &amp;&amp; ((rx.outer.outer + floormod(threadIdx.x_1, 7)) &lt; 8)), (float32*)data_2[(((((rc.outer.outer*784) + (floordiv(threadIdx.x_1, 7)*7)) + rx.outer.outer) + floormod(threadIdx.x_1, 7)) + 384)], 0f32, dtype=float32)
        attr [IterVar(threadIdx.x_1, (nullptr), &quot;ThreadIndex&quot;, &quot;threadIdx.x&quot;)] &quot;thread_extent&quot; = 56;
        pad_temp.shared[(threadIdx.x_1 + 560)] = @tir.if_then_else(((((1 &lt;= floormod((floordiv(threadIdx.x_1, 7) + 8), 9)) &amp;&amp; (floormod((floordiv(threadIdx.x_1, 7) + 8), 9) &lt; 8)) &amp;&amp; (1 &lt;= (rx.outer.outer + floormod(threadIdx.x_1, 7)))) &amp;&amp; ((rx.outer.outer + floormod(threadIdx.x_1, 7)) &lt; 8)), (float32*)data_2[((((((rc.outer.outer*784) + (floordiv((floordiv(threadIdx.x_1, 7) + 80), 9)*49)) + (floormod((floordiv(threadIdx.x_1, 7) + 8), 9)*7)) + rx.outer.outer) + floormod(threadIdx.x_1, 7)) - 8)], 0f32, dtype=float32)
        attr [IterVar(threadIdx.x_1, (nullptr), &quot;ThreadIndex&quot;, &quot;threadIdx.x&quot;)] &quot;thread_extent&quot; = 56;
        pad_temp.shared[(threadIdx.x_1 + 616)] = @tir.if_then_else(((((1 &lt;= floormod((floordiv(threadIdx.x_1, 7) + 7), 9)) &amp;&amp; (floormod((floordiv(threadIdx.x_1, 7) + 7), 9) &lt; 8)) &amp;&amp; (1 &lt;= (rx.outer.outer + floormod(threadIdx.x_1, 7)))) &amp;&amp; ((rx.outer.outer + floormod(threadIdx.x_1, 7)) &lt; 8)), (float32*)data_2[((((((rc.outer.outer*784) + (floordiv((floordiv(threadIdx.x_1, 7) + 88), 9)*49)) + (floormod((floordiv(threadIdx.x_1, 7) + 7), 9)*7)) + rx.outer.outer) + floormod(threadIdx.x_1, 7)) - 8)], 0f32, dtype=float32)
        attr [IterVar(threadIdx.x_1, (nullptr), &quot;ThreadIndex&quot;, &quot;threadIdx.x&quot;)] &quot;thread_extent&quot; = 56;
        pad_temp.shared[(threadIdx.x_1 + 672)] = @tir.if_then_else(((((1 &lt;= floormod((floordiv(threadIdx.x_1, 7) + 6), 9)) &amp;&amp; (floormod((floordiv(threadIdx.x_1, 7) + 6), 9) &lt; 8)) &amp;&amp; (1 &lt;= (rx.outer.outer + floormod(threadIdx.x_1, 7)))) &amp;&amp; ((rx.outer.outer + floormod(threadIdx.x_1, 7)) &lt; 8)), (float32*)data_2[((((((rc.outer.outer*784) + (floordiv((floordiv(threadIdx.x_1, 7) + 96), 9)*49)) + (floormod((floordiv(threadIdx.x_1, 7) + 6), 9)*7)) + rx.outer.outer) + floormod(threadIdx.x_1, 7)) - 8)], 0f32, dtype=float32)
        attr [IterVar(threadIdx.x_1, (nullptr), &quot;ThreadIndex&quot;, &quot;threadIdx.x&quot;)] &quot;thread_extent&quot; = 56;
        pad_temp.shared[(threadIdx.x_1 + 728)] = @tir.if_then_else(((((1 &lt;= floormod((floordiv(threadIdx.x_1, 7) + 5), 9)) &amp;&amp; (floormod((floordiv(threadIdx.x_1, 7) + 5), 9) &lt; 8)) &amp;&amp; (1 &lt;= (rx.outer.outer + floormod(threadIdx.x_1, 7)))) &amp;&amp; ((rx.outer.outer + floormod(threadIdx.x_1, 7)) &lt; 8)), (float32*)data_2[((((((rc.outer.outer*784) + (floordiv((floordiv(threadIdx.x_1, 7) + 104), 9)*49)) + (floormod((floordiv(threadIdx.x_1, 7) + 5), 9)*7)) + rx.outer.outer) + floormod(threadIdx.x_1, 7)) - 8)], 0f32, dtype=float32)
        attr [IterVar(threadIdx.x_1, (nullptr), &quot;ThreadIndex&quot;, &quot;threadIdx.x&quot;)] &quot;thread_extent&quot; = 56;
        pad_temp.shared[(threadIdx.x_1 + 784)] = @tir.if_then_else(((((1 &lt;= floormod((floordiv(threadIdx.x_1, 7) + 4), 9)) &amp;&amp; (floormod((floordiv(threadIdx.x_1, 7) + 4), 9) &lt; 8)) &amp;&amp; (1 &lt;= (rx.outer.outer + floormod(threadIdx.x_1, 7)))) &amp;&amp; ((rx.outer.outer + floormod(threadIdx.x_1, 7)) &lt; 8)), (float32*)data_2[((((((rc.outer.outer*784) + (floordiv((floordiv(threadIdx.x_1, 7) + 112), 9)*49)) + (floormod((floordiv(threadIdx.x_1, 7) + 4), 9)*7)) + rx.outer.outer) + floormod(threadIdx.x_1, 7)) - 8)], 0f32, dtype=float32)
        attr [IterVar(threadIdx.x_1, (nullptr), &quot;ThreadIndex&quot;, &quot;threadIdx.x&quot;)] &quot;thread_extent&quot; = 56;
        pad_temp.shared[(threadIdx.x_1 + 840)] = @tir.if_then_else(((((1 &lt;= floormod((floordiv(threadIdx.x_1, 7) + 3), 9)) &amp;&amp; (floormod((floordiv(threadIdx.x_1, 7) + 3), 9) &lt; 8)) &amp;&amp; (1 &lt;= (rx.outer.outer + floormod(threadIdx.x_1, 7)))) &amp;&amp; ((rx.outer.outer + floormod(threadIdx.x_1, 7)) &lt; 8)), (float32*)data_2[((((((rc.outer.outer*784) + (floordiv((floordiv(threadIdx.x_1, 7) + 120), 9)*49)) + (floormod((floordiv(threadIdx.x_1, 7) + 3), 9)*7)) + rx.outer.outer) + floormod(threadIdx.x_1, 7)) - 8)], 0f32, dtype=float32)
        attr [IterVar(threadIdx.x_1, (nullptr), &quot;ThreadIndex&quot;, &quot;threadIdx.x&quot;)] &quot;thread_extent&quot; = 56;
        pad_temp.shared[(threadIdx.x_1 + 896)] = @tir.if_then_else(((((1 &lt;= floormod((floordiv(threadIdx.x_1, 7) + 2), 9)) &amp;&amp; (floormod((floordiv(threadIdx.x_1, 7) + 2), 9) &lt; 8)) &amp;&amp; (1 &lt;= (rx.outer.outer + floormod(threadIdx.x_1, 7)))) &amp;&amp; ((rx.outer.outer + floormod(threadIdx.x_1, 7)) &lt; 8)), (float32*)data_2[((((((rc.outer.outer*784) + (floordiv((floordiv(threadIdx.x_1, 7) + 128), 9)*49)) + (floormod((floordiv(threadIdx.x_1, 7) + 2), 9)*7)) + rx.outer.outer) + floormod(threadIdx.x_1, 7)) - 8)], 0f32, dtype=float32)
        attr [IterVar(threadIdx.x_1, (nullptr), &quot;ThreadIndex&quot;, &quot;threadIdx.x&quot;)] &quot;thread_extent&quot; = 56;
        pad_temp.shared[(threadIdx.x_1 + 952)] = @tir.if_then_else((((floormod((floordiv(threadIdx.x_1, 7) + 1), 9) &lt; 8) &amp;&amp; (1 &lt;= (rx.outer.outer + floormod(threadIdx.x_1, 7)))) &amp;&amp; ((rx.outer.outer + floormod(threadIdx.x_1, 7)) &lt; 8)), (float32*)data_2[((((((rc.outer.outer*784) + (floordiv((floordiv(threadIdx.x_1, 7) + 136), 9)*49)) + (floormod((floordiv(threadIdx.x_1, 7) + 1), 9)*7)) + rx.outer.outer) + floormod(threadIdx.x_1, 7)) - 8)], 0f32, dtype=float32)
        attr [IterVar(threadIdx.x_2: int32, (nullptr), &quot;ThreadIndex&quot;, &quot;threadIdx.x&quot;)] &quot;thread_extent&quot; = 56;
        kernel.shared[threadIdx.x_2] = (float32*)kernel_2[(((((blockIdx.x*36864) + (floordiv(threadIdx.x_2, 48)*4608)) + (rc.outer.outer*144)) + (floormod(threadIdx.x_2, 48)*3)) + rx.outer.outer)]
        attr [IterVar(threadIdx.x_2, (nullptr), &quot;ThreadIndex&quot;, &quot;threadIdx.x&quot;)] &quot;thread_extent&quot; = 56;
        kernel.shared[(threadIdx.x_2 + 56)] = (float32*)kernel_2[(((((blockIdx.x*36864) + (floordiv((threadIdx.x_2 + 56), 48)*4608)) + (rc.outer.outer*144)) + (floormod((threadIdx.x_2 + 8), 48)*3)) + rx.outer.outer)]
        attr [IterVar(threadIdx.x_2, (nullptr), &quot;ThreadIndex&quot;, &quot;threadIdx.x&quot;)] &quot;thread_extent&quot; = 56;
        kernel.shared[(threadIdx.x_2 + 112)] = (float32*)kernel_2[(((((blockIdx.x*36864) + (floordiv((threadIdx.x_2 + 112), 48)*4608)) + (rc.outer.outer*144)) + (floormod((threadIdx.x_2 + 16), 48)*3)) + rx.outer.outer)]
        attr [IterVar(threadIdx.x_2, (nullptr), &quot;ThreadIndex&quot;, &quot;threadIdx.x&quot;)] &quot;thread_extent&quot; = 56;
        kernel.shared[(threadIdx.x_2 + 168)] = (float32*)kernel_2[(((((blockIdx.x*36864) + (floordiv((threadIdx.x_2 + 168), 48)*4608)) + (rc.outer.outer*144)) + (floormod((threadIdx.x_2 + 24), 48)*3)) + rx.outer.outer)]
        attr [IterVar(threadIdx.x_2, (nullptr), &quot;ThreadIndex&quot;, &quot;threadIdx.x&quot;)] &quot;thread_extent&quot; = 56;
        kernel.shared[(threadIdx.x_2 + 224)] = (float32*)kernel_2[(((((blockIdx.x*36864) + (floordiv((threadIdx.x_2 + 224), 48)*4608)) + (rc.outer.outer*144)) + (floormod((threadIdx.x_2 + 32), 48)*3)) + rx.outer.outer)]
        attr [IterVar(threadIdx.x_2, (nullptr), &quot;ThreadIndex&quot;, &quot;threadIdx.x&quot;)] &quot;thread_extent&quot; = 56;
        kernel.shared[(threadIdx.x_2 + 280)] = (float32*)kernel_2[(((((blockIdx.x*36864) + (floordiv((threadIdx.x_2 + 280), 48)*4608)) + (rc.outer.outer*144)) + (floormod((threadIdx.x_2 + 40), 48)*3)) + rx.outer.outer)]
        attr [IterVar(threadIdx.x_2, (nullptr), &quot;ThreadIndex&quot;, &quot;threadIdx.x&quot;)] &quot;thread_extent&quot; = 56;
        if @tir.likely((threadIdx.x_2 &lt; 48), dtype=bool) {
          kernel.shared[(threadIdx.x_2 + 336)] = (float32*)kernel_2[(((((blockIdx.x*36864) + (rc.outer.outer*144)) + (threadIdx.x_2*3)) + rx.outer.outer) + 32256)]
        }
        compute_3[0] = ((float32*)compute_3[0] + ((float32*)pad_temp.shared[(floormod(threadIdx.x, 7)*7)]*(float32*)kernel.shared[(floordiv(threadIdx.x, 7)*48)]))
        compute_3[1] = ((float32*)compute_3[1] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 1)]*(float32*)kernel.shared[(floordiv(threadIdx.x, 7)*48)]))
        compute_3[2] = ((float32*)compute_3[2] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 2)]*(float32*)kernel.shared[(floordiv(threadIdx.x, 7)*48)]))
        compute_3[3] = ((float32*)compute_3[3] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 3)]*(float32*)kernel.shared[(floordiv(threadIdx.x, 7)*48)]))
        compute_3[4] = ((float32*)compute_3[4] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 4)]*(float32*)kernel.shared[(floordiv(threadIdx.x, 7)*48)]))
        compute_3[5] = ((float32*)compute_3[5] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 5)]*(float32*)kernel.shared[(floordiv(threadIdx.x, 7)*48)]))
        compute_3[6] = ((float32*)compute_3[6] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 6)]*(float32*)kernel.shared[(floordiv(threadIdx.x, 7)*48)]))
        compute_3[0] = ((float32*)compute_3[0] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 7)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 1)]))
        compute_3[1] = ((float32*)compute_3[1] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 8)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 1)]))
        compute_3[2] = ((float32*)compute_3[2] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 9)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 1)]))
        compute_3[3] = ((float32*)compute_3[3] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 10)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 1)]))
        compute_3[4] = ((float32*)compute_3[4] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 11)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 1)]))
        compute_3[5] = ((float32*)compute_3[5] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 12)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 1)]))
        compute_3[6] = ((float32*)compute_3[6] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 13)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 1)]))
        compute_3[0] = ((float32*)compute_3[0] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 14)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 2)]))
        compute_3[1] = ((float32*)compute_3[1] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 15)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 2)]))
        compute_3[2] = ((float32*)compute_3[2] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 16)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 2)]))
        compute_3[3] = ((float32*)compute_3[3] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 17)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 2)]))
        compute_3[4] = ((float32*)compute_3[4] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 18)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 2)]))
        compute_3[5] = ((float32*)compute_3[5] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 19)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 2)]))
        compute_3[6] = ((float32*)compute_3[6] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 20)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 2)]))
        compute_3[0] = ((float32*)compute_3[0] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 63)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 3)]))
        compute_3[1] = ((float32*)compute_3[1] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 64)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 3)]))
        compute_3[2] = ((float32*)compute_3[2] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 65)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 3)]))
        compute_3[3] = ((float32*)compute_3[3] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 66)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 3)]))
        compute_3[4] = ((float32*)compute_3[4] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 67)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 3)]))
        compute_3[5] = ((float32*)compute_3[5] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 68)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 3)]))
        compute_3[6] = ((float32*)compute_3[6] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 69)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 3)]))
        compute_3[0] = ((float32*)compute_3[0] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 70)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 4)]))
        compute_3[1] = ((float32*)compute_3[1] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 71)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 4)]))
        compute_3[2] = ((float32*)compute_3[2] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 72)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 4)]))
        compute_3[3] = ((float32*)compute_3[3] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 73)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 4)]))
        compute_3[4] = ((float32*)compute_3[4] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 74)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 4)]))
        compute_3[5] = ((float32*)compute_3[5] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 75)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 4)]))
        compute_3[6] = ((float32*)compute_3[6] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 76)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 4)]))
        compute_3[0] = ((float32*)compute_3[0] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 77)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 5)]))
        compute_3[1] = ((float32*)compute_3[1] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 78)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 5)]))
        compute_3[2] = ((float32*)compute_3[2] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 79)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 5)]))
        compute_3[3] = ((float32*)compute_3[3] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 80)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 5)]))
        compute_3[4] = ((float32*)compute_3[4] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 81)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 5)]))
        compute_3[5] = ((float32*)compute_3[5] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 82)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 5)]))
        compute_3[6] = ((float32*)compute_3[6] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 83)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 5)]))
        compute_3[0] = ((float32*)compute_3[0] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 126)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 6)]))
        compute_3[1] = ((float32*)compute_3[1] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 127)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 6)]))
        compute_3[2] = ((float32*)compute_3[2] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 128)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 6)]))
        compute_3[3] = ((float32*)compute_3[3] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 129)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 6)]))
        compute_3[4] = ((float32*)compute_3[4] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 130)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 6)]))
        compute_3[5] = ((float32*)compute_3[5] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 131)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 6)]))
        compute_3[6] = ((float32*)compute_3[6] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 132)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 6)]))
        compute_3[0] = ((float32*)compute_3[0] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 133)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 7)]))
        compute_3[1] = ((float32*)compute_3[1] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 134)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 7)]))
        compute_3[2] = ((float32*)compute_3[2] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 135)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 7)]))
        compute_3[3] = ((float32*)compute_3[3] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 136)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 7)]))
        compute_3[4] = ((float32*)compute_3[4] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 137)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 7)]))
        compute_3[5] = ((float32*)compute_3[5] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 138)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 7)]))
        compute_3[6] = ((float32*)compute_3[6] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 139)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 7)]))
        compute_3[0] = ((float32*)compute_3[0] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 140)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 8)]))
        compute_3[1] = ((float32*)compute_3[1] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 141)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 8)]))
        compute_3[2] = ((float32*)compute_3[2] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 142)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 8)]))
        compute_3[3] = ((float32*)compute_3[3] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 143)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 8)]))
        compute_3[4] = ((float32*)compute_3[4] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 144)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 8)]))
        compute_3[5] = ((float32*)compute_3[5] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 145)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 8)]))
        compute_3[6] = ((float32*)compute_3[6] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 146)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 8)]))
        compute_3[0] = ((float32*)compute_3[0] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 189)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 9)]))
        compute_3[1] = ((float32*)compute_3[1] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 190)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 9)]))
        compute_3[2] = ((float32*)compute_3[2] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 191)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 9)]))
        compute_3[3] = ((float32*)compute_3[3] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 192)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 9)]))
        compute_3[4] = ((float32*)compute_3[4] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 193)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 9)]))
        compute_3[5] = ((float32*)compute_3[5] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 194)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 9)]))
        compute_3[6] = ((float32*)compute_3[6] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 195)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 9)]))
        compute_3[0] = ((float32*)compute_3[0] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 196)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 10)]))
        compute_3[1] = ((float32*)compute_3[1] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 197)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 10)]))
        compute_3[2] = ((float32*)compute_3[2] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 198)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 10)]))
        compute_3[3] = ((float32*)compute_3[3] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 199)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 10)]))
        compute_3[4] = ((float32*)compute_3[4] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 200)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 10)]))
        compute_3[5] = ((float32*)compute_3[5] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 201)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 10)]))
        compute_3[6] = ((float32*)compute_3[6] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 202)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 10)]))
        compute_3[0] = ((float32*)compute_3[0] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 203)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 11)]))
        compute_3[1] = ((float32*)compute_3[1] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 204)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 11)]))
        compute_3[2] = ((float32*)compute_3[2] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 205)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 11)]))
        compute_3[3] = ((float32*)compute_3[3] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 206)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 11)]))
        compute_3[4] = ((float32*)compute_3[4] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 207)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 11)]))
        compute_3[5] = ((float32*)compute_3[5] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 208)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 11)]))
        compute_3[6] = ((float32*)compute_3[6] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 209)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 11)]))
        compute_3[0] = ((float32*)compute_3[0] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 252)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 12)]))
        compute_3[1] = ((float32*)compute_3[1] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 253)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 12)]))
        compute_3[2] = ((float32*)compute_3[2] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 254)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 12)]))
        compute_3[3] = ((float32*)compute_3[3] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 255)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 12)]))
        compute_3[4] = ((float32*)compute_3[4] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 256)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 12)]))
        compute_3[5] = ((float32*)compute_3[5] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 257)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 12)]))
        compute_3[6] = ((float32*)compute_3[6] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 258)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 12)]))
        compute_3[0] = ((float32*)compute_3[0] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 259)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 13)]))
        compute_3[1] = ((float32*)compute_3[1] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 260)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 13)]))
        compute_3[2] = ((float32*)compute_3[2] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 261)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 13)]))
        compute_3[3] = ((float32*)compute_3[3] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 262)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 13)]))
        compute_3[4] = ((float32*)compute_3[4] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 263)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 13)]))
        compute_3[5] = ((float32*)compute_3[5] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 264)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 13)]))
        compute_3[6] = ((float32*)compute_3[6] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 265)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 13)]))
        compute_3[0] = ((float32*)compute_3[0] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 266)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 14)]))
        compute_3[1] = ((float32*)compute_3[1] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 267)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 14)]))
        compute_3[2] = ((float32*)compute_3[2] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 268)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 14)]))
        compute_3[3] = ((float32*)compute_3[3] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 269)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 14)]))
        compute_3[4] = ((float32*)compute_3[4] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 270)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 14)]))
        compute_3[5] = ((float32*)compute_3[5] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 271)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 14)]))
        compute_3[6] = ((float32*)compute_3[6] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 272)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 14)]))
        compute_3[0] = ((float32*)compute_3[0] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 315)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 15)]))
        compute_3[1] = ((float32*)compute_3[1] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 316)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 15)]))
        compute_3[2] = ((float32*)compute_3[2] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 317)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 15)]))
        compute_3[3] = ((float32*)compute_3[3] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 318)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 15)]))
        compute_3[4] = ((float32*)compute_3[4] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 319)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 15)]))
        compute_3[5] = ((float32*)compute_3[5] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 320)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 15)]))
        compute_3[6] = ((float32*)compute_3[6] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 321)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 15)]))
        compute_3[0] = ((float32*)compute_3[0] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 322)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 16)]))
        compute_3[1] = ((float32*)compute_3[1] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 323)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 16)]))
        compute_3[2] = ((float32*)compute_3[2] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 324)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 16)]))
        compute_3[3] = ((float32*)compute_3[3] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 325)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 16)]))
        compute_3[4] = ((float32*)compute_3[4] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 326)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 16)]))
        compute_3[5] = ((float32*)compute_3[5] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 327)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 16)]))
        compute_3[6] = ((float32*)compute_3[6] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 328)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 16)]))
        compute_3[0] = ((float32*)compute_3[0] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 329)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 17)]))
        compute_3[1] = ((float32*)compute_3[1] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 330)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 17)]))
        compute_3[2] = ((float32*)compute_3[2] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 331)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 17)]))
        compute_3[3] = ((float32*)compute_3[3] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 332)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 17)]))
        compute_3[4] = ((float32*)compute_3[4] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 333)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 17)]))
        compute_3[5] = ((float32*)compute_3[5] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 334)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 17)]))
        compute_3[6] = ((float32*)compute_3[6] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 335)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 17)]))
        compute_3[0] = ((float32*)compute_3[0] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 378)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 18)]))
        compute_3[1] = ((float32*)compute_3[1] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 379)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 18)]))
        compute_3[2] = ((float32*)compute_3[2] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 380)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 18)]))
        compute_3[3] = ((float32*)compute_3[3] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 381)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 18)]))
        compute_3[4] = ((float32*)compute_3[4] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 382)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 18)]))
        compute_3[5] = ((float32*)compute_3[5] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 383)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 18)]))
        compute_3[6] = ((float32*)compute_3[6] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 384)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 18)]))
        compute_3[0] = ((float32*)compute_3[0] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 385)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 19)]))
        compute_3[1] = ((float32*)compute_3[1] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 386)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 19)]))
        compute_3[2] = ((float32*)compute_3[2] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 387)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 19)]))
        compute_3[3] = ((float32*)compute_3[3] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 388)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 19)]))
        compute_3[4] = ((float32*)compute_3[4] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 389)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 19)]))
        compute_3[5] = ((float32*)compute_3[5] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 390)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 19)]))
        compute_3[6] = ((float32*)compute_3[6] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 391)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 19)]))
        compute_3[0] = ((float32*)compute_3[0] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 392)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 20)]))
        compute_3[1] = ((float32*)compute_3[1] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 393)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 20)]))
        compute_3[2] = ((float32*)compute_3[2] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 394)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 20)]))
        compute_3[3] = ((float32*)compute_3[3] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 395)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 20)]))
        compute_3[4] = ((float32*)compute_3[4] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 396)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 20)]))
        compute_3[5] = ((float32*)compute_3[5] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 397)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 20)]))
        compute_3[6] = ((float32*)compute_3[6] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 398)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 20)]))
        compute_3[0] = ((float32*)compute_3[0] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 441)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 21)]))
        compute_3[1] = ((float32*)compute_3[1] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 442)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 21)]))
        compute_3[2] = ((float32*)compute_3[2] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 443)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 21)]))
        compute_3[3] = ((float32*)compute_3[3] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 444)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 21)]))
        compute_3[4] = ((float32*)compute_3[4] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 445)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 21)]))
        compute_3[5] = ((float32*)compute_3[5] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 446)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 21)]))
        compute_3[6] = ((float32*)compute_3[6] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 447)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 21)]))
        compute_3[0] = ((float32*)compute_3[0] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 448)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 22)]))
        compute_3[1] = ((float32*)compute_3[1] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 449)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 22)]))
        compute_3[2] = ((float32*)compute_3[2] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 450)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 22)]))
        compute_3[3] = ((float32*)compute_3[3] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 451)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 22)]))
        compute_3[4] = ((float32*)compute_3[4] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 452)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 22)]))
        compute_3[5] = ((float32*)compute_3[5] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 453)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 22)]))
        compute_3[6] = ((float32*)compute_3[6] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 454)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 22)]))
        compute_3[0] = ((float32*)compute_3[0] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 455)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 23)]))
        compute_3[1] = ((float32*)compute_3[1] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 456)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 23)]))
        compute_3[2] = ((float32*)compute_3[2] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 457)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 23)]))
        compute_3[3] = ((float32*)compute_3[3] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 458)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 23)]))
        compute_3[4] = ((float32*)compute_3[4] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 459)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 23)]))
        compute_3[5] = ((float32*)compute_3[5] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 460)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 23)]))
        compute_3[6] = ((float32*)compute_3[6] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 461)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 23)]))
        compute_3[0] = ((float32*)compute_3[0] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 504)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 24)]))
        compute_3[1] = ((float32*)compute_3[1] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 505)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 24)]))
        compute_3[2] = ((float32*)compute_3[2] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 506)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 24)]))
        compute_3[3] = ((float32*)compute_3[3] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 507)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 24)]))
        compute_3[4] = ((float32*)compute_3[4] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 508)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 24)]))
        compute_3[5] = ((float32*)compute_3[5] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 509)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 24)]))
        compute_3[6] = ((float32*)compute_3[6] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 510)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 24)]))
        compute_3[0] = ((float32*)compute_3[0] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 511)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 25)]))
        compute_3[1] = ((float32*)compute_3[1] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 512)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 25)]))
        compute_3[2] = ((float32*)compute_3[2] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 513)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 25)]))
        compute_3[3] = ((float32*)compute_3[3] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 514)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 25)]))
        compute_3[4] = ((float32*)compute_3[4] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 515)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 25)]))
        compute_3[5] = ((float32*)compute_3[5] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 516)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 25)]))
        compute_3[6] = ((float32*)compute_3[6] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 517)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 25)]))
        compute_3[0] = ((float32*)compute_3[0] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 518)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 26)]))
        compute_3[1] = ((float32*)compute_3[1] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 519)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 26)]))
        compute_3[2] = ((float32*)compute_3[2] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 520)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 26)]))
        compute_3[3] = ((float32*)compute_3[3] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 521)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 26)]))
        compute_3[4] = ((float32*)compute_3[4] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 522)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 26)]))
        compute_3[5] = ((float32*)compute_3[5] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 523)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 26)]))
        compute_3[6] = ((float32*)compute_3[6] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 524)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 26)]))
        compute_3[0] = ((float32*)compute_3[0] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 567)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 27)]))
        compute_3[1] = ((float32*)compute_3[1] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 568)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 27)]))
        compute_3[2] = ((float32*)compute_3[2] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 569)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 27)]))
        compute_3[3] = ((float32*)compute_3[3] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 570)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 27)]))
        compute_3[4] = ((float32*)compute_3[4] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 571)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 27)]))
        compute_3[5] = ((float32*)compute_3[5] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 572)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 27)]))
        compute_3[6] = ((float32*)compute_3[6] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 573)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 27)]))
        compute_3[0] = ((float32*)compute_3[0] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 574)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 28)]))
        compute_3[1] = ((float32*)compute_3[1] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 575)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 28)]))
        compute_3[2] = ((float32*)compute_3[2] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 576)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 28)]))
        compute_3[3] = ((float32*)compute_3[3] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 577)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 28)]))
        compute_3[4] = ((float32*)compute_3[4] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 578)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 28)]))
        compute_3[5] = ((float32*)compute_3[5] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 579)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 28)]))
        compute_3[6] = ((float32*)compute_3[6] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 580)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 28)]))
        compute_3[0] = ((float32*)compute_3[0] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 581)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 29)]))
        compute_3[1] = ((float32*)compute_3[1] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 582)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 29)]))
        compute_3[2] = ((float32*)compute_3[2] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 583)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 29)]))
        compute_3[3] = ((float32*)compute_3[3] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 584)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 29)]))
        compute_3[4] = ((float32*)compute_3[4] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 585)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 29)]))
        compute_3[5] = ((float32*)compute_3[5] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 586)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 29)]))
        compute_3[6] = ((float32*)compute_3[6] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 587)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 29)]))
        compute_3[0] = ((float32*)compute_3[0] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 630)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 30)]))
        compute_3[1] = ((float32*)compute_3[1] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 631)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 30)]))
        compute_3[2] = ((float32*)compute_3[2] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 632)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 30)]))
        compute_3[3] = ((float32*)compute_3[3] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 633)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 30)]))
        compute_3[4] = ((float32*)compute_3[4] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 634)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 30)]))
        compute_3[5] = ((float32*)compute_3[5] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 635)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 30)]))
        compute_3[6] = ((float32*)compute_3[6] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 636)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 30)]))
        compute_3[0] = ((float32*)compute_3[0] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 637)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 31)]))
        compute_3[1] = ((float32*)compute_3[1] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 638)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 31)]))
        compute_3[2] = ((float32*)compute_3[2] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 639)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 31)]))
        compute_3[3] = ((float32*)compute_3[3] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 640)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 31)]))
        compute_3[4] = ((float32*)compute_3[4] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 641)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 31)]))
        compute_3[5] = ((float32*)compute_3[5] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 642)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 31)]))
        compute_3[6] = ((float32*)compute_3[6] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 643)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 31)]))
        compute_3[0] = ((float32*)compute_3[0] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 644)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 32)]))
        compute_3[1] = ((float32*)compute_3[1] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 645)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 32)]))
        compute_3[2] = ((float32*)compute_3[2] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 646)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 32)]))
        compute_3[3] = ((float32*)compute_3[3] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 647)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 32)]))
        compute_3[4] = ((float32*)compute_3[4] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 648)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 32)]))
        compute_3[5] = ((float32*)compute_3[5] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 649)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 32)]))
        compute_3[6] = ((float32*)compute_3[6] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 650)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 32)]))
        compute_3[0] = ((float32*)compute_3[0] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 693)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 33)]))
        compute_3[1] = ((float32*)compute_3[1] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 694)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 33)]))
        compute_3[2] = ((float32*)compute_3[2] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 695)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 33)]))
        compute_3[3] = ((float32*)compute_3[3] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 696)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 33)]))
        compute_3[4] = ((float32*)compute_3[4] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 697)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 33)]))
        compute_3[5] = ((float32*)compute_3[5] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 698)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 33)]))
        compute_3[6] = ((float32*)compute_3[6] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 699)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 33)]))
        compute_3[0] = ((float32*)compute_3[0] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 700)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 34)]))
        compute_3[1] = ((float32*)compute_3[1] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 701)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 34)]))
        compute_3[2] = ((float32*)compute_3[2] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 702)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 34)]))
        compute_3[3] = ((float32*)compute_3[3] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 703)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 34)]))
        compute_3[4] = ((float32*)compute_3[4] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 704)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 34)]))
        compute_3[5] = ((float32*)compute_3[5] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 705)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 34)]))
        compute_3[6] = ((float32*)compute_3[6] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 706)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 34)]))
        compute_3[0] = ((float32*)compute_3[0] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 707)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 35)]))
        compute_3[1] = ((float32*)compute_3[1] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 708)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 35)]))
        compute_3[2] = ((float32*)compute_3[2] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 709)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 35)]))
        compute_3[3] = ((float32*)compute_3[3] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 710)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 35)]))
        compute_3[4] = ((float32*)compute_3[4] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 711)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 35)]))
        compute_3[5] = ((float32*)compute_3[5] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 712)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 35)]))
        compute_3[6] = ((float32*)compute_3[6] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 713)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 35)]))
        compute_3[0] = ((float32*)compute_3[0] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 756)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 36)]))
        compute_3[1] = ((float32*)compute_3[1] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 757)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 36)]))
        compute_3[2] = ((float32*)compute_3[2] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 758)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 36)]))
        compute_3[3] = ((float32*)compute_3[3] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 759)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 36)]))
        compute_3[4] = ((float32*)compute_3[4] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 760)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 36)]))
        compute_3[5] = ((float32*)compute_3[5] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 761)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 36)]))
        compute_3[6] = ((float32*)compute_3[6] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 762)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 36)]))
        compute_3[0] = ((float32*)compute_3[0] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 763)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 37)]))
        compute_3[1] = ((float32*)compute_3[1] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 764)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 37)]))
        compute_3[2] = ((float32*)compute_3[2] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 765)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 37)]))
        compute_3[3] = ((float32*)compute_3[3] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 766)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 37)]))
        compute_3[4] = ((float32*)compute_3[4] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 767)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 37)]))
        compute_3[5] = ((float32*)compute_3[5] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 768)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 37)]))
        compute_3[6] = ((float32*)compute_3[6] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 769)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 37)]))
        compute_3[0] = ((float32*)compute_3[0] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 770)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 38)]))
        compute_3[1] = ((float32*)compute_3[1] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 771)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 38)]))
        compute_3[2] = ((float32*)compute_3[2] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 772)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 38)]))
        compute_3[3] = ((float32*)compute_3[3] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 773)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 38)]))
        compute_3[4] = ((float32*)compute_3[4] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 774)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 38)]))
        compute_3[5] = ((float32*)compute_3[5] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 775)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 38)]))
        compute_3[6] = ((float32*)compute_3[6] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 776)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 38)]))
        compute_3[0] = ((float32*)compute_3[0] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 819)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 39)]))
        compute_3[1] = ((float32*)compute_3[1] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 820)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 39)]))
        compute_3[2] = ((float32*)compute_3[2] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 821)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 39)]))
        compute_3[3] = ((float32*)compute_3[3] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 822)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 39)]))
        compute_3[4] = ((float32*)compute_3[4] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 823)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 39)]))
        compute_3[5] = ((float32*)compute_3[5] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 824)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 39)]))
        compute_3[6] = ((float32*)compute_3[6] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 825)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 39)]))
        compute_3[0] = ((float32*)compute_3[0] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 826)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 40)]))
        compute_3[1] = ((float32*)compute_3[1] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 827)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 40)]))
        compute_3[2] = ((float32*)compute_3[2] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 828)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 40)]))
        compute_3[3] = ((float32*)compute_3[3] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 829)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 40)]))
        compute_3[4] = ((float32*)compute_3[4] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 830)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 40)]))
        compute_3[5] = ((float32*)compute_3[5] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 831)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 40)]))
        compute_3[6] = ((float32*)compute_3[6] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 832)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 40)]))
        compute_3[0] = ((float32*)compute_3[0] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 833)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 41)]))
        compute_3[1] = ((float32*)compute_3[1] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 834)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 41)]))
        compute_3[2] = ((float32*)compute_3[2] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 835)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 41)]))
        compute_3[3] = ((float32*)compute_3[3] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 836)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 41)]))
        compute_3[4] = ((float32*)compute_3[4] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 837)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 41)]))
        compute_3[5] = ((float32*)compute_3[5] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 838)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 41)]))
        compute_3[6] = ((float32*)compute_3[6] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 839)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 41)]))
        compute_3[0] = ((float32*)compute_3[0] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 882)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 42)]))
        compute_3[1] = ((float32*)compute_3[1] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 883)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 42)]))
        compute_3[2] = ((float32*)compute_3[2] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 884)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 42)]))
        compute_3[3] = ((float32*)compute_3[3] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 885)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 42)]))
        compute_3[4] = ((float32*)compute_3[4] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 886)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 42)]))
        compute_3[5] = ((float32*)compute_3[5] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 887)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 42)]))
        compute_3[6] = ((float32*)compute_3[6] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 888)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 42)]))
        compute_3[0] = ((float32*)compute_3[0] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 889)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 43)]))
        compute_3[1] = ((float32*)compute_3[1] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 890)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 43)]))
        compute_3[2] = ((float32*)compute_3[2] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 891)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 43)]))
        compute_3[3] = ((float32*)compute_3[3] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 892)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 43)]))
        compute_3[4] = ((float32*)compute_3[4] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 893)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 43)]))
        compute_3[5] = ((float32*)compute_3[5] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 894)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 43)]))
        compute_3[6] = ((float32*)compute_3[6] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 895)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 43)]))
        compute_3[0] = ((float32*)compute_3[0] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 896)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 44)]))
        compute_3[1] = ((float32*)compute_3[1] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 897)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 44)]))
        compute_3[2] = ((float32*)compute_3[2] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 898)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 44)]))
        compute_3[3] = ((float32*)compute_3[3] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 899)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 44)]))
        compute_3[4] = ((float32*)compute_3[4] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 900)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 44)]))
        compute_3[5] = ((float32*)compute_3[5] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 901)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 44)]))
        compute_3[6] = ((float32*)compute_3[6] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 902)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 44)]))
        compute_3[0] = ((float32*)compute_3[0] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 945)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 45)]))
        compute_3[1] = ((float32*)compute_3[1] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 946)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 45)]))
        compute_3[2] = ((float32*)compute_3[2] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 947)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 45)]))
        compute_3[3] = ((float32*)compute_3[3] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 948)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 45)]))
        compute_3[4] = ((float32*)compute_3[4] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 949)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 45)]))
        compute_3[5] = ((float32*)compute_3[5] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 950)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 45)]))
        compute_3[6] = ((float32*)compute_3[6] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 951)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 45)]))
        compute_3[0] = ((float32*)compute_3[0] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 952)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 46)]))
        compute_3[1] = ((float32*)compute_3[1] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 953)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 46)]))
        compute_3[2] = ((float32*)compute_3[2] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 954)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 46)]))
        compute_3[3] = ((float32*)compute_3[3] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 955)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 46)]))
        compute_3[4] = ((float32*)compute_3[4] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 956)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 46)]))
        compute_3[5] = ((float32*)compute_3[5] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 957)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 46)]))
        compute_3[6] = ((float32*)compute_3[6] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 958)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 46)]))
        compute_3[0] = ((float32*)compute_3[0] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 959)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 47)]))
        compute_3[1] = ((float32*)compute_3[1] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 960)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 47)]))
        compute_3[2] = ((float32*)compute_3[2] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 961)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 47)]))
        compute_3[3] = ((float32*)compute_3[3] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 962)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 47)]))
        compute_3[4] = ((float32*)compute_3[4] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 963)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 47)]))
        compute_3[5] = ((float32*)compute_3[5] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 964)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 47)]))
        compute_3[6] = ((float32*)compute_3[6] + ((float32*)pad_temp.shared[((floormod(threadIdx.x, 7)*7) + 965)]*(float32*)kernel.shared[((floordiv(threadIdx.x, 7)*48) + 47)]))
      }
    }
    compute_2[((blockIdx.x*392) + (threadIdx.x*7))] = max(((float32*)compute_3[0] + (float32*)bias_2[((blockIdx.x*8) + floordiv(threadIdx.x, 7))]), 0f32)
    compute_2[(((blockIdx.x*392) + (threadIdx.x*7)) + 1)] = max(((float32*)compute_3[1] + (float32*)bias_2[((blockIdx.x*8) + floordiv(threadIdx.x, 7))]), 0f32)
    compute_2[(((blockIdx.x*392) + (threadIdx.x*7)) + 2)] = max(((float32*)compute_3[2] + (float32*)bias_2[((blockIdx.x*8) + floordiv(threadIdx.x, 7))]), 0f32)
    compute_2[(((blockIdx.x*392) + (threadIdx.x*7)) + 3)] = max(((float32*)compute_3[3] + (float32*)bias_2[((blockIdx.x*8) + floordiv(threadIdx.x, 7))]), 0f32)
    compute_2[(((blockIdx.x*392) + (threadIdx.x*7)) + 4)] = max(((float32*)compute_3[4] + (float32*)bias_2[((blockIdx.x*8) + floordiv(threadIdx.x, 7))]), 0f32)
    compute_2[(((blockIdx.x*392) + (threadIdx.x*7)) + 5)] = max(((float32*)compute_3[5] + (float32*)bias_2[((blockIdx.x*8) + floordiv(threadIdx.x, 7))]), 0f32)
    compute_2[(((blockIdx.x*392) + (threadIdx.x*7)) + 6)] = max(((float32*)compute_3[6] + (float32*)bias_2[((blockIdx.x*8) + floordiv(threadIdx.x, 7))]), 0f32)
  }
}
</pre></div>
</div>
</section>
<section id="check-correctness-and-evaluate-performance">
<h2>Check correctness and evaluate performance<a class="headerlink" href="#check-correctness-and-evaluate-performance" title="Permalink to this headline">¶</a></h2>
<p>We build the binary and check its correctness and performance.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">func</span> <span class="o">=</span> <a href="../../api/python/driver.html#tvm.build" title="View documentation for tvm.build"><span class="n">tvm</span><span class="o">.</span><span class="n">build</span></a><span class="p">(</span><span class="n">sch</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>

<span class="c1"># Check correctness</span>
<span class="n">data_np</span> <span class="o">=</span> <a href="https://numpy.org/doc/stable/reference/random/generated/numpy.random.uniform.html#numpy.random.uniform" title="View documentation for numpy.random.uniform"><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span></a><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">CI</span><span class="p">,</span> <span class="n">H</span><span class="p">,</span> <span class="n">W</span><span class="p">))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><a href="https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.float32" title="View documentation for numpy.float32"><span class="n">np</span><span class="o">.</span><span class="n">float32</span></a><span class="p">)</span>
<span class="n">weight_np</span> <span class="o">=</span> <a href="https://numpy.org/doc/stable/reference/random/generated/numpy.random.uniform.html#numpy.random.uniform" title="View documentation for numpy.random.uniform"><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span></a><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">CO</span><span class="p">,</span> <span class="n">CI</span><span class="p">,</span> <span class="n">KH</span><span class="p">,</span> <span class="n">KW</span><span class="p">))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><a href="https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.float32" title="View documentation for numpy.float32"><span class="n">np</span><span class="o">.</span><span class="n">float32</span></a><span class="p">)</span>
<span class="n">bias_np</span> <span class="o">=</span> <a href="https://numpy.org/doc/stable/reference/random/generated/numpy.random.uniform.html#numpy.random.uniform" title="View documentation for numpy.random.uniform"><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span></a><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">CO</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><a href="https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.float32" title="View documentation for numpy.float32"><span class="n">np</span><span class="o">.</span><span class="n">float32</span></a><span class="p">)</span>
<span class="n">conv_np</span> <span class="o">=</span> <span class="n">conv2d_nchw_python</span><span class="p">(</span><span class="n">data_np</span><span class="p">,</span> <span class="n">weight_np</span><span class="p">,</span> <span class="n">strides</span><span class="p">,</span> <span class="n">padding</span><span class="p">)</span>
<span class="n">out_np</span> <span class="o">=</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.maximum.html#numpy.maximum" title="View documentation for numpy.maximum"><span class="n">np</span><span class="o">.</span><span class="n">maximum</span></a><span class="p">(</span><span class="n">conv_np</span> <span class="o">+</span> <span class="n">bias_np</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">)</span>

<span class="n">dev</span> <span class="o">=</span> <span class="n">tvm</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>
<span class="n">data_tvm</span> <span class="o">=</span> <a href="../../api/python/ndarray.html#tvm.nd.array" title="View documentation for tvm.nd.array"><span class="n">tvm</span><span class="o">.</span><span class="n">nd</span><span class="o">.</span><span class="n">array</span></a><span class="p">(</span><span class="n">data_np</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">dev</span><span class="p">)</span>
<span class="n">weight_tvm</span> <span class="o">=</span> <a href="../../api/python/ndarray.html#tvm.nd.array" title="View documentation for tvm.nd.array"><span class="n">tvm</span><span class="o">.</span><span class="n">nd</span><span class="o">.</span><span class="n">array</span></a><span class="p">(</span><span class="n">weight_np</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">dev</span><span class="p">)</span>
<span class="n">bias_tvm</span> <span class="o">=</span> <a href="../../api/python/ndarray.html#tvm.nd.array" title="View documentation for tvm.nd.array"><span class="n">tvm</span><span class="o">.</span><span class="n">nd</span><span class="o">.</span><span class="n">array</span></a><span class="p">(</span><span class="n">bias_np</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">dev</span><span class="p">)</span>
<span class="n">out_tvm</span> <span class="o">=</span> <a href="../../api/python/ndarray.html#tvm.nd.empty" title="View documentation for tvm.nd.empty"><span class="n">tvm</span><span class="o">.</span><span class="n">nd</span><span class="o">.</span><span class="n">empty</span></a><span class="p">(</span><span class="n">out_np</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">dev</span><span class="p">)</span>
<span class="n">func</span><span class="p">(</span><span class="n">data_tvm</span><span class="p">,</span> <span class="n">weight_tvm</span><span class="p">,</span> <span class="n">bias_tvm</span><span class="p">,</span> <span class="n">out_tvm</span><span class="p">)</span>

<span class="c1"># Check results</span>
<a href="https://numpy.org/doc/stable/reference/generated/numpy.testing.assert_allclose.html#numpy.testing.assert_allclose" title="View documentation for numpy.testing.assert_allclose"><span class="n">np</span><span class="o">.</span><span class="n">testing</span><span class="o">.</span><span class="n">assert_allclose</span></a><span class="p">(</span><span class="n">out_np</span><span class="p">,</span> <span class="n">out_tvm</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">rtol</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">)</span>

<span class="c1"># Evaluate execution time</span>
<span class="n">evaluator</span> <span class="o">=</span> <span class="n">func</span><span class="o">.</span><span class="n">time_evaluator</span><span class="p">(</span><span class="n">func</span><span class="o">.</span><span class="n">entry_name</span><span class="p">,</span> <span class="n">dev</span><span class="p">,</span> <span class="n">min_repeat_ms</span><span class="o">=</span><span class="mi">500</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span>
    <span class="s2">&quot;Execution time of this operator: </span><span class="si">%.3f</span><span class="s2"> ms&quot;</span>
    <span class="o">%</span> <span class="p">(</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.median.html#numpy.median" title="View documentation for numpy.median"><span class="n">np</span><span class="o">.</span><span class="n">median</span></a><span class="p">(</span><span class="n">evaluator</span><span class="p">(</span><span class="n">data_tvm</span><span class="p">,</span> <span class="n">weight_tvm</span><span class="p">,</span> <span class="n">bias_tvm</span><span class="p">,</span> <span class="n">out_tvm</span><span class="p">)</span><span class="o">.</span><span class="n">results</span><span class="p">)</span> <span class="o">*</span> <span class="mi">1000</span><span class="p">)</span>
<span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Execution time of this operator: 0.353 ms
</pre></div>
</div>
</section>
<section id="using-the-record-file">
<h2>Using the record file<a class="headerlink" href="#using-the-record-file" title="Permalink to this headline">¶</a></h2>
<p>During the search, all measurement records are dumped into the record
file “conv2d.json”. The measurement records can be used to re-apply search results,
resume the search, and perform other analyses.</p>
<p>Here is an example where we load the best schedule from a file,
print the equivalent python schedule API and CUDA source code.
They can be used for debugging and learning the behavior of the auto-scheduler.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Equivalent python schedule:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">task</span><span class="o">.</span><span class="n">print_best</span><span class="p">(</span><span class="n">log_file</span><span class="p">,</span> <span class="n">print_mode</span><span class="o">=</span><span class="s2">&quot;schedule&quot;</span><span class="p">))</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;CUDA source code:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">task</span><span class="o">.</span><span class="n">print_best</span><span class="p">(</span><span class="n">log_file</span><span class="p">,</span> <span class="n">print_mode</span><span class="o">=</span><span class="s2">&quot;cuda&quot;</span><span class="p">))</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Equivalent python schedule:
pad_temp_i0, pad_temp_i1, pad_temp_i2, pad_temp_i3 = tuple(pad_temp.op.axis) + tuple(pad_temp.op.reduce_axis)
compute_nn, compute_ff, compute_yy, compute_xx, compute_rc, compute_ry, compute_rx = tuple(compute.op.axis) + tuple(compute.op.reduce_axis)
T_add_ax0, T_add_ax1, T_add_ax2, T_add_ax3 = tuple(T_add.op.axis) + tuple(T_add.op.reduce_axis)
compute_i0, compute_i1, compute_i2, compute_i3 = tuple(compute.op.axis) + tuple(compute.op.reduce_axis)
s[T_add].compute_inline()
compute_nn_o_i, compute_nn_i = s[compute].split(compute_nn, factor=1)
compute_nn_o_o_i, compute_nn_o_i = s[compute].split(compute_nn_o_i, factor=1)
compute_nn_o_o_o_i, compute_nn_o_o_i = s[compute].split(compute_nn_o_o_i, factor=1)
compute_nn_o_o_o_o, compute_nn_o_o_o_i = s[compute].split(compute_nn_o_o_o_i, factor=1)
compute_ff_o_i, compute_ff_i = s[compute].split(compute_ff, factor=1)
compute_ff_o_o_i, compute_ff_o_i = s[compute].split(compute_ff_o_i, factor=1)
compute_ff_o_o_o_i, compute_ff_o_o_i = s[compute].split(compute_ff_o_o_i, factor=8)
compute_ff_o_o_o_o, compute_ff_o_o_o_i = s[compute].split(compute_ff_o_o_o_i, factor=1)
compute_yy_o_i, compute_yy_i = s[compute].split(compute_yy, factor=1)
compute_yy_o_o_i, compute_yy_o_i = s[compute].split(compute_yy_o_i, factor=1)
compute_yy_o_o_o_i, compute_yy_o_o_i = s[compute].split(compute_yy_o_o_i, factor=7)
compute_yy_o_o_o_o, compute_yy_o_o_o_i = s[compute].split(compute_yy_o_o_o_i, factor=1)
compute_xx_o_i, compute_xx_i = s[compute].split(compute_xx, factor=1)
compute_xx_o_o_i, compute_xx_o_i = s[compute].split(compute_xx_o_i, factor=1)
compute_xx_o_o_o_i, compute_xx_o_o_i = s[compute].split(compute_xx_o_o_i, factor=1)
compute_xx_o_o_o_o, compute_xx_o_o_o_i = s[compute].split(compute_xx_o_o_o_i, factor=7)
compute_rc_o_i, compute_rc_i = s[compute].split(compute_rc, factor=16)
compute_rc_o_o, compute_rc_o_i = s[compute].split(compute_rc_o_i, factor=1)
compute_ry_o_i, compute_ry_i = s[compute].split(compute_ry, factor=3)
compute_ry_o_o, compute_ry_o_i = s[compute].split(compute_ry_o_i, factor=1)
compute_rx_o_i, compute_rx_i = s[compute].split(compute_rx, factor=1)
compute_rx_o_o, compute_rx_o_i = s[compute].split(compute_rx_o_i, factor=1)
s[compute].reorder(compute_nn_o_o_o_o, compute_ff_o_o_o_o, compute_yy_o_o_o_o, compute_xx_o_o_o_o, compute_nn_o_o_o_i, compute_ff_o_o_o_i, compute_yy_o_o_o_i, compute_xx_o_o_o_i, compute_nn_o_o_i, compute_ff_o_o_i, compute_yy_o_o_i, compute_xx_o_o_i, compute_rc_o_o, compute_ry_o_o, compute_rx_o_o, compute_rc_o_i, compute_ry_o_i, compute_rx_o_i, compute_nn_o_i, compute_ff_o_i, compute_yy_o_i, compute_xx_o_i, compute_rc_i, compute_ry_i, compute_rx_i, compute_nn_i, compute_ff_i, compute_yy_i, compute_xx_i)
compute_i0_o_i, compute_i0_i = s[compute].split(compute_i0, factor=1)
compute_i0_o_o_i, compute_i0_o_i = s[compute].split(compute_i0_o_i, factor=1)
compute_i0_o_o_o, compute_i0_o_o_i = s[compute].split(compute_i0_o_o_i, factor=1)
compute_i1_o_i, compute_i1_i = s[compute].split(compute_i1, factor=1)
compute_i1_o_o_i, compute_i1_o_i = s[compute].split(compute_i1_o_i, factor=8)
compute_i1_o_o_o, compute_i1_o_o_i = s[compute].split(compute_i1_o_o_i, factor=1)
compute_i2_o_i, compute_i2_i = s[compute].split(compute_i2, factor=1)
compute_i2_o_o_i, compute_i2_o_i = s[compute].split(compute_i2_o_i, factor=7)
compute_i2_o_o_o, compute_i2_o_o_i = s[compute].split(compute_i2_o_o_i, factor=1)
compute_i3_o_i, compute_i3_i = s[compute].split(compute_i3, factor=1)
compute_i3_o_o_i, compute_i3_o_i = s[compute].split(compute_i3_o_i, factor=1)
compute_i3_o_o_o, compute_i3_o_o_i = s[compute].split(compute_i3_o_o_i, factor=7)
s[compute].reorder(compute_i0_o_o_o, compute_i1_o_o_o, compute_i2_o_o_o, compute_i3_o_o_o, compute_i0_o_o_i, compute_i1_o_o_i, compute_i2_o_o_i, compute_i3_o_o_i, compute_i0_o_i, compute_i1_o_i, compute_i2_o_i, compute_i3_o_i, compute_i0_i, compute_i1_i, compute_i2_i, compute_i3_i)
s[compute].compute_at(s[compute], compute_i3_o_i)
kernel_shared = s.cache_read(kernel, &quot;shared&quot;, [compute])
kernel_shared_ax0, kernel_shared_ax1, kernel_shared_ax2, kernel_shared_ax3 = tuple(kernel_shared.op.axis)
s[kernel_shared].compute_at(s[compute], compute_rx_o_o)
pad_temp_shared = s.cache_read(pad_temp, &quot;shared&quot;, [compute])
pad_temp_shared_ax0, pad_temp_shared_ax1, pad_temp_shared_ax2, pad_temp_shared_ax3 = tuple(pad_temp_shared.op.axis)
s[pad_temp_shared].compute_at(s[compute], compute_rx_o_o)
s[pad_temp].compute_inline()
compute_i0_o_o_o_i1_o_o_o_fused_i2_o_o_o_fused_i3_o_o_o_fused = s[compute].fuse(compute_i0_o_o_o, compute_i1_o_o_o, compute_i2_o_o_o, compute_i3_o_o_o)
s[compute].bind(compute_i0_o_o_o_i1_o_o_o_fused_i2_o_o_o_fused_i3_o_o_o_fused, te.thread_axis(&quot;blockIdx.x&quot;))
compute_i0_o_o_i_i1_o_o_i_fused_i2_o_o_i_fused_i3_o_o_i_fused = s[compute].fuse(compute_i0_o_o_i, compute_i1_o_o_i, compute_i2_o_o_i, compute_i3_o_o_i)
s[compute].bind(compute_i0_o_o_i_i1_o_o_i_fused_i2_o_o_i_fused_i3_o_o_i_fused, te.thread_axis(&quot;vthread&quot;))
compute_i0_o_i_i1_o_i_fused_i2_o_i_fused_i3_o_i_fused = s[compute].fuse(compute_i0_o_i, compute_i1_o_i, compute_i2_o_i, compute_i3_o_i)
s[compute].bind(compute_i0_o_i_i1_o_i_fused_i2_o_i_fused_i3_o_i_fused, te.thread_axis(&quot;threadIdx.x&quot;))
kernel_shared_ax0_ax1_fused_ax2_fused_ax3_fused = s[kernel_shared].fuse(kernel_shared_ax0, kernel_shared_ax1, kernel_shared_ax2, kernel_shared_ax3)
kernel_shared_ax0_ax1_fused_ax2_fused_ax3_fused_o, kernel_shared_ax0_ax1_fused_ax2_fused_ax3_fused_i = s[kernel_shared].split(kernel_shared_ax0_ax1_fused_ax2_fused_ax3_fused, factor=1)
s[kernel_shared].vectorize(kernel_shared_ax0_ax1_fused_ax2_fused_ax3_fused_i)
kernel_shared_ax0_ax1_fused_ax2_fused_ax3_fused_o_o, kernel_shared_ax0_ax1_fused_ax2_fused_ax3_fused_o_i = s[kernel_shared].split(kernel_shared_ax0_ax1_fused_ax2_fused_ax3_fused_o, factor=56)
s[kernel_shared].bind(kernel_shared_ax0_ax1_fused_ax2_fused_ax3_fused_o_i, te.thread_axis(&quot;threadIdx.x&quot;))
pad_temp_shared_ax0_ax1_fused_ax2_fused_ax3_fused = s[pad_temp_shared].fuse(pad_temp_shared_ax0, pad_temp_shared_ax1, pad_temp_shared_ax2, pad_temp_shared_ax3)
pad_temp_shared_ax0_ax1_fused_ax2_fused_ax3_fused_o, pad_temp_shared_ax0_ax1_fused_ax2_fused_ax3_fused_i = s[pad_temp_shared].split(pad_temp_shared_ax0_ax1_fused_ax2_fused_ax3_fused, factor=1)
s[pad_temp_shared].vectorize(pad_temp_shared_ax0_ax1_fused_ax2_fused_ax3_fused_i)
pad_temp_shared_ax0_ax1_fused_ax2_fused_ax3_fused_o_o, pad_temp_shared_ax0_ax1_fused_ax2_fused_ax3_fused_o_i = s[pad_temp_shared].split(pad_temp_shared_ax0_ax1_fused_ax2_fused_ax3_fused_o, factor=56)
s[pad_temp_shared].bind(pad_temp_shared_ax0_ax1_fused_ax2_fused_ax3_fused_o_i, te.thread_axis(&quot;threadIdx.x&quot;))
s[compute].pragma(compute_nn_o_o_o_o, &quot;auto_unroll_max_step&quot;, 1024)
s[compute].pragma(compute_nn_o_o_o_o, &quot;unroll_explicit&quot;, True)

CUDA source code:

#ifdef _WIN32
  using uint = unsigned int;
  using uchar = unsigned char;
  using ushort = unsigned short;
  using int64_t = long long;
  using uint64_t = unsigned long long;
#else
  #define uint unsigned int
  #define uchar unsigned char
  #define ushort unsigned short
  #define int64_t long long
  #define uint64_t unsigned long long
#endif
extern &quot;C&quot; __global__ void default_function_kernel0(float* __restrict__ data, float* __restrict__ kernel, float* __restrict__ compute, float* __restrict__ bias) {
  float compute1[7];
  __shared__ float pad_temp_shared[1008];
  __shared__ float kernel_shared[384];
  compute1[(0)] = 0.000000e+00f;
  compute1[(1)] = 0.000000e+00f;
  compute1[(2)] = 0.000000e+00f;
  compute1[(3)] = 0.000000e+00f;
  compute1[(4)] = 0.000000e+00f;
  compute1[(5)] = 0.000000e+00f;
  compute1[(6)] = 0.000000e+00f;
  for (int rc_outer_outer = 0; rc_outer_outer &lt; 32; ++rc_outer_outer) {
    for (int rx_outer_outer = 0; rx_outer_outer &lt; 3; ++rx_outer_outer) {
      __syncthreads();
      pad_temp_shared[(((int)threadIdx.x))] = ((((7 &lt;= ((int)threadIdx.x)) &amp;&amp; (1 &lt;= (rx_outer_outer + (((int)threadIdx.x) % 7)))) &amp;&amp; ((rx_outer_outer + (((int)threadIdx.x) % 7)) &lt; 8)) ? data[(((((rc_outer_outer * 784) + ((int)threadIdx.x)) + rx_outer_outer) - 8))] : 0.000000e+00f);
      pad_temp_shared[((((int)threadIdx.x) + 56))] = (((((1 &lt;= (((((int)threadIdx.x) / 7) + 8) % 9)) &amp;&amp; ((((((int)threadIdx.x) / 7) + 8) % 9) &lt; 8)) &amp;&amp; (1 &lt;= (rx_outer_outer + (((int)threadIdx.x) % 7)))) &amp;&amp; ((rx_outer_outer + (((int)threadIdx.x) % 7)) &lt; 8)) ? data[(((((((rc_outer_outer * 784) + (((((int)threadIdx.x) + 56) / 63) * 49)) + ((((((int)threadIdx.x) / 7) + 8) % 9) * 7)) + rx_outer_outer) + (((int)threadIdx.x) % 7)) - 8))] : 0.000000e+00f);
      pad_temp_shared[((((int)threadIdx.x) + 112))] = (((((1 &lt;= (((((int)threadIdx.x) / 7) + 7) % 9)) &amp;&amp; ((((((int)threadIdx.x) / 7) + 7) % 9) &lt; 8)) &amp;&amp; (1 &lt;= (rx_outer_outer + (((int)threadIdx.x) % 7)))) &amp;&amp; ((rx_outer_outer + (((int)threadIdx.x) % 7)) &lt; 8)) ? data[(((((((rc_outer_outer * 784) + (((((int)threadIdx.x) + 112) / 63) * 49)) + ((((((int)threadIdx.x) / 7) + 7) % 9) * 7)) + rx_outer_outer) + (((int)threadIdx.x) % 7)) - 8))] : 0.000000e+00f);
      pad_temp_shared[((((int)threadIdx.x) + 168))] = (((((1 &lt;= (((((int)threadIdx.x) / 7) + 6) % 9)) &amp;&amp; ((((((int)threadIdx.x) / 7) + 6) % 9) &lt; 8)) &amp;&amp; (1 &lt;= (rx_outer_outer + (((int)threadIdx.x) % 7)))) &amp;&amp; ((rx_outer_outer + (((int)threadIdx.x) % 7)) &lt; 8)) ? data[(((((((rc_outer_outer * 784) + (((((int)threadIdx.x) + 168) / 63) * 49)) + ((((((int)threadIdx.x) / 7) + 6) % 9) * 7)) + rx_outer_outer) + (((int)threadIdx.x) % 7)) - 8))] : 0.000000e+00f);
      pad_temp_shared[((((int)threadIdx.x) + 224))] = (((((1 &lt;= (((((int)threadIdx.x) / 7) + 5) % 9)) &amp;&amp; ((((((int)threadIdx.x) / 7) + 5) % 9) &lt; 8)) &amp;&amp; (1 &lt;= (rx_outer_outer + (((int)threadIdx.x) % 7)))) &amp;&amp; ((rx_outer_outer + (((int)threadIdx.x) % 7)) &lt; 8)) ? data[(((((((rc_outer_outer * 784) + (((((int)threadIdx.x) + 224) / 63) * 49)) + ((((((int)threadIdx.x) / 7) + 5) % 9) * 7)) + rx_outer_outer) + (((int)threadIdx.x) % 7)) - 8))] : 0.000000e+00f);
      pad_temp_shared[((((int)threadIdx.x) + 280))] = (((((1 &lt;= (((((int)threadIdx.x) / 7) + 4) % 9)) &amp;&amp; ((((((int)threadIdx.x) / 7) + 4) % 9) &lt; 8)) &amp;&amp; (1 &lt;= (rx_outer_outer + (((int)threadIdx.x) % 7)))) &amp;&amp; ((rx_outer_outer + (((int)threadIdx.x) % 7)) &lt; 8)) ? data[(((((((rc_outer_outer * 784) + (((((int)threadIdx.x) + 280) / 63) * 49)) + ((((((int)threadIdx.x) / 7) + 4) % 9) * 7)) + rx_outer_outer) + (((int)threadIdx.x) % 7)) - 8))] : 0.000000e+00f);
      pad_temp_shared[((((int)threadIdx.x) + 336))] = (((((1 &lt;= (((((int)threadIdx.x) / 7) + 3) % 9)) &amp;&amp; ((((((int)threadIdx.x) / 7) + 3) % 9) &lt; 8)) &amp;&amp; (1 &lt;= (rx_outer_outer + (((int)threadIdx.x) % 7)))) &amp;&amp; ((rx_outer_outer + (((int)threadIdx.x) % 7)) &lt; 8)) ? data[(((((((rc_outer_outer * 784) + (((((int)threadIdx.x) + 336) / 63) * 49)) + ((((((int)threadIdx.x) / 7) + 3) % 9) * 7)) + rx_outer_outer) + (((int)threadIdx.x) % 7)) - 8))] : 0.000000e+00f);
      pad_temp_shared[((((int)threadIdx.x) + 392))] = (((((1 &lt;= (((((int)threadIdx.x) / 7) + 2) % 9)) &amp;&amp; ((((((int)threadIdx.x) / 7) + 2) % 9) &lt; 8)) &amp;&amp; (1 &lt;= (rx_outer_outer + (((int)threadIdx.x) % 7)))) &amp;&amp; ((rx_outer_outer + (((int)threadIdx.x) % 7)) &lt; 8)) ? data[(((((((rc_outer_outer * 784) + (((((int)threadIdx.x) + 392) / 63) * 49)) + ((((((int)threadIdx.x) / 7) + 2) % 9) * 7)) + rx_outer_outer) + (((int)threadIdx.x) % 7)) - 8))] : 0.000000e+00f);
      pad_temp_shared[((((int)threadIdx.x) + 448))] = ((((((int)threadIdx.x) &lt; 49) &amp;&amp; (1 &lt;= (rx_outer_outer + (((int)threadIdx.x) % 7)))) &amp;&amp; ((rx_outer_outer + (((int)threadIdx.x) % 7)) &lt; 8)) ? data[(((((((rc_outer_outer * 784) + (((((int)threadIdx.x) + 448) / 63) * 49)) + (((((int)threadIdx.x) / 7) + 1) * 7)) + rx_outer_outer) + (((int)threadIdx.x) % 7)) - 8))] : 0.000000e+00f);
      pad_temp_shared[((((int)threadIdx.x) + 504))] = ((((7 &lt;= ((int)threadIdx.x)) &amp;&amp; (1 &lt;= (rx_outer_outer + (((int)threadIdx.x) % 7)))) &amp;&amp; ((rx_outer_outer + (((int)threadIdx.x) % 7)) &lt; 8)) ? data[(((((rc_outer_outer * 784) + ((int)threadIdx.x)) + rx_outer_outer) + 384))] : 0.000000e+00f);
      pad_temp_shared[((((int)threadIdx.x) + 560))] = (((((1 &lt;= (((((int)threadIdx.x) / 7) + 8) % 9)) &amp;&amp; ((((((int)threadIdx.x) / 7) + 8) % 9) &lt; 8)) &amp;&amp; (1 &lt;= (rx_outer_outer + (((int)threadIdx.x) % 7)))) &amp;&amp; ((rx_outer_outer + (((int)threadIdx.x) % 7)) &lt; 8)) ? data[(((((((rc_outer_outer * 784) + (((((int)threadIdx.x) + 560) / 63) * 49)) + ((((((int)threadIdx.x) / 7) + 8) % 9) * 7)) + rx_outer_outer) + (((int)threadIdx.x) % 7)) - 8))] : 0.000000e+00f);
      pad_temp_shared[((((int)threadIdx.x) + 616))] = (((((1 &lt;= (((((int)threadIdx.x) / 7) + 7) % 9)) &amp;&amp; ((((((int)threadIdx.x) / 7) + 7) % 9) &lt; 8)) &amp;&amp; (1 &lt;= (rx_outer_outer + (((int)threadIdx.x) % 7)))) &amp;&amp; ((rx_outer_outer + (((int)threadIdx.x) % 7)) &lt; 8)) ? data[(((((((rc_outer_outer * 784) + (((((int)threadIdx.x) + 616) / 63) * 49)) + ((((((int)threadIdx.x) / 7) + 7) % 9) * 7)) + rx_outer_outer) + (((int)threadIdx.x) % 7)) - 8))] : 0.000000e+00f);
      pad_temp_shared[((((int)threadIdx.x) + 672))] = (((((1 &lt;= (((((int)threadIdx.x) / 7) + 6) % 9)) &amp;&amp; ((((((int)threadIdx.x) / 7) + 6) % 9) &lt; 8)) &amp;&amp; (1 &lt;= (rx_outer_outer + (((int)threadIdx.x) % 7)))) &amp;&amp; ((rx_outer_outer + (((int)threadIdx.x) % 7)) &lt; 8)) ? data[(((((((rc_outer_outer * 784) + (((((int)threadIdx.x) + 672) / 63) * 49)) + ((((((int)threadIdx.x) / 7) + 6) % 9) * 7)) + rx_outer_outer) + (((int)threadIdx.x) % 7)) - 8))] : 0.000000e+00f);
      pad_temp_shared[((((int)threadIdx.x) + 728))] = (((((1 &lt;= (((((int)threadIdx.x) / 7) + 5) % 9)) &amp;&amp; ((((((int)threadIdx.x) / 7) + 5) % 9) &lt; 8)) &amp;&amp; (1 &lt;= (rx_outer_outer + (((int)threadIdx.x) % 7)))) &amp;&amp; ((rx_outer_outer + (((int)threadIdx.x) % 7)) &lt; 8)) ? data[(((((((rc_outer_outer * 784) + (((((int)threadIdx.x) + 728) / 63) * 49)) + ((((((int)threadIdx.x) / 7) + 5) % 9) * 7)) + rx_outer_outer) + (((int)threadIdx.x) % 7)) - 8))] : 0.000000e+00f);
      pad_temp_shared[((((int)threadIdx.x) + 784))] = (((((1 &lt;= (((((int)threadIdx.x) / 7) + 4) % 9)) &amp;&amp; ((((((int)threadIdx.x) / 7) + 4) % 9) &lt; 8)) &amp;&amp; (1 &lt;= (rx_outer_outer + (((int)threadIdx.x) % 7)))) &amp;&amp; ((rx_outer_outer + (((int)threadIdx.x) % 7)) &lt; 8)) ? data[(((((((rc_outer_outer * 784) + (((((int)threadIdx.x) + 784) / 63) * 49)) + ((((((int)threadIdx.x) / 7) + 4) % 9) * 7)) + rx_outer_outer) + (((int)threadIdx.x) % 7)) - 8))] : 0.000000e+00f);
      pad_temp_shared[((((int)threadIdx.x) + 840))] = (((((1 &lt;= (((((int)threadIdx.x) / 7) + 3) % 9)) &amp;&amp; ((((((int)threadIdx.x) / 7) + 3) % 9) &lt; 8)) &amp;&amp; (1 &lt;= (rx_outer_outer + (((int)threadIdx.x) % 7)))) &amp;&amp; ((rx_outer_outer + (((int)threadIdx.x) % 7)) &lt; 8)) ? data[(((((((rc_outer_outer * 784) + (((((int)threadIdx.x) + 840) / 63) * 49)) + ((((((int)threadIdx.x) / 7) + 3) % 9) * 7)) + rx_outer_outer) + (((int)threadIdx.x) % 7)) - 8))] : 0.000000e+00f);
      pad_temp_shared[((((int)threadIdx.x) + 896))] = (((((1 &lt;= (((((int)threadIdx.x) / 7) + 2) % 9)) &amp;&amp; ((((((int)threadIdx.x) / 7) + 2) % 9) &lt; 8)) &amp;&amp; (1 &lt;= (rx_outer_outer + (((int)threadIdx.x) % 7)))) &amp;&amp; ((rx_outer_outer + (((int)threadIdx.x) % 7)) &lt; 8)) ? data[(((((((rc_outer_outer * 784) + (((((int)threadIdx.x) + 896) / 63) * 49)) + ((((((int)threadIdx.x) / 7) + 2) % 9) * 7)) + rx_outer_outer) + (((int)threadIdx.x) % 7)) - 8))] : 0.000000e+00f);
      pad_temp_shared[((((int)threadIdx.x) + 952))] = ((((((int)threadIdx.x) &lt; 49) &amp;&amp; (1 &lt;= (rx_outer_outer + (((int)threadIdx.x) % 7)))) &amp;&amp; ((rx_outer_outer + (((int)threadIdx.x) % 7)) &lt; 8)) ? data[(((((((rc_outer_outer * 784) + (((((int)threadIdx.x) + 952) / 63) * 49)) + (((((int)threadIdx.x) / 7) + 1) * 7)) + rx_outer_outer) + (((int)threadIdx.x) % 7)) - 8))] : 0.000000e+00f);
      kernel_shared[(((int)threadIdx.x))] = kernel[((((((((int)blockIdx.x) * 36864) + ((((int)threadIdx.x) / 48) * 4608)) + (rc_outer_outer * 144)) + ((((int)threadIdx.x) % 48) * 3)) + rx_outer_outer))];
      kernel_shared[((((int)threadIdx.x) + 56))] = kernel[((((((((int)blockIdx.x) * 36864) + (((((int)threadIdx.x) + 56) / 48) * 4608)) + (rc_outer_outer * 144)) + (((((int)threadIdx.x) + 8) % 48) * 3)) + rx_outer_outer))];
      kernel_shared[((((int)threadIdx.x) + 112))] = kernel[((((((((int)blockIdx.x) * 36864) + (((((int)threadIdx.x) + 112) / 48) * 4608)) + (rc_outer_outer * 144)) + (((((int)threadIdx.x) + 16) % 48) * 3)) + rx_outer_outer))];
      kernel_shared[((((int)threadIdx.x) + 168))] = kernel[((((((((int)blockIdx.x) * 36864) + (((((int)threadIdx.x) + 168) / 48) * 4608)) + (rc_outer_outer * 144)) + (((((int)threadIdx.x) + 24) % 48) * 3)) + rx_outer_outer))];
      kernel_shared[((((int)threadIdx.x) + 224))] = kernel[((((((((int)blockIdx.x) * 36864) + (((((int)threadIdx.x) + 224) / 48) * 4608)) + (rc_outer_outer * 144)) + (((((int)threadIdx.x) + 32) % 48) * 3)) + rx_outer_outer))];
      kernel_shared[((((int)threadIdx.x) + 280))] = kernel[((((((((int)blockIdx.x) * 36864) + (((((int)threadIdx.x) + 280) / 48) * 4608)) + (rc_outer_outer * 144)) + (((((int)threadIdx.x) + 40) % 48) * 3)) + rx_outer_outer))];
      if (((int)threadIdx.x) &lt; 48) {
        kernel_shared[((((int)threadIdx.x) + 336))] = kernel[((((((((int)blockIdx.x) * 36864) + (rc_outer_outer * 144)) + (((int)threadIdx.x) * 3)) + rx_outer_outer) + 32256))];
      }
      __syncthreads();
      compute1[(0)] = (compute1[(0)] + (pad_temp_shared[(((((int)threadIdx.x) % 7) * 7))] * kernel_shared[(((((int)threadIdx.x) / 7) * 48))]));
      compute1[(1)] = (compute1[(1)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 1))] * kernel_shared[(((((int)threadIdx.x) / 7) * 48))]));
      compute1[(2)] = (compute1[(2)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 2))] * kernel_shared[(((((int)threadIdx.x) / 7) * 48))]));
      compute1[(3)] = (compute1[(3)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 3))] * kernel_shared[(((((int)threadIdx.x) / 7) * 48))]));
      compute1[(4)] = (compute1[(4)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 4))] * kernel_shared[(((((int)threadIdx.x) / 7) * 48))]));
      compute1[(5)] = (compute1[(5)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 5))] * kernel_shared[(((((int)threadIdx.x) / 7) * 48))]));
      compute1[(6)] = (compute1[(6)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 6))] * kernel_shared[(((((int)threadIdx.x) / 7) * 48))]));
      compute1[(0)] = (compute1[(0)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 7))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 1))]));
      compute1[(1)] = (compute1[(1)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 8))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 1))]));
      compute1[(2)] = (compute1[(2)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 9))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 1))]));
      compute1[(3)] = (compute1[(3)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 10))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 1))]));
      compute1[(4)] = (compute1[(4)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 11))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 1))]));
      compute1[(5)] = (compute1[(5)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 12))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 1))]));
      compute1[(6)] = (compute1[(6)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 13))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 1))]));
      compute1[(0)] = (compute1[(0)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 14))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 2))]));
      compute1[(1)] = (compute1[(1)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 15))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 2))]));
      compute1[(2)] = (compute1[(2)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 16))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 2))]));
      compute1[(3)] = (compute1[(3)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 17))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 2))]));
      compute1[(4)] = (compute1[(4)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 18))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 2))]));
      compute1[(5)] = (compute1[(5)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 19))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 2))]));
      compute1[(6)] = (compute1[(6)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 20))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 2))]));
      compute1[(0)] = (compute1[(0)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 63))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 3))]));
      compute1[(1)] = (compute1[(1)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 64))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 3))]));
      compute1[(2)] = (compute1[(2)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 65))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 3))]));
      compute1[(3)] = (compute1[(3)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 66))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 3))]));
      compute1[(4)] = (compute1[(4)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 67))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 3))]));
      compute1[(5)] = (compute1[(5)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 68))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 3))]));
      compute1[(6)] = (compute1[(6)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 69))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 3))]));
      compute1[(0)] = (compute1[(0)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 70))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 4))]));
      compute1[(1)] = (compute1[(1)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 71))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 4))]));
      compute1[(2)] = (compute1[(2)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 72))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 4))]));
      compute1[(3)] = (compute1[(3)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 73))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 4))]));
      compute1[(4)] = (compute1[(4)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 74))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 4))]));
      compute1[(5)] = (compute1[(5)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 75))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 4))]));
      compute1[(6)] = (compute1[(6)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 76))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 4))]));
      compute1[(0)] = (compute1[(0)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 77))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 5))]));
      compute1[(1)] = (compute1[(1)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 78))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 5))]));
      compute1[(2)] = (compute1[(2)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 79))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 5))]));
      compute1[(3)] = (compute1[(3)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 80))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 5))]));
      compute1[(4)] = (compute1[(4)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 81))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 5))]));
      compute1[(5)] = (compute1[(5)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 82))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 5))]));
      compute1[(6)] = (compute1[(6)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 83))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 5))]));
      compute1[(0)] = (compute1[(0)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 126))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 6))]));
      compute1[(1)] = (compute1[(1)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 127))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 6))]));
      compute1[(2)] = (compute1[(2)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 128))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 6))]));
      compute1[(3)] = (compute1[(3)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 129))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 6))]));
      compute1[(4)] = (compute1[(4)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 130))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 6))]));
      compute1[(5)] = (compute1[(5)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 131))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 6))]));
      compute1[(6)] = (compute1[(6)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 132))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 6))]));
      compute1[(0)] = (compute1[(0)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 133))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 7))]));
      compute1[(1)] = (compute1[(1)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 134))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 7))]));
      compute1[(2)] = (compute1[(2)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 135))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 7))]));
      compute1[(3)] = (compute1[(3)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 136))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 7))]));
      compute1[(4)] = (compute1[(4)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 137))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 7))]));
      compute1[(5)] = (compute1[(5)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 138))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 7))]));
      compute1[(6)] = (compute1[(6)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 139))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 7))]));
      compute1[(0)] = (compute1[(0)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 140))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 8))]));
      compute1[(1)] = (compute1[(1)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 141))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 8))]));
      compute1[(2)] = (compute1[(2)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 142))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 8))]));
      compute1[(3)] = (compute1[(3)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 143))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 8))]));
      compute1[(4)] = (compute1[(4)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 144))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 8))]));
      compute1[(5)] = (compute1[(5)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 145))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 8))]));
      compute1[(6)] = (compute1[(6)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 146))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 8))]));
      compute1[(0)] = (compute1[(0)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 189))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 9))]));
      compute1[(1)] = (compute1[(1)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 190))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 9))]));
      compute1[(2)] = (compute1[(2)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 191))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 9))]));
      compute1[(3)] = (compute1[(3)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 192))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 9))]));
      compute1[(4)] = (compute1[(4)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 193))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 9))]));
      compute1[(5)] = (compute1[(5)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 194))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 9))]));
      compute1[(6)] = (compute1[(6)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 195))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 9))]));
      compute1[(0)] = (compute1[(0)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 196))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 10))]));
      compute1[(1)] = (compute1[(1)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 197))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 10))]));
      compute1[(2)] = (compute1[(2)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 198))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 10))]));
      compute1[(3)] = (compute1[(3)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 199))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 10))]));
      compute1[(4)] = (compute1[(4)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 200))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 10))]));
      compute1[(5)] = (compute1[(5)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 201))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 10))]));
      compute1[(6)] = (compute1[(6)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 202))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 10))]));
      compute1[(0)] = (compute1[(0)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 203))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 11))]));
      compute1[(1)] = (compute1[(1)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 204))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 11))]));
      compute1[(2)] = (compute1[(2)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 205))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 11))]));
      compute1[(3)] = (compute1[(3)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 206))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 11))]));
      compute1[(4)] = (compute1[(4)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 207))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 11))]));
      compute1[(5)] = (compute1[(5)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 208))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 11))]));
      compute1[(6)] = (compute1[(6)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 209))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 11))]));
      compute1[(0)] = (compute1[(0)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 252))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 12))]));
      compute1[(1)] = (compute1[(1)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 253))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 12))]));
      compute1[(2)] = (compute1[(2)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 254))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 12))]));
      compute1[(3)] = (compute1[(3)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 255))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 12))]));
      compute1[(4)] = (compute1[(4)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 256))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 12))]));
      compute1[(5)] = (compute1[(5)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 257))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 12))]));
      compute1[(6)] = (compute1[(6)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 258))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 12))]));
      compute1[(0)] = (compute1[(0)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 259))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 13))]));
      compute1[(1)] = (compute1[(1)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 260))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 13))]));
      compute1[(2)] = (compute1[(2)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 261))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 13))]));
      compute1[(3)] = (compute1[(3)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 262))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 13))]));
      compute1[(4)] = (compute1[(4)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 263))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 13))]));
      compute1[(5)] = (compute1[(5)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 264))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 13))]));
      compute1[(6)] = (compute1[(6)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 265))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 13))]));
      compute1[(0)] = (compute1[(0)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 266))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 14))]));
      compute1[(1)] = (compute1[(1)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 267))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 14))]));
      compute1[(2)] = (compute1[(2)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 268))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 14))]));
      compute1[(3)] = (compute1[(3)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 269))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 14))]));
      compute1[(4)] = (compute1[(4)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 270))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 14))]));
      compute1[(5)] = (compute1[(5)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 271))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 14))]));
      compute1[(6)] = (compute1[(6)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 272))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 14))]));
      compute1[(0)] = (compute1[(0)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 315))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 15))]));
      compute1[(1)] = (compute1[(1)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 316))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 15))]));
      compute1[(2)] = (compute1[(2)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 317))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 15))]));
      compute1[(3)] = (compute1[(3)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 318))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 15))]));
      compute1[(4)] = (compute1[(4)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 319))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 15))]));
      compute1[(5)] = (compute1[(5)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 320))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 15))]));
      compute1[(6)] = (compute1[(6)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 321))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 15))]));
      compute1[(0)] = (compute1[(0)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 322))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 16))]));
      compute1[(1)] = (compute1[(1)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 323))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 16))]));
      compute1[(2)] = (compute1[(2)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 324))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 16))]));
      compute1[(3)] = (compute1[(3)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 325))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 16))]));
      compute1[(4)] = (compute1[(4)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 326))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 16))]));
      compute1[(5)] = (compute1[(5)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 327))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 16))]));
      compute1[(6)] = (compute1[(6)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 328))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 16))]));
      compute1[(0)] = (compute1[(0)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 329))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 17))]));
      compute1[(1)] = (compute1[(1)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 330))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 17))]));
      compute1[(2)] = (compute1[(2)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 331))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 17))]));
      compute1[(3)] = (compute1[(3)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 332))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 17))]));
      compute1[(4)] = (compute1[(4)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 333))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 17))]));
      compute1[(5)] = (compute1[(5)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 334))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 17))]));
      compute1[(6)] = (compute1[(6)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 335))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 17))]));
      compute1[(0)] = (compute1[(0)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 378))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 18))]));
      compute1[(1)] = (compute1[(1)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 379))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 18))]));
      compute1[(2)] = (compute1[(2)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 380))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 18))]));
      compute1[(3)] = (compute1[(3)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 381))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 18))]));
      compute1[(4)] = (compute1[(4)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 382))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 18))]));
      compute1[(5)] = (compute1[(5)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 383))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 18))]));
      compute1[(6)] = (compute1[(6)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 384))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 18))]));
      compute1[(0)] = (compute1[(0)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 385))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 19))]));
      compute1[(1)] = (compute1[(1)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 386))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 19))]));
      compute1[(2)] = (compute1[(2)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 387))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 19))]));
      compute1[(3)] = (compute1[(3)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 388))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 19))]));
      compute1[(4)] = (compute1[(4)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 389))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 19))]));
      compute1[(5)] = (compute1[(5)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 390))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 19))]));
      compute1[(6)] = (compute1[(6)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 391))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 19))]));
      compute1[(0)] = (compute1[(0)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 392))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 20))]));
      compute1[(1)] = (compute1[(1)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 393))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 20))]));
      compute1[(2)] = (compute1[(2)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 394))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 20))]));
      compute1[(3)] = (compute1[(3)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 395))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 20))]));
      compute1[(4)] = (compute1[(4)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 396))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 20))]));
      compute1[(5)] = (compute1[(5)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 397))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 20))]));
      compute1[(6)] = (compute1[(6)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 398))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 20))]));
      compute1[(0)] = (compute1[(0)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 441))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 21))]));
      compute1[(1)] = (compute1[(1)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 442))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 21))]));
      compute1[(2)] = (compute1[(2)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 443))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 21))]));
      compute1[(3)] = (compute1[(3)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 444))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 21))]));
      compute1[(4)] = (compute1[(4)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 445))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 21))]));
      compute1[(5)] = (compute1[(5)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 446))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 21))]));
      compute1[(6)] = (compute1[(6)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 447))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 21))]));
      compute1[(0)] = (compute1[(0)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 448))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 22))]));
      compute1[(1)] = (compute1[(1)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 449))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 22))]));
      compute1[(2)] = (compute1[(2)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 450))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 22))]));
      compute1[(3)] = (compute1[(3)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 451))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 22))]));
      compute1[(4)] = (compute1[(4)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 452))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 22))]));
      compute1[(5)] = (compute1[(5)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 453))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 22))]));
      compute1[(6)] = (compute1[(6)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 454))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 22))]));
      compute1[(0)] = (compute1[(0)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 455))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 23))]));
      compute1[(1)] = (compute1[(1)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 456))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 23))]));
      compute1[(2)] = (compute1[(2)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 457))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 23))]));
      compute1[(3)] = (compute1[(3)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 458))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 23))]));
      compute1[(4)] = (compute1[(4)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 459))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 23))]));
      compute1[(5)] = (compute1[(5)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 460))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 23))]));
      compute1[(6)] = (compute1[(6)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 461))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 23))]));
      compute1[(0)] = (compute1[(0)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 504))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 24))]));
      compute1[(1)] = (compute1[(1)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 505))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 24))]));
      compute1[(2)] = (compute1[(2)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 506))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 24))]));
      compute1[(3)] = (compute1[(3)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 507))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 24))]));
      compute1[(4)] = (compute1[(4)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 508))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 24))]));
      compute1[(5)] = (compute1[(5)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 509))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 24))]));
      compute1[(6)] = (compute1[(6)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 510))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 24))]));
      compute1[(0)] = (compute1[(0)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 511))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 25))]));
      compute1[(1)] = (compute1[(1)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 512))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 25))]));
      compute1[(2)] = (compute1[(2)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 513))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 25))]));
      compute1[(3)] = (compute1[(3)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 514))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 25))]));
      compute1[(4)] = (compute1[(4)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 515))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 25))]));
      compute1[(5)] = (compute1[(5)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 516))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 25))]));
      compute1[(6)] = (compute1[(6)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 517))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 25))]));
      compute1[(0)] = (compute1[(0)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 518))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 26))]));
      compute1[(1)] = (compute1[(1)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 519))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 26))]));
      compute1[(2)] = (compute1[(2)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 520))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 26))]));
      compute1[(3)] = (compute1[(3)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 521))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 26))]));
      compute1[(4)] = (compute1[(4)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 522))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 26))]));
      compute1[(5)] = (compute1[(5)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 523))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 26))]));
      compute1[(6)] = (compute1[(6)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 524))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 26))]));
      compute1[(0)] = (compute1[(0)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 567))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 27))]));
      compute1[(1)] = (compute1[(1)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 568))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 27))]));
      compute1[(2)] = (compute1[(2)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 569))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 27))]));
      compute1[(3)] = (compute1[(3)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 570))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 27))]));
      compute1[(4)] = (compute1[(4)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 571))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 27))]));
      compute1[(5)] = (compute1[(5)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 572))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 27))]));
      compute1[(6)] = (compute1[(6)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 573))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 27))]));
      compute1[(0)] = (compute1[(0)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 574))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 28))]));
      compute1[(1)] = (compute1[(1)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 575))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 28))]));
      compute1[(2)] = (compute1[(2)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 576))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 28))]));
      compute1[(3)] = (compute1[(3)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 577))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 28))]));
      compute1[(4)] = (compute1[(4)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 578))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 28))]));
      compute1[(5)] = (compute1[(5)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 579))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 28))]));
      compute1[(6)] = (compute1[(6)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 580))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 28))]));
      compute1[(0)] = (compute1[(0)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 581))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 29))]));
      compute1[(1)] = (compute1[(1)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 582))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 29))]));
      compute1[(2)] = (compute1[(2)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 583))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 29))]));
      compute1[(3)] = (compute1[(3)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 584))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 29))]));
      compute1[(4)] = (compute1[(4)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 585))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 29))]));
      compute1[(5)] = (compute1[(5)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 586))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 29))]));
      compute1[(6)] = (compute1[(6)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 587))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 29))]));
      compute1[(0)] = (compute1[(0)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 630))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 30))]));
      compute1[(1)] = (compute1[(1)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 631))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 30))]));
      compute1[(2)] = (compute1[(2)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 632))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 30))]));
      compute1[(3)] = (compute1[(3)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 633))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 30))]));
      compute1[(4)] = (compute1[(4)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 634))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 30))]));
      compute1[(5)] = (compute1[(5)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 635))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 30))]));
      compute1[(6)] = (compute1[(6)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 636))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 30))]));
      compute1[(0)] = (compute1[(0)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 637))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 31))]));
      compute1[(1)] = (compute1[(1)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 638))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 31))]));
      compute1[(2)] = (compute1[(2)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 639))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 31))]));
      compute1[(3)] = (compute1[(3)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 640))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 31))]));
      compute1[(4)] = (compute1[(4)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 641))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 31))]));
      compute1[(5)] = (compute1[(5)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 642))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 31))]));
      compute1[(6)] = (compute1[(6)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 643))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 31))]));
      compute1[(0)] = (compute1[(0)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 644))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 32))]));
      compute1[(1)] = (compute1[(1)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 645))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 32))]));
      compute1[(2)] = (compute1[(2)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 646))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 32))]));
      compute1[(3)] = (compute1[(3)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 647))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 32))]));
      compute1[(4)] = (compute1[(4)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 648))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 32))]));
      compute1[(5)] = (compute1[(5)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 649))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 32))]));
      compute1[(6)] = (compute1[(6)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 650))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 32))]));
      compute1[(0)] = (compute1[(0)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 693))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 33))]));
      compute1[(1)] = (compute1[(1)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 694))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 33))]));
      compute1[(2)] = (compute1[(2)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 695))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 33))]));
      compute1[(3)] = (compute1[(3)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 696))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 33))]));
      compute1[(4)] = (compute1[(4)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 697))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 33))]));
      compute1[(5)] = (compute1[(5)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 698))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 33))]));
      compute1[(6)] = (compute1[(6)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 699))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 33))]));
      compute1[(0)] = (compute1[(0)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 700))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 34))]));
      compute1[(1)] = (compute1[(1)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 701))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 34))]));
      compute1[(2)] = (compute1[(2)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 702))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 34))]));
      compute1[(3)] = (compute1[(3)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 703))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 34))]));
      compute1[(4)] = (compute1[(4)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 704))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 34))]));
      compute1[(5)] = (compute1[(5)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 705))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 34))]));
      compute1[(6)] = (compute1[(6)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 706))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 34))]));
      compute1[(0)] = (compute1[(0)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 707))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 35))]));
      compute1[(1)] = (compute1[(1)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 708))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 35))]));
      compute1[(2)] = (compute1[(2)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 709))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 35))]));
      compute1[(3)] = (compute1[(3)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 710))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 35))]));
      compute1[(4)] = (compute1[(4)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 711))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 35))]));
      compute1[(5)] = (compute1[(5)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 712))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 35))]));
      compute1[(6)] = (compute1[(6)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 713))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 35))]));
      compute1[(0)] = (compute1[(0)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 756))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 36))]));
      compute1[(1)] = (compute1[(1)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 757))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 36))]));
      compute1[(2)] = (compute1[(2)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 758))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 36))]));
      compute1[(3)] = (compute1[(3)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 759))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 36))]));
      compute1[(4)] = (compute1[(4)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 760))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 36))]));
      compute1[(5)] = (compute1[(5)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 761))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 36))]));
      compute1[(6)] = (compute1[(6)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 762))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 36))]));
      compute1[(0)] = (compute1[(0)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 763))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 37))]));
      compute1[(1)] = (compute1[(1)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 764))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 37))]));
      compute1[(2)] = (compute1[(2)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 765))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 37))]));
      compute1[(3)] = (compute1[(3)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 766))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 37))]));
      compute1[(4)] = (compute1[(4)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 767))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 37))]));
      compute1[(5)] = (compute1[(5)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 768))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 37))]));
      compute1[(6)] = (compute1[(6)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 769))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 37))]));
      compute1[(0)] = (compute1[(0)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 770))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 38))]));
      compute1[(1)] = (compute1[(1)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 771))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 38))]));
      compute1[(2)] = (compute1[(2)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 772))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 38))]));
      compute1[(3)] = (compute1[(3)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 773))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 38))]));
      compute1[(4)] = (compute1[(4)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 774))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 38))]));
      compute1[(5)] = (compute1[(5)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 775))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 38))]));
      compute1[(6)] = (compute1[(6)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 776))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 38))]));
      compute1[(0)] = (compute1[(0)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 819))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 39))]));
      compute1[(1)] = (compute1[(1)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 820))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 39))]));
      compute1[(2)] = (compute1[(2)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 821))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 39))]));
      compute1[(3)] = (compute1[(3)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 822))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 39))]));
      compute1[(4)] = (compute1[(4)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 823))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 39))]));
      compute1[(5)] = (compute1[(5)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 824))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 39))]));
      compute1[(6)] = (compute1[(6)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 825))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 39))]));
      compute1[(0)] = (compute1[(0)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 826))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 40))]));
      compute1[(1)] = (compute1[(1)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 827))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 40))]));
      compute1[(2)] = (compute1[(2)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 828))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 40))]));
      compute1[(3)] = (compute1[(3)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 829))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 40))]));
      compute1[(4)] = (compute1[(4)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 830))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 40))]));
      compute1[(5)] = (compute1[(5)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 831))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 40))]));
      compute1[(6)] = (compute1[(6)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 832))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 40))]));
      compute1[(0)] = (compute1[(0)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 833))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 41))]));
      compute1[(1)] = (compute1[(1)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 834))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 41))]));
      compute1[(2)] = (compute1[(2)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 835))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 41))]));
      compute1[(3)] = (compute1[(3)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 836))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 41))]));
      compute1[(4)] = (compute1[(4)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 837))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 41))]));
      compute1[(5)] = (compute1[(5)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 838))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 41))]));
      compute1[(6)] = (compute1[(6)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 839))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 41))]));
      compute1[(0)] = (compute1[(0)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 882))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 42))]));
      compute1[(1)] = (compute1[(1)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 883))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 42))]));
      compute1[(2)] = (compute1[(2)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 884))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 42))]));
      compute1[(3)] = (compute1[(3)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 885))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 42))]));
      compute1[(4)] = (compute1[(4)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 886))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 42))]));
      compute1[(5)] = (compute1[(5)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 887))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 42))]));
      compute1[(6)] = (compute1[(6)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 888))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 42))]));
      compute1[(0)] = (compute1[(0)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 889))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 43))]));
      compute1[(1)] = (compute1[(1)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 890))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 43))]));
      compute1[(2)] = (compute1[(2)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 891))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 43))]));
      compute1[(3)] = (compute1[(3)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 892))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 43))]));
      compute1[(4)] = (compute1[(4)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 893))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 43))]));
      compute1[(5)] = (compute1[(5)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 894))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 43))]));
      compute1[(6)] = (compute1[(6)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 895))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 43))]));
      compute1[(0)] = (compute1[(0)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 896))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 44))]));
      compute1[(1)] = (compute1[(1)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 897))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 44))]));
      compute1[(2)] = (compute1[(2)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 898))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 44))]));
      compute1[(3)] = (compute1[(3)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 899))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 44))]));
      compute1[(4)] = (compute1[(4)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 900))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 44))]));
      compute1[(5)] = (compute1[(5)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 901))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 44))]));
      compute1[(6)] = (compute1[(6)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 902))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 44))]));
      compute1[(0)] = (compute1[(0)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 945))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 45))]));
      compute1[(1)] = (compute1[(1)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 946))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 45))]));
      compute1[(2)] = (compute1[(2)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 947))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 45))]));
      compute1[(3)] = (compute1[(3)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 948))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 45))]));
      compute1[(4)] = (compute1[(4)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 949))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 45))]));
      compute1[(5)] = (compute1[(5)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 950))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 45))]));
      compute1[(6)] = (compute1[(6)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 951))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 45))]));
      compute1[(0)] = (compute1[(0)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 952))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 46))]));
      compute1[(1)] = (compute1[(1)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 953))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 46))]));
      compute1[(2)] = (compute1[(2)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 954))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 46))]));
      compute1[(3)] = (compute1[(3)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 955))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 46))]));
      compute1[(4)] = (compute1[(4)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 956))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 46))]));
      compute1[(5)] = (compute1[(5)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 957))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 46))]));
      compute1[(6)] = (compute1[(6)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 958))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 46))]));
      compute1[(0)] = (compute1[(0)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 959))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 47))]));
      compute1[(1)] = (compute1[(1)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 960))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 47))]));
      compute1[(2)] = (compute1[(2)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 961))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 47))]));
      compute1[(3)] = (compute1[(3)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 962))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 47))]));
      compute1[(4)] = (compute1[(4)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 963))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 47))]));
      compute1[(5)] = (compute1[(5)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 964))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 47))]));
      compute1[(6)] = (compute1[(6)] + (pad_temp_shared[((((((int)threadIdx.x) % 7) * 7) + 965))] * kernel_shared[((((((int)threadIdx.x) / 7) * 48) + 47))]));
    }
  }
  compute[(((((int)blockIdx.x) * 392) + (((int)threadIdx.x) * 7)))] = max((compute1[(0)] + bias[(((((int)blockIdx.x) * 8) + (((int)threadIdx.x) / 7)))]), 0.000000e+00f);
  compute[((((((int)blockIdx.x) * 392) + (((int)threadIdx.x) * 7)) + 1))] = max((compute1[(1)] + bias[(((((int)blockIdx.x) * 8) + (((int)threadIdx.x) / 7)))]), 0.000000e+00f);
  compute[((((((int)blockIdx.x) * 392) + (((int)threadIdx.x) * 7)) + 2))] = max((compute1[(2)] + bias[(((((int)blockIdx.x) * 8) + (((int)threadIdx.x) / 7)))]), 0.000000e+00f);
  compute[((((((int)blockIdx.x) * 392) + (((int)threadIdx.x) * 7)) + 3))] = max((compute1[(3)] + bias[(((((int)blockIdx.x) * 8) + (((int)threadIdx.x) / 7)))]), 0.000000e+00f);
  compute[((((((int)blockIdx.x) * 392) + (((int)threadIdx.x) * 7)) + 4))] = max((compute1[(4)] + bias[(((((int)blockIdx.x) * 8) + (((int)threadIdx.x) / 7)))]), 0.000000e+00f);
  compute[((((((int)blockIdx.x) * 392) + (((int)threadIdx.x) * 7)) + 5))] = max((compute1[(5)] + bias[(((((int)blockIdx.x) * 8) + (((int)threadIdx.x) / 7)))]), 0.000000e+00f);
  compute[((((((int)blockIdx.x) * 392) + (((int)threadIdx.x) * 7)) + 6))] = max((compute1[(6)] + bias[(((((int)blockIdx.x) * 8) + (((int)threadIdx.x) / 7)))]), 0.000000e+00f);
}
</pre></div>
</div>
<p>A more complicated example is to resume the search.
In this case, we need to create the search policy and cost model by ourselves
and resume the status of search policy and cost model with the log file.
In the example below we resume the status and do more 5 trials.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">resume_search</span><span class="p">(</span><span class="n">task</span><span class="p">,</span> <span class="n">log_file</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Resume search:&quot;</span><span class="p">)</span>
    <span class="n">cost_model</span> <span class="o">=</span> <a href="../../api/python/auto_scheduler.html#tvm.auto_scheduler.XGBModel" title="View documentation for tvm.auto_scheduler.XGBModel"><span class="n">auto_scheduler</span><span class="o">.</span><span class="n">XGBModel</span></a><span class="p">()</span>
    <span class="n">cost_model</span><span class="o">.</span><span class="n">update_from_file</span><span class="p">(</span><span class="n">log_file</span><span class="p">)</span>
    <span class="n">search_policy</span> <span class="o">=</span> <a href="../../api/python/auto_scheduler.html#tvm.auto_scheduler.SketchPolicy" title="View documentation for tvm.auto_scheduler.SketchPolicy"><span class="n">auto_scheduler</span><span class="o">.</span><span class="n">SketchPolicy</span></a><span class="p">(</span>
        <span class="n">task</span><span class="p">,</span> <span class="n">cost_model</span><span class="p">,</span> <span class="n">init_search_callbacks</span><span class="o">=</span><span class="p">[</span><a href="../../api/python/auto_scheduler.html#tvm.auto_scheduler.PreloadMeasuredStates" title="View documentation for tvm.auto_scheduler.PreloadMeasuredStates"><span class="n">auto_scheduler</span><span class="o">.</span><span class="n">PreloadMeasuredStates</span></a><span class="p">(</span><span class="n">log_file</span><span class="p">)]</span>
    <span class="p">)</span>
    <span class="n">measure_ctx</span> <span class="o">=</span> <a href="../../api/python/auto_scheduler.html#tvm.auto_scheduler.LocalRPCMeasureContext" title="View documentation for tvm.auto_scheduler.LocalRPCMeasureContext"><span class="n">auto_scheduler</span><span class="o">.</span><span class="n">LocalRPCMeasureContext</span></a><span class="p">(</span><span class="n">min_repeat_ms</span><span class="o">=</span><span class="mi">300</span><span class="p">)</span>
    <span class="n">tune_option</span> <span class="o">=</span> <a href="../../api/python/auto_scheduler.html#tvm.auto_scheduler.TuningOptions" title="View documentation for tvm.auto_scheduler.TuningOptions"><span class="n">auto_scheduler</span><span class="o">.</span><span class="n">TuningOptions</span></a><span class="p">(</span>
        <span class="n">num_measure_trials</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
        <span class="n">runner</span><span class="o">=</span><span class="n">measure_ctx</span><span class="o">.</span><span class="n">runner</span><span class="p">,</span>
        <span class="n">measure_callbacks</span><span class="o">=</span><span class="p">[</span><a href="../../api/python/auto_scheduler.html#tvm.auto_scheduler.RecordToFile" title="View documentation for tvm.auto_scheduler.RecordToFile"><span class="n">auto_scheduler</span><span class="o">.</span><span class="n">RecordToFile</span></a><span class="p">(</span><span class="n">log_file</span><span class="p">)],</span>
    <span class="p">)</span>
    <span class="n">task</span><span class="o">.</span><span class="n">tune</span><span class="p">(</span><span class="n">tune_option</span><span class="p">,</span> <span class="n">search_policy</span><span class="o">=</span><span class="n">search_policy</span><span class="p">)</span>

    <span class="c1"># Kill the measurement process</span>
    <span class="k">del</span> <span class="n">measure_ctx</span>


<span class="n">resume_search</span><span class="p">(</span><span class="n">task</span><span class="p">,</span> <span class="n">log_file</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Resume search:
/usr/local/lib/python3.6/dist-packages/xgboost/training.py:17: UserWarning: Old style callback is deprecated.  See: https://xgboost.readthedocs.io/en/latest/python/callbacks.html
  warnings.warn(f&#39;Old style callback is deprecated.  See: {link}&#39;, UserWarning)
Get devices for measurement successfully!
</pre></div>
</div>
<p class="sphx-glr-timing"><strong>Total running time of the script:</strong> ( 1 minutes  3.026 seconds)</p>
<div class="sphx-glr-footer class sphx-glr-footer-example docutils container" id="sphx-glr-download-tutorials-auto-scheduler-tune-conv2d-layer-cuda-py">
<div class="sphx-glr-download docutils container">
<p><a class="reference download internal" download="" href="../../_downloads/678f3c372a599a18d909aed0fefb30be/tune_conv2d_layer_cuda.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">tune_conv2d_layer_cuda.py</span></code></a></p>
</div>
<div class="sphx-glr-download docutils container">
<p><a class="reference download internal" download="" href="../../_downloads/bcb4a24e8acc1ca84214bc8d7fb7954b/tune_conv2d_layer_cuda.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">tune_conv2d_layer_cuda.ipynb</span></code></a></p>
</div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.github.io">Gallery generated by Sphinx-Gallery</a></p>
</section>
</section>


           </div>
           
          </div>
          

<footer>

    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="tune_network_x86.html" class="btn btn-neutral float-right" title="Auto-scheduling a Neural Network for x86 CPU" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="../autotvm/tune_relay_mobile_gpu.html" class="btn btn-neutral float-left" title="Auto-tuning a Convolutional Network for Mobile GPU" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>

<div id="button" class="backtop"><img src="../../_static//img/right.svg" alt="backtop"/> </div>
<section class="footerSec">
    <div class="footerHeader">
      <ul class="d-flex align-md-items-center justify-content-between flex-column flex-md-row">
        <li class="copywrite d-flex align-items-center">
          <h5 id="copy-right-info">© 2020 Apache Software Foundation | All right reserved</h5>
        </li>
      </ul>

    </div>

    <ul>
      <li class="footernote">Copyright © 2020 The Apache Software Foundation. Apache TVM, Apache, the Apache feather, and the Apache TVM project logo are either trademarks or registered trademarks of the Apache Software Foundation.</li>
    </ul>

</section>
</footer>
        </div>
      </div>

    </section>

  </div>
  

    <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.12.9/umd/popper.min.js" integrity="sha384-ApNbgh9B+Y1QKtv3Rn7W3mgPxhU9K/ScQsAP7hUibX39j7fakFPskvXusvfa0b4Q" crossorigin="anonymous"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/js/bootstrap.min.js" integrity="sha384-JZR6Spejh4U02d8jOt6vLEHfe/JQGiRRSQQxSfFWpi1MquVdAyjUar5+76PVCmYl" crossorigin="anonymous"></script>

  </body>
  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
    <!-- Theme Analytics -->
    <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-75982049-2', 'auto');
    ga('send', 'pageview');
    </script>

    
   

</body>
</html>